{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d302fa6-142b-4a37-af40-6ec4e59b3dd1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Seasonal flu vaccines\n",
    "This exericse predicts whether individuals will receive their seasonal flu vaccines by fitting machine learning models to the U.S. National 2009 H1N1 Flu Survey data. Data is provided courtesy of the United States National Center for Health Statistics to DrivenData for a practice competition (https://www.drivendata.org/competitions/66/flu-shot-learning/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1f475bcb-6bc5-46f4-857c-44f2b7fb7fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#data preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#support vector classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#deep learning model\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "\n",
    "#performance metrics\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2f42718a-2ab4-42b6-8f18-917728e822b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d12b6ba-4a96-408d-b531-34162e37dfcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data checking and cleaning\n",
    "In this section, read the csv files into pandas Dataframe and perform any necessary checking and cleaning steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1fef6eb2-c36c-491e-8fdd-aea483a1c0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1n1_vaccine</th>\n",
       "      <th>seasonal_vaccine</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respondent_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               h1n1_vaccine  seasonal_vaccine\n",
       "respondent_id                                \n",
       "0                         0                 0\n",
       "1                         0                 1\n",
       "2                         0                 0"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading training_set_labels \n",
    "df_labels = pd.read_csv(\"./Resources/training_set_labels.csv\", index_col = \"respondent_id\")\n",
    "df_labels.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "80488bd8-3ae1-4bcb-9f97-3968aeb068df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>doctor_recc_h1n1</th>\n",
       "      <th>...</th>\n",
       "      <th>income_poverty</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>rent_or_own</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>census_msa</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>employment_industry</th>\n",
       "      <th>employment_occupation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respondent_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>oxchjgsf</td>\n",
       "      <td>Non-MSA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Employed</td>\n",
       "      <td>bhuqouqj</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pxcmvdjn</td>\n",
       "      <td>xgwztkwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rucpziij</td>\n",
       "      <td>xtkaffoo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n",
       "respondent_id                                                            \n",
       "0                       1.0             0.0                        0.0   \n",
       "1                       3.0             2.0                        0.0   \n",
       "2                       1.0             1.0                        0.0   \n",
       "\n",
       "               behavioral_avoidance  behavioral_face_mask  \\\n",
       "respondent_id                                               \n",
       "0                               0.0                   0.0   \n",
       "1                               1.0                   0.0   \n",
       "2                               1.0                   0.0   \n",
       "\n",
       "               behavioral_wash_hands  behavioral_large_gatherings  \\\n",
       "respondent_id                                                       \n",
       "0                                0.0                          0.0   \n",
       "1                                1.0                          0.0   \n",
       "2                                0.0                          0.0   \n",
       "\n",
       "               behavioral_outside_home  behavioral_touch_face  \\\n",
       "respondent_id                                                   \n",
       "0                                  1.0                    1.0   \n",
       "1                                  1.0                    1.0   \n",
       "2                                  0.0                    0.0   \n",
       "\n",
       "               doctor_recc_h1n1  ...             income_poverty  \\\n",
       "respondent_id                    ...                              \n",
       "0                           0.0  ...              Below Poverty   \n",
       "1                           0.0  ...              Below Poverty   \n",
       "2                           NaN  ...  <= $75,000, Above Poverty   \n",
       "\n",
       "               marital_status  rent_or_own   employment_status  \\\n",
       "respondent_id                                                    \n",
       "0                 Not Married          Own  Not in Labor Force   \n",
       "1                 Not Married         Rent            Employed   \n",
       "2                 Not Married          Own            Employed   \n",
       "\n",
       "               hhs_geo_region                census_msa  household_adults  \\\n",
       "respondent_id                                                               \n",
       "0                    oxchjgsf                   Non-MSA               0.0   \n",
       "1                    bhuqouqj  MSA, Not Principle  City               0.0   \n",
       "2                    qufhixun  MSA, Not Principle  City               2.0   \n",
       "\n",
       "               household_children  employment_industry  employment_occupation  \n",
       "respondent_id                                                                  \n",
       "0                             0.0                  NaN                    NaN  \n",
       "1                             0.0             pxcmvdjn               xgwztkwe  \n",
       "2                             0.0             rucpziij               xtkaffoo  \n",
       "\n",
       "[3 rows x 35 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading training_set_features\n",
    "df_features = pd.read_csv(\"./Resources/training_set_features.csv\", index_col = \"respondent_id\")\n",
    "df_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b35fc6d7-fc60-431a-809a-c8d608512ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1n1_vaccine</th>\n",
       "      <th>seasonal_vaccine</th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>...</th>\n",
       "      <th>income_poverty</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>rent_or_own</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>census_msa</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "      <th>employment_industry</th>\n",
       "      <th>employment_occupation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respondent_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>oxchjgsf</td>\n",
       "      <td>Non-MSA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Employed</td>\n",
       "      <td>bhuqouqj</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pxcmvdjn</td>\n",
       "      <td>xgwztkwe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rucpziij</td>\n",
       "      <td>xtkaffoo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               h1n1_vaccine  seasonal_vaccine  h1n1_concern  h1n1_knowledge  \\\n",
       "respondent_id                                                                 \n",
       "0                         0                 0           1.0             0.0   \n",
       "1                         0                 1           3.0             2.0   \n",
       "2                         0                 0           1.0             1.0   \n",
       "\n",
       "               behavioral_antiviral_meds  behavioral_avoidance  \\\n",
       "respondent_id                                                    \n",
       "0                                    0.0                   0.0   \n",
       "1                                    0.0                   1.0   \n",
       "2                                    0.0                   1.0   \n",
       "\n",
       "               behavioral_face_mask  behavioral_wash_hands  \\\n",
       "respondent_id                                                \n",
       "0                               0.0                    0.0   \n",
       "1                               0.0                    1.0   \n",
       "2                               0.0                    0.0   \n",
       "\n",
       "               behavioral_large_gatherings  behavioral_outside_home  ...  \\\n",
       "respondent_id                                                        ...   \n",
       "0                                      0.0                      1.0  ...   \n",
       "1                                      0.0                      1.0  ...   \n",
       "2                                      0.0                      0.0  ...   \n",
       "\n",
       "                          income_poverty  marital_status  rent_or_own  \\\n",
       "respondent_id                                                           \n",
       "0                          Below Poverty     Not Married          Own   \n",
       "1                          Below Poverty     Not Married         Rent   \n",
       "2              <= $75,000, Above Poverty     Not Married          Own   \n",
       "\n",
       "                employment_status  hhs_geo_region                census_msa  \\\n",
       "respondent_id                                                                 \n",
       "0              Not in Labor Force        oxchjgsf                   Non-MSA   \n",
       "1                        Employed        bhuqouqj  MSA, Not Principle  City   \n",
       "2                        Employed        qufhixun  MSA, Not Principle  City   \n",
       "\n",
       "               household_adults  household_children  employment_industry  \\\n",
       "respondent_id                                                              \n",
       "0                           0.0                 0.0                  NaN   \n",
       "1                           0.0                 0.0             pxcmvdjn   \n",
       "2                           2.0                 0.0             rucpziij   \n",
       "\n",
       "               employment_occupation  \n",
       "respondent_id                         \n",
       "0                                NaN  \n",
       "1                           xgwztkwe  \n",
       "2                           xtkaffoo  \n",
       "\n",
       "[3 rows x 37 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine both dataframes into a single dataframe\n",
    "df_vaccine = pd.concat([df_labels,df_features],axis = 1)\n",
    "df_vaccine.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0dec164b-bb89-414e-b24a-798c66cecdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['h1n1_vaccine', 'h1n1_concern', 'h1n1_knowledge', 'doctor_recc_h1n1',\n",
       "       'opinion_h1n1_vacc_effective', 'opinion_h1n1_risk',\n",
       "       'opinion_h1n1_sick_from_vacc'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#identify h1n1 specific columns\n",
    "h1n1 = df_vaccine.filter(like = \"h1n1\").columns\n",
    "display(h1n1)\n",
    "\n",
    "#drop h1n1 specific data\n",
    "df_vaccine.drop(columns = h1n1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "57589cb1-6e3e-43c2-a32a-139c3ff5128e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seasonal_vaccine                   0\n",
       "behavioral_antiviral_meds         71\n",
       "behavioral_avoidance             208\n",
       "behavioral_face_mask              19\n",
       "behavioral_wash_hands             42\n",
       "behavioral_large_gatherings       87\n",
       "behavioral_outside_home           82\n",
       "behavioral_touch_face            128\n",
       "doctor_recc_seasonal            2160\n",
       "chronic_med_condition            971\n",
       "child_under_6_months             820\n",
       "health_worker                    804\n",
       "health_insurance               12274\n",
       "opinion_seas_vacc_effective      462\n",
       "opinion_seas_risk                514\n",
       "opinion_seas_sick_from_vacc      537\n",
       "age_group                          0\n",
       "education                       1407\n",
       "race                               0\n",
       "sex                                0\n",
       "income_poverty                  4423\n",
       "marital_status                  1408\n",
       "rent_or_own                     2042\n",
       "employment_status               1463\n",
       "hhs_geo_region                     0\n",
       "census_msa                         0\n",
       "household_adults                 249\n",
       "household_children               249\n",
       "employment_industry            13330\n",
       "employment_occupation          13470\n",
       "dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for missing values\n",
    "df_vaccine.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "97687ce8-fbda-43fb-88b2-0121b909f02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns with more than 40% missing value\n",
    "df_vaccine.drop(columns = [\"health_insurance\",\"employment_industry\",\"employment_occupation\"], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "802bdaf9-bdd3-4c6b-89b1-c4dae84c38bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 26707 entries, 0 to 26706\n",
      "Data columns (total 27 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   seasonal_vaccine             26707 non-null  int64  \n",
      " 1   behavioral_antiviral_meds    26636 non-null  float64\n",
      " 2   behavioral_avoidance         26499 non-null  float64\n",
      " 3   behavioral_face_mask         26688 non-null  float64\n",
      " 4   behavioral_wash_hands        26665 non-null  float64\n",
      " 5   behavioral_large_gatherings  26620 non-null  float64\n",
      " 6   behavioral_outside_home      26625 non-null  float64\n",
      " 7   behavioral_touch_face        26579 non-null  float64\n",
      " 8   doctor_recc_seasonal         24547 non-null  float64\n",
      " 9   chronic_med_condition        25736 non-null  float64\n",
      " 10  child_under_6_months         25887 non-null  float64\n",
      " 11  health_worker                25903 non-null  float64\n",
      " 12  opinion_seas_vacc_effective  26245 non-null  float64\n",
      " 13  opinion_seas_risk            26193 non-null  float64\n",
      " 14  opinion_seas_sick_from_vacc  26170 non-null  float64\n",
      " 15  age_group                    26707 non-null  object \n",
      " 16  education                    25300 non-null  object \n",
      " 17  race                         26707 non-null  object \n",
      " 18  sex                          26707 non-null  object \n",
      " 19  income_poverty               22284 non-null  object \n",
      " 20  marital_status               25299 non-null  object \n",
      " 21  rent_or_own                  24665 non-null  object \n",
      " 22  employment_status            25244 non-null  object \n",
      " 23  hhs_geo_region               26707 non-null  object \n",
      " 24  census_msa                   26707 non-null  object \n",
      " 25  household_adults             26458 non-null  float64\n",
      " 26  household_children           26458 non-null  float64\n",
      "dtypes: float64(16), int64(1), object(10)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_vaccine.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd54884-6921-41f9-8667-aa40398e0d35",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "**Review the DataFrame, looking for categorical variables that will need to be encoded, as well as columns that could eventually define your features and target variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "65d5c155-d886-4ebe-902c-a98be4e5b705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>doctor_recc_seasonal</th>\n",
       "      <th>chronic_med_condition</th>\n",
       "      <th>child_under_6_months</th>\n",
       "      <th>...</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>income_poverty</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>rent_or_own</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>census_msa</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>respondent_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>oxchjgsf</td>\n",
       "      <td>Non-MSA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Employed</td>\n",
       "      <td>bhuqouqj</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               behavioral_antiviral_meds  behavioral_avoidance  \\\n",
       "respondent_id                                                    \n",
       "0                                    0.0                   0.0   \n",
       "1                                    0.0                   1.0   \n",
       "2                                    0.0                   1.0   \n",
       "\n",
       "               behavioral_face_mask  behavioral_wash_hands  \\\n",
       "respondent_id                                                \n",
       "0                               0.0                    0.0   \n",
       "1                               0.0                    1.0   \n",
       "2                               0.0                    0.0   \n",
       "\n",
       "               behavioral_large_gatherings  behavioral_outside_home  \\\n",
       "respondent_id                                                         \n",
       "0                                      0.0                      1.0   \n",
       "1                                      0.0                      1.0   \n",
       "2                                      0.0                      0.0   \n",
       "\n",
       "               behavioral_touch_face  doctor_recc_seasonal  \\\n",
       "respondent_id                                                \n",
       "0                                1.0                   0.0   \n",
       "1                                1.0                   0.0   \n",
       "2                                0.0                   NaN   \n",
       "\n",
       "               chronic_med_condition  child_under_6_months  ...   race  \\\n",
       "respondent_id                                               ...          \n",
       "0                                0.0                   0.0  ...  White   \n",
       "1                                0.0                   0.0  ...  White   \n",
       "2                                1.0                   0.0  ...  White   \n",
       "\n",
       "                  sex             income_poverty  marital_status rent_or_own  \\\n",
       "respondent_id                                                                  \n",
       "0              Female              Below Poverty     Not Married         Own   \n",
       "1                Male              Below Poverty     Not Married        Rent   \n",
       "2                Male  <= $75,000, Above Poverty     Not Married         Own   \n",
       "\n",
       "                employment_status hhs_geo_region                census_msa  \\\n",
       "respondent_id                                                                \n",
       "0              Not in Labor Force       oxchjgsf                   Non-MSA   \n",
       "1                        Employed       bhuqouqj  MSA, Not Principle  City   \n",
       "2                        Employed       qufhixun  MSA, Not Principle  City   \n",
       "\n",
       "              household_adults household_children  \n",
       "respondent_id                                      \n",
       "0                          0.0                0.0  \n",
       "1                          0.0                0.0  \n",
       "2                          2.0                0.0  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features = df_vaccine.drop(columns = [\"seasonal_vaccine\"]).copy()\n",
    "df_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "75142b68-fe0b-4620-ab7b-f03cf12c922d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['behavioral_antiviral_meds',\n",
       " 'behavioral_avoidance',\n",
       " 'behavioral_face_mask',\n",
       " 'behavioral_wash_hands',\n",
       " 'behavioral_large_gatherings',\n",
       " 'behavioral_outside_home',\n",
       " 'behavioral_touch_face',\n",
       " 'doctor_recc_seasonal',\n",
       " 'chronic_med_condition',\n",
       " 'child_under_6_months',\n",
       " 'health_worker',\n",
       " 'opinion_seas_vacc_effective',\n",
       " 'opinion_seas_risk',\n",
       " 'opinion_seas_sick_from_vacc',\n",
       " 'household_adults',\n",
       " 'household_children']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and display the list of numerical variables \n",
    "numerical_variables = list(df_features.dtypes[df_features.dtypes != \"object\"].index)\n",
    "numerical_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "24fe41d7-57e5-4c20-adfc-5b2b03056dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age_group',\n",
       " 'education',\n",
       " 'race',\n",
       " 'sex',\n",
       " 'income_poverty',\n",
       " 'marital_status',\n",
       " 'rent_or_own',\n",
       " 'employment_status',\n",
       " 'hhs_geo_region',\n",
       " 'census_msa']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of categorical variables \n",
    "categorical_variables = list(df_features.dtypes[df_features.dtypes == \"object\"].index)\n",
    "\n",
    "# Display the categorical variables list\n",
    "categorical_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48f961a-31e2-48b5-8c0e-3d4d4b41ae7d",
   "metadata": {},
   "source": [
    "**Replacing missing values with most frequent value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6ee56d1a-db52-4f2c-b806-2b8d39791e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define strategy for replacing missing values\n",
    "imp_mostfreq = SimpleImputer(strategy = \"most_frequent\", missing_values = np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c3caaa29-a0fc-4bdd-8380-6f333a09859e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>behavioral_antiviral_meds</th>\n",
       "      <th>behavioral_avoidance</th>\n",
       "      <th>behavioral_face_mask</th>\n",
       "      <th>behavioral_wash_hands</th>\n",
       "      <th>behavioral_large_gatherings</th>\n",
       "      <th>behavioral_outside_home</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>doctor_recc_seasonal</th>\n",
       "      <th>chronic_med_condition</th>\n",
       "      <th>child_under_6_months</th>\n",
       "      <th>health_worker</th>\n",
       "      <th>opinion_seas_vacc_effective</th>\n",
       "      <th>opinion_seas_risk</th>\n",
       "      <th>opinion_seas_sick_from_vacc</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   behavioral_antiviral_meds  behavioral_avoidance  behavioral_face_mask  \\\n",
       "0                        0.0                   0.0                   0.0   \n",
       "1                        0.0                   1.0                   0.0   \n",
       "2                        0.0                   1.0                   0.0   \n",
       "3                        0.0                   1.0                   0.0   \n",
       "4                        0.0                   1.0                   0.0   \n",
       "\n",
       "   behavioral_wash_hands  behavioral_large_gatherings  \\\n",
       "0                    0.0                          0.0   \n",
       "1                    1.0                          0.0   \n",
       "2                    0.0                          0.0   \n",
       "3                    1.0                          1.0   \n",
       "4                    1.0                          1.0   \n",
       "\n",
       "   behavioral_outside_home  behavioral_touch_face  doctor_recc_seasonal  \\\n",
       "0                      1.0                    1.0                   0.0   \n",
       "1                      1.0                    1.0                   0.0   \n",
       "2                      0.0                    0.0                   0.0   \n",
       "3                      0.0                    0.0                   1.0   \n",
       "4                      0.0                    1.0                   0.0   \n",
       "\n",
       "   chronic_med_condition  child_under_6_months  health_worker  \\\n",
       "0                    0.0                   0.0            0.0   \n",
       "1                    0.0                   0.0            0.0   \n",
       "2                    1.0                   0.0            0.0   \n",
       "3                    1.0                   0.0            0.0   \n",
       "4                    0.0                   0.0            0.0   \n",
       "\n",
       "   opinion_seas_vacc_effective  opinion_seas_risk  \\\n",
       "0                          2.0                1.0   \n",
       "1                          4.0                2.0   \n",
       "2                          4.0                1.0   \n",
       "3                          5.0                4.0   \n",
       "4                          3.0                1.0   \n",
       "\n",
       "   opinion_seas_sick_from_vacc  household_adults  household_children  \n",
       "0                          2.0               0.0                 0.0  \n",
       "1                          4.0               0.0                 0.0  \n",
       "2                          2.0               2.0                 0.0  \n",
       "3                          1.0               0.0                 0.0  \n",
       "4                          4.0               1.0                 0.0  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replacing missing values\n",
    "df_numerical_variables_imputed = pd.DataFrame(imp_mostfreq.fit_transform(df_features[numerical_variables].loc[:,:]),\n",
    "                                   columns = df_features[numerical_variables].columns)\n",
    "\n",
    "df_numerical_variables_imputed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d755f946-858e-4a15-9487-be56eb6d3dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_group</th>\n",
       "      <th>education</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>income_poverty</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>rent_or_own</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>hhs_geo_region</th>\n",
       "      <th>census_msa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>55 - 64 Years</td>\n",
       "      <td>&lt; 12 Years</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>oxchjgsf</td>\n",
       "      <td>Non-MSA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35 - 44 Years</td>\n",
       "      <td>12 Years</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Employed</td>\n",
       "      <td>bhuqouqj</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18 - 34 Years</td>\n",
       "      <td>College Graduate</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65+ Years</td>\n",
       "      <td>12 Years</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Below Poverty</td>\n",
       "      <td>Not Married</td>\n",
       "      <td>Rent</td>\n",
       "      <td>Not in Labor Force</td>\n",
       "      <td>lrircsnp</td>\n",
       "      <td>MSA, Principle City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45 - 54 Years</td>\n",
       "      <td>Some College</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>&lt;= $75,000, Above Poverty</td>\n",
       "      <td>Married</td>\n",
       "      <td>Own</td>\n",
       "      <td>Employed</td>\n",
       "      <td>qufhixun</td>\n",
       "      <td>MSA, Not Principle  City</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age_group         education   race     sex             income_poverty  \\\n",
       "0  55 - 64 Years        < 12 Years  White  Female              Below Poverty   \n",
       "1  35 - 44 Years          12 Years  White    Male              Below Poverty   \n",
       "2  18 - 34 Years  College Graduate  White    Male  <= $75,000, Above Poverty   \n",
       "3      65+ Years          12 Years  White  Female              Below Poverty   \n",
       "4  45 - 54 Years      Some College  White  Female  <= $75,000, Above Poverty   \n",
       "\n",
       "  marital_status rent_or_own   employment_status hhs_geo_region  \\\n",
       "0    Not Married         Own  Not in Labor Force       oxchjgsf   \n",
       "1    Not Married        Rent            Employed       bhuqouqj   \n",
       "2    Not Married         Own            Employed       qufhixun   \n",
       "3    Not Married        Rent  Not in Labor Force       lrircsnp   \n",
       "4        Married         Own            Employed       qufhixun   \n",
       "\n",
       "                 census_msa  \n",
       "0                   Non-MSA  \n",
       "1  MSA, Not Principle  City  \n",
       "2  MSA, Not Principle  City  \n",
       "3       MSA, Principle City  \n",
       "4  MSA, Not Principle  City  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replacing missing values\n",
    "df_categorical_variables_imputed = pd.DataFrame(imp_mostfreq.fit_transform(df_features[categorical_variables].loc[:,:]),\n",
    "                                   columns = df_features[categorical_variables].columns)\n",
    "\n",
    "df_categorical_variables_imputed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d8f91d-7066-4813-a5bf-bac4048a8561",
   "metadata": {},
   "source": [
    "**Encode the dataset’s categorical variables using OneHotEncoder, and then place the encoded variables into a new DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "70c8d48e-1105-4f3f-8962-a10f17139b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ac9da98a-64c5-44e5-a729-9b749132ff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorcal variables using OneHotEncoder\n",
    "encoded_data = enc.fit_transform(df_categorical_variables_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c79b16b8-fa5c-4c1a-b658-7d84c309f5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_group_18 - 34 Years</th>\n",
       "      <th>age_group_35 - 44 Years</th>\n",
       "      <th>age_group_45 - 54 Years</th>\n",
       "      <th>age_group_55 - 64 Years</th>\n",
       "      <th>age_group_65+ Years</th>\n",
       "      <th>education_12 Years</th>\n",
       "      <th>education_&lt; 12 Years</th>\n",
       "      <th>education_College Graduate</th>\n",
       "      <th>education_Some College</th>\n",
       "      <th>race_Black</th>\n",
       "      <th>...</th>\n",
       "      <th>hhs_geo_region_fpwskwrf</th>\n",
       "      <th>hhs_geo_region_kbazzjca</th>\n",
       "      <th>hhs_geo_region_lrircsnp</th>\n",
       "      <th>hhs_geo_region_lzgpxyit</th>\n",
       "      <th>hhs_geo_region_mlyzmhmf</th>\n",
       "      <th>hhs_geo_region_oxchjgsf</th>\n",
       "      <th>hhs_geo_region_qufhixun</th>\n",
       "      <th>census_msa_MSA, Not Principle  City</th>\n",
       "      <th>census_msa_MSA, Principle City</th>\n",
       "      <th>census_msa_Non-MSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_group_18 - 34 Years  age_group_35 - 44 Years  age_group_45 - 54 Years  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      1.0                      0.0   \n",
       "2                      1.0                      0.0                      0.0   \n",
       "3                      0.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      1.0   \n",
       "\n",
       "   age_group_55 - 64 Years  age_group_65+ Years  education_12 Years  \\\n",
       "0                      1.0                  0.0                 0.0   \n",
       "1                      0.0                  0.0                 1.0   \n",
       "2                      0.0                  0.0                 0.0   \n",
       "3                      0.0                  1.0                 1.0   \n",
       "4                      0.0                  0.0                 0.0   \n",
       "\n",
       "   education_< 12 Years  education_College Graduate  education_Some College  \\\n",
       "0                   1.0                         0.0                     0.0   \n",
       "1                   0.0                         0.0                     0.0   \n",
       "2                   0.0                         1.0                     0.0   \n",
       "3                   0.0                         0.0                     0.0   \n",
       "4                   0.0                         0.0                     1.0   \n",
       "\n",
       "   race_Black  ...  hhs_geo_region_fpwskwrf  hhs_geo_region_kbazzjca  \\\n",
       "0         0.0  ...                      0.0                      0.0   \n",
       "1         0.0  ...                      0.0                      0.0   \n",
       "2         0.0  ...                      0.0                      0.0   \n",
       "3         0.0  ...                      0.0                      0.0   \n",
       "4         0.0  ...                      0.0                      0.0   \n",
       "\n",
       "   hhs_geo_region_lrircsnp  hhs_geo_region_lzgpxyit  hhs_geo_region_mlyzmhmf  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                      1.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   hhs_geo_region_oxchjgsf  hhs_geo_region_qufhixun  \\\n",
       "0                      1.0                      0.0   \n",
       "1                      0.0                      0.0   \n",
       "2                      0.0                      1.0   \n",
       "3                      0.0                      0.0   \n",
       "4                      0.0                      1.0   \n",
       "\n",
       "   census_msa_MSA, Not Principle  City  census_msa_MSA, Principle City  \\\n",
       "0                                  0.0                             0.0   \n",
       "1                                  1.0                             0.0   \n",
       "2                                  1.0                             0.0   \n",
       "3                                  0.0                             1.0   \n",
       "4                                  1.0                             0.0   \n",
       "\n",
       "   census_msa_Non-MSA  \n",
       "0                 1.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with the encoded variables\n",
    "encoded_df = pd.DataFrame(encoded_data,\n",
    "                          columns = enc.get_feature_names_out(categorical_variables)\n",
    "                         )\n",
    "\n",
    "# Review the DataFrame\n",
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bda3a3-f434-460a-9099-fbb2cf8ddc15",
   "metadata": {},
   "source": [
    "**Add the original DataFrame’s numerical variables to the DataFrame containing the encoded variables.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2cb0e826-eca4-44ea-842c-3967a0b879d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_group_18 - 34 Years</th>\n",
       "      <th>age_group_35 - 44 Years</th>\n",
       "      <th>age_group_45 - 54 Years</th>\n",
       "      <th>age_group_55 - 64 Years</th>\n",
       "      <th>age_group_65+ Years</th>\n",
       "      <th>education_12 Years</th>\n",
       "      <th>education_&lt; 12 Years</th>\n",
       "      <th>education_College Graduate</th>\n",
       "      <th>education_Some College</th>\n",
       "      <th>race_Black</th>\n",
       "      <th>...</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>doctor_recc_seasonal</th>\n",
       "      <th>chronic_med_condition</th>\n",
       "      <th>child_under_6_months</th>\n",
       "      <th>health_worker</th>\n",
       "      <th>opinion_seas_vacc_effective</th>\n",
       "      <th>opinion_seas_risk</th>\n",
       "      <th>opinion_seas_sick_from_vacc</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_group_18 - 34 Years  age_group_35 - 44 Years  age_group_45 - 54 Years  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      1.0                      0.0   \n",
       "2                      1.0                      0.0                      0.0   \n",
       "\n",
       "   age_group_55 - 64 Years  age_group_65+ Years  education_12 Years  \\\n",
       "0                      1.0                  0.0                 0.0   \n",
       "1                      0.0                  0.0                 1.0   \n",
       "2                      0.0                  0.0                 0.0   \n",
       "\n",
       "   education_< 12 Years  education_College Graduate  education_Some College  \\\n",
       "0                   1.0                         0.0                     0.0   \n",
       "1                   0.0                         0.0                     0.0   \n",
       "2                   0.0                         1.0                     0.0   \n",
       "\n",
       "   race_Black  ...  behavioral_touch_face  doctor_recc_seasonal  \\\n",
       "0         0.0  ...                    1.0                   0.0   \n",
       "1         0.0  ...                    1.0                   0.0   \n",
       "2         0.0  ...                    0.0                   0.0   \n",
       "\n",
       "   chronic_med_condition  child_under_6_months  health_worker  \\\n",
       "0                    0.0                   0.0            0.0   \n",
       "1                    0.0                   0.0            0.0   \n",
       "2                    1.0                   0.0            0.0   \n",
       "\n",
       "   opinion_seas_vacc_effective  opinion_seas_risk  \\\n",
       "0                          2.0                1.0   \n",
       "1                          4.0                2.0   \n",
       "2                          4.0                1.0   \n",
       "\n",
       "   opinion_seas_sick_from_vacc  household_adults  household_children  \n",
       "0                          2.0               0.0                 0.0  \n",
       "1                          4.0               0.0                 0.0  \n",
       "2                          2.0               2.0                 0.0  \n",
       "\n",
       "[3 rows x 54 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the numerical variables from the original DataFrame to the one-hot encoding DataFrame\n",
    "encoded_df = pd.concat([encoded_df, df_numerical_variables_imputed], axis = 1)\n",
    "\n",
    "# Review the Dataframe\n",
    "encoded_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decf9fbc-f5c7-45d2-bb80-b93db2981242",
   "metadata": {},
   "source": [
    "**Define features and target variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f2650790-dac5-4458-93fd-5dea69eb71da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_group_18 - 34 Years</th>\n",
       "      <th>age_group_35 - 44 Years</th>\n",
       "      <th>age_group_45 - 54 Years</th>\n",
       "      <th>age_group_55 - 64 Years</th>\n",
       "      <th>age_group_65+ Years</th>\n",
       "      <th>education_12 Years</th>\n",
       "      <th>education_&lt; 12 Years</th>\n",
       "      <th>education_College Graduate</th>\n",
       "      <th>education_Some College</th>\n",
       "      <th>race_Black</th>\n",
       "      <th>...</th>\n",
       "      <th>behavioral_touch_face</th>\n",
       "      <th>doctor_recc_seasonal</th>\n",
       "      <th>chronic_med_condition</th>\n",
       "      <th>child_under_6_months</th>\n",
       "      <th>health_worker</th>\n",
       "      <th>opinion_seas_vacc_effective</th>\n",
       "      <th>opinion_seas_risk</th>\n",
       "      <th>opinion_seas_sick_from_vacc</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_group_18 - 34 Years  age_group_35 - 44 Years  age_group_45 - 54 Years  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      1.0                      0.0   \n",
       "2                      1.0                      0.0                      0.0   \n",
       "3                      0.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      1.0   \n",
       "\n",
       "   age_group_55 - 64 Years  age_group_65+ Years  education_12 Years  \\\n",
       "0                      1.0                  0.0                 0.0   \n",
       "1                      0.0                  0.0                 1.0   \n",
       "2                      0.0                  0.0                 0.0   \n",
       "3                      0.0                  1.0                 1.0   \n",
       "4                      0.0                  0.0                 0.0   \n",
       "\n",
       "   education_< 12 Years  education_College Graduate  education_Some College  \\\n",
       "0                   1.0                         0.0                     0.0   \n",
       "1                   0.0                         0.0                     0.0   \n",
       "2                   0.0                         1.0                     0.0   \n",
       "3                   0.0                         0.0                     0.0   \n",
       "4                   0.0                         0.0                     1.0   \n",
       "\n",
       "   race_Black  ...  behavioral_touch_face  doctor_recc_seasonal  \\\n",
       "0         0.0  ...                    1.0                   0.0   \n",
       "1         0.0  ...                    1.0                   0.0   \n",
       "2         0.0  ...                    0.0                   0.0   \n",
       "3         0.0  ...                    0.0                   1.0   \n",
       "4         0.0  ...                    1.0                   0.0   \n",
       "\n",
       "   chronic_med_condition  child_under_6_months  health_worker  \\\n",
       "0                    0.0                   0.0            0.0   \n",
       "1                    0.0                   0.0            0.0   \n",
       "2                    1.0                   0.0            0.0   \n",
       "3                    1.0                   0.0            0.0   \n",
       "4                    0.0                   0.0            0.0   \n",
       "\n",
       "   opinion_seas_vacc_effective  opinion_seas_risk  \\\n",
       "0                          2.0                1.0   \n",
       "1                          4.0                2.0   \n",
       "2                          4.0                1.0   \n",
       "3                          5.0                4.0   \n",
       "4                          3.0                1.0   \n",
       "\n",
       "   opinion_seas_sick_from_vacc  household_adults  household_children  \n",
       "0                          2.0               0.0                 0.0  \n",
       "1                          4.0               0.0                 0.0  \n",
       "2                          2.0               2.0                 0.0  \n",
       "3                          1.0               0.0                 0.0  \n",
       "4                          4.0               1.0                 0.0  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define features set X\n",
    "X = encoded_df.copy()\n",
    "\n",
    "# Review the features DataFrame\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "778da008-0bcd-4d10-a342-69cc6366aa46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "respondent_id\n",
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    1\n",
       "4    0\n",
       "Name: seasonal_vaccine, dtype: int64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define target variable y\n",
    "y = df_vaccine[\"seasonal_vaccine\"].copy()\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "cca7a3a5-d025-4aab-a392-f45b04bfd412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    14272\n",
       "1    12435\n",
       "Name: seasonal_vaccine, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cabdfc-bf2f-4345-aea8-dc0151b7bbda",
   "metadata": {},
   "source": [
    "**Split dataset into training and testing dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "d08be692-2c27-4942-9e2b-20c05f013dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training, validation, and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b6bb3b1b-dbc2-4f0a-9a52-b3e89caa7b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c844dee6-768f-4358-a9d9-0d23db53753f",
   "metadata": {},
   "source": [
    "## Build and Train Machine Learning Models\n",
    "Three models are considered:\n",
    "1. Support vector classifier model\n",
    "2. Random forest classifier model\n",
    "3. Deep learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac5de1a-b232-4d08-8800-e073d27bb454",
   "metadata": {},
   "source": [
    "### 3. Deep learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6542dfe-d252-4c99-9b60-2c03f94b1bfc",
   "metadata": {},
   "source": [
    "#### Possible optimizers for a binary classifier deep learning model:\n",
    "\n",
    "1. Stochastic Gradient Decent (SGD) - SGD is a simple and efficient optimizer that is easy to implement, but it can be sensitive to the learning rate.\n",
    "\n",
    "2. Adam - Adam is an adaptive optimization algorithm that combines the ideas of momentum and learning rate decay, which can help it converge more quickly to the optimal solution.\n",
    "\n",
    "3. RMSprop - RMSprop is another adaptive optimization algorithm that uses moving averages of the parameters to scale the learning rate, which can help it converge more quickly to the optimal solution.\n",
    "\n",
    "4. Adagrad - Adagrad is an optimization algorithm that adapts the learning rate to the parameters, with larger updates for infrequent and smaller updates for frequent parameters.\n",
    "\n",
    "#### Possible activation functions for binary classifier deep learning models:\n",
    "\n",
    "1. ReLU (Rectified Linear Unit) - ReLU is a simple activation function that replaces all negative values in the input with zero, while leaving positive values unchanged. It is fast to compute and has been found to work well in a wide range of deep learning models.\n",
    "\n",
    "2. Sigmoid - The sigmoid function maps any input to a value between 0 and 1, which makes it useful for predicting probabilities. However, it can cause the gradients of the model to vanish when the values are too large or too small, which can slow down training.\n",
    "\n",
    "3. Tanh - The tanh function is similar to the sigmoid function, but it maps the input to values between -1 and 1. It has a stronger gradient than the sigmoid function, which can allow it to converge faster to the optimal solution.\n",
    "\n",
    "4. Softmax - The softmax function is often used as the activation function in the output layer of a multi-class classifier. It converts a set of scores into a probability distribution, such that the sum of all the probabilities is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541f517d-b7e7-4199-b0cc-76ac1613ae14",
   "metadata": {},
   "source": [
    "#### 3. i) - (Baseline) Deep learning model using:\n",
    "**Input Features:** 54<br>\n",
    "**Output Neuron(s):** 1<br>\n",
    "**Loss:** Binary Crossentropy<br>\n",
    "**Optimizer:** Adam<br>\n",
    "**Metrics:** Accuracy<br>\n",
    "**Epochs:** 50<br>\n",
    "> *Layer 1*<br>\n",
    "**Hidden Nodes:** 27<br>\n",
    "**Activation Function:** ReLu<br>\n",
    "\n",
    "> *Layer 2*<br>\n",
    "**Hidden Nodes:** 14<br>\n",
    "**Activation Function:** ReLu<br>\n",
    "\n",
    "> *Output Layer*<br>\n",
    "**Activation Function:** Sigmoid<br>\n",
    "\n",
    "**Baseline AUC Score:** 0.7526832556204512 [~0.7527]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aae4f339-6d66-412b-a8cd-1935e76c7c04",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features = len(X_train.iloc[0])\n",
    "\n",
    "# Review the number of features\n",
    "number_input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4fe7e40e-8fd3-4bf0-8ced-330fbc4b84a5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the number of neurons in the output layer\n",
    "number_output_neurons = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3b368b71-ce5c-46ad-b866-924c4a4a5610",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the first hidden layer\n",
    "hidden_nodes_layer1 = (number_input_features + 1)//2\n",
    "\n",
    "# Review the number hidden nodes in the first layer\n",
    "hidden_nodes_layer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "37304c43-29f1-4065-8043-27a4af7eae26",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the second hidden layer\n",
    "hidden_nodes_layer2 = (hidden_nodes_layer1 + 1)//2\n",
    "\n",
    "# Review the number hidden nodes in the second layer\n",
    "hidden_nodes_layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dd3162ab-5771-43dc-9efa-b1959e59797c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the Sequential model instance\n",
    "nn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c1ac53a3-c7b9-4ba9-9e72-20640d62d240",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add the first hidden layer\n",
    "nn.add(Dense(units = hidden_nodes_layer1, activation = \"relu\", input_dim = number_input_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "18a00971-edd8-4814-917f-f34d05cd777e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add the second hidden layer\n",
    "nn.add(Dense(units = hidden_nodes_layer2, activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b39f53ac-8baf-40c0-9007-328b24000167",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn.add(Dense(units = number_output_neurons, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c386ac74-8750-41d0-8f44-5521c21bc580",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 27)                1485      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 14)                392       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,892\n",
      "Trainable params: 1,892\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Display the Sequential model summary\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "14bf16ce-35f1-4309-8b26-c13dc793b1bc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics =[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ad5e8359-f4d6-44c8-854f-2a2d998e4b6e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "626/626 [==============================] - 3s 2ms/step - loss: 0.5462 - accuracy: 0.7215\n",
      "Epoch 2/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4839 - accuracy: 0.7738\n",
      "Epoch 3/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4768 - accuracy: 0.7790\n",
      "Epoch 4/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4717 - accuracy: 0.7816\n",
      "Epoch 5/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4694 - accuracy: 0.7826\n",
      "Epoch 6/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4663 - accuracy: 0.7836\n",
      "Epoch 7/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4638 - accuracy: 0.7855\n",
      "Epoch 8/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4617 - accuracy: 0.7878\n",
      "Epoch 9/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4593 - accuracy: 0.7878\n",
      "Epoch 10/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4574 - accuracy: 0.7884\n",
      "Epoch 11/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4566 - accuracy: 0.7903\n",
      "Epoch 12/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4544 - accuracy: 0.7907\n",
      "Epoch 13/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4527 - accuracy: 0.7911\n",
      "Epoch 14/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4509 - accuracy: 0.7939\n",
      "Epoch 15/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4498 - accuracy: 0.7937\n",
      "Epoch 16/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4479 - accuracy: 0.7941\n",
      "Epoch 17/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4467 - accuracy: 0.7944\n",
      "Epoch 18/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4458 - accuracy: 0.7976\n",
      "Epoch 19/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4441 - accuracy: 0.7968\n",
      "Epoch 20/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4431 - accuracy: 0.7979\n",
      "Epoch 21/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4413 - accuracy: 0.7984\n",
      "Epoch 22/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4397 - accuracy: 0.7992\n",
      "Epoch 23/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4387 - accuracy: 0.7996\n",
      "Epoch 24/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4381 - accuracy: 0.7999\n",
      "Epoch 25/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4364 - accuracy: 0.8002\n",
      "Epoch 26/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4358 - accuracy: 0.8003\n",
      "Epoch 27/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4350 - accuracy: 0.8008\n",
      "Epoch 28/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4342 - accuracy: 0.8018\n",
      "Epoch 29/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4327 - accuracy: 0.8022\n",
      "Epoch 30/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4321 - accuracy: 0.8023\n",
      "Epoch 31/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4311 - accuracy: 0.8032\n",
      "Epoch 32/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4305 - accuracy: 0.8023\n",
      "Epoch 33/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4291 - accuracy: 0.8030\n",
      "Epoch 34/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4286 - accuracy: 0.8037\n",
      "Epoch 35/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4278 - accuracy: 0.8043\n",
      "Epoch 36/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4280 - accuracy: 0.8060\n",
      "Epoch 37/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4266 - accuracy: 0.8047\n",
      "Epoch 38/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4258 - accuracy: 0.8062\n",
      "Epoch 39/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4257 - accuracy: 0.8048\n",
      "Epoch 40/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4250 - accuracy: 0.8063\n",
      "Epoch 41/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4245 - accuracy: 0.8071\n",
      "Epoch 42/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4240 - accuracy: 0.8069\n",
      "Epoch 43/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4236 - accuracy: 0.8074\n",
      "Epoch 44/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4228 - accuracy: 0.8064\n",
      "Epoch 45/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4226 - accuracy: 0.8077\n",
      "Epoch 46/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4221 - accuracy: 0.8081\n",
      "Epoch 47/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4213 - accuracy: 0.8079\n",
      "Epoch 48/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4213 - accuracy: 0.8087\n",
      "Epoch 49/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4203 - accuracy: 0.8088\n",
      "Epoch 50/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4205 - accuracy: 0.8085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x173c046c100>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "nn.fit(X_train_scaled, y_train, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "725becc1-24c3-481f-bb26-3b43f4cd6da8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the testing data to make the model predictions\n",
    "y_pred_nn = (nn.predict(X_test_scaled) > 0.5).astype(\"int64\")\n",
    "\n",
    "# Review the model's predicted values\n",
    "y_pred_nn[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1de70b4c-fbf3-45af-a020-336c1a85de99",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.77      3540\n",
      "           1       0.73      0.75      0.74      3137\n",
      "\n",
      "    accuracy                           0.75      6677\n",
      "   macro avg       0.75      0.75      0.75      6677\n",
      "weighted avg       0.75      0.75      0.75      6677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "testing_report_nn = classification_report(y_test, y_pred_nn)\n",
    "print(testing_report_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bbb673dd-1ae0-4160-a1fe-08f8872bc5ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7593020878920989"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7632426623010576"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7526832556204512"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compare roc_auc_score\n",
    "display(roc_auc_score(y_test, y_pred_svm))\n",
    "display(roc_auc_score(y_test, y_pred_rf))\n",
    "display(roc_auc_score(y_test, y_pred_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "80666d39-b47e-4d5f-b3ae-f4db69bcac2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define a function to plot roc_curve\n",
    "def plot_roc(y_true, y_score, label_name, ax):\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "    ax.plot(fpr, tpr)\n",
    "    ax.plot([0, 1], [0, 1], color='grey', linestyle='--')\n",
    "    ax.set_ylabel('TPR')\n",
    "    ax.set_xlabel('FPR')\n",
    "    ax.set_title(\n",
    "        f\"{label_name}: AUC = {roc_auc_score(y_true, y_score):.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9058a3b4-a420-41a9-b837-09cab00ad943",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot roc_curve for each model\n",
    "fig, ax = plt.subplots(1, 3, figsize = (12,4))\n",
    "\n",
    "plot_roc(y_test, y_pred_svm, \"Model 1 SVM\", ax=ax[0])\n",
    "plot_roc(y_test, y_pred_rf, \"Model 2 RFM\", ax=ax[1])\n",
    "plot_roc(y_test, y_pred_nn, \"Model 3 DLM\", ax=ax[2])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32851a8-cc35-40cc-9182-b340ae06fb3a",
   "metadata": {},
   "source": [
    "### Fine-Tuning the DLM - Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada4c13d-4c0d-4fe8-9fef-e0e827a38a33",
   "metadata": {},
   "source": [
    "#### 3. ii) - (1st Trial) Deep learning model using:\n",
    "\n",
    "**Input Features:** 54<br>\n",
    "**Output Neuron(s):** 1<br>\n",
    "**Loss:** Binary Crossentropy<br>\n",
    "**Optimizer:** Adam<br>\n",
    "**Metrics:** Accuracy<br>\n",
    "**Epochs:** 50<br>\n",
    "> *Layer 1*<br>\n",
    "**Hidden Nodes:** 27<br>\n",
    "**Activation Function:** ReLu<br>\n",
    "\n",
    "> *Layer 2*<br>\n",
    "**Hidden Nodes:** 14<br>\n",
    "**Activation Function:** ReLu<br>\n",
    "\n",
    "> *Output Layer*<br>\n",
    "**Activation Function:** Tanh\n",
    "\n",
    "**AUC SCORE:** 0.7487661841804308 [Decrease of ~0.004 from baseline]<br>\n",
    "**Changes from Baseline:**<br>\n",
    "Output layer activation function, Sigmoid --> Tanh<br>\n",
    "**Result:**<br>\n",
    "Decrease in AUC as compared to baseline. Better to use Sigmoid rather than Tanh as the output layer activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "70cba636-9697-41ac-bb38-a554d3e0b90e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 27)                1485      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 14)                392       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,892\n",
      "Trainable params: 1,892\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the Sequential model instance for 1st Trial\n",
    "nn_t1 = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_t1.add(Dense(units = hidden_nodes_layer1, activation = \"relu\", input_dim = number_input_features))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_t1.add(Dense(units = hidden_nodes_layer2, activation = \"relu\"))\n",
    "\n",
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn_t1.add(Dense(units = number_output_neurons, activation = \"tanh\"))\n",
    "\n",
    "# Display the Sequential model summary\n",
    "nn_t1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aa51c2b1-70ac-4fd3-9987-e88cd7834b79",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn_t1.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics =[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ee8eea2e-024f-4944-8aa3-65abc79d334b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "626/626 [==============================] - 4s 2ms/step - loss: 1.2549 - accuracy: 0.6049\n",
      "Epoch 2/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6741 - accuracy: 0.6762\n",
      "Epoch 3/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.6011 - accuracy: 0.7254\n",
      "Epoch 4/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.5613 - accuracy: 0.7499\n",
      "Epoch 5/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.5331 - accuracy: 0.7606\n",
      "Epoch 6/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5266 - accuracy: 0.7620\n",
      "Epoch 7/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5177 - accuracy: 0.7705\n",
      "Epoch 8/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5392 - accuracy: 0.7389\n",
      "Epoch 9/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5078 - accuracy: 0.7730\n",
      "Epoch 10/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4954 - accuracy: 0.7768\n",
      "Epoch 11/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4922 - accuracy: 0.7793\n",
      "Epoch 12/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4840 - accuracy: 0.7819\n",
      "Epoch 13/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4788 - accuracy: 0.7827\n",
      "Epoch 14/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4771 - accuracy: 0.7822\n",
      "Epoch 15/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4716 - accuracy: 0.7834\n",
      "Epoch 16/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4698 - accuracy: 0.7840\n",
      "Epoch 17/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4737 - accuracy: 0.7844\n",
      "Epoch 18/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4718 - accuracy: 0.7800\n",
      "Epoch 19/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4643 - accuracy: 0.7839\n",
      "Epoch 20/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4633 - accuracy: 0.7862\n",
      "Epoch 21/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4626 - accuracy: 0.7864\n",
      "Epoch 22/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4582 - accuracy: 0.7881\n",
      "Epoch 23/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4568 - accuracy: 0.7870\n",
      "Epoch 24/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4620 - accuracy: 0.7865\n",
      "Epoch 25/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4610 - accuracy: 0.7854\n",
      "Epoch 26/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4589 - accuracy: 0.7872\n",
      "Epoch 27/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4537 - accuracy: 0.7904\n",
      "Epoch 28/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4518 - accuracy: 0.7903\n",
      "Epoch 29/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4526 - accuracy: 0.7876\n",
      "Epoch 30/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4625 - accuracy: 0.7885\n",
      "Epoch 31/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4542 - accuracy: 0.7902\n",
      "Epoch 32/50\n",
      "626/626 [==============================] - 2s 4ms/step - loss: 0.4510 - accuracy: 0.7906\n",
      "Epoch 33/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4604 - accuracy: 0.7840\n",
      "Epoch 34/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4592 - accuracy: 0.7867\n",
      "Epoch 35/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4527 - accuracy: 0.7882\n",
      "Epoch 36/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4466 - accuracy: 0.7913\n",
      "Epoch 37/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4444 - accuracy: 0.7906\n",
      "Epoch 38/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4476 - accuracy: 0.7917\n",
      "Epoch 39/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4444 - accuracy: 0.7909\n",
      "Epoch 40/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4435 - accuracy: 0.7924\n",
      "Epoch 41/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4454 - accuracy: 0.7925\n",
      "Epoch 42/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4455 - accuracy: 0.7918\n",
      "Epoch 43/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4420 - accuracy: 0.7915\n",
      "Epoch 44/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4464 - accuracy: 0.7922\n",
      "Epoch 45/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4436 - accuracy: 0.7924\n",
      "Epoch 46/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4414 - accuracy: 0.7922\n",
      "Epoch 47/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4389 - accuracy: 0.7957\n",
      "Epoch 48/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4386 - accuracy: 0.7934\n",
      "Epoch 49/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4422 - accuracy: 0.7893\n",
      "Epoch 50/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4498 - accuracy: 0.7896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x173c1954040>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "nn_t1.fit(X_train_scaled, y_train, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "30870b59-0347-4ddb-9631-473b7c3610ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the testing data to make the model predictions\n",
    "y_pred_nn_t1 = (nn_t1.predict(X_test_scaled) > 0.5).astype(\"int64\")\n",
    "\n",
    "# Review the model's predicted values\n",
    "y_pred_nn_t1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "639d309b-4a4b-47bc-9bb8-0b4df4f7e3ea",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      3540\n",
      "           1       0.72      0.76      0.74      3137\n",
      "\n",
      "    accuracy                           0.75      6677\n",
      "   macro avg       0.75      0.75      0.75      6677\n",
      "weighted avg       0.75      0.75      0.75      6677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "testing_report_nn_t1 = classification_report(y_test, y_pred_nn_t1)\n",
    "print(testing_report_nn_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bb4c8df2-c854-4e00-bb2a-e118889fc7e9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7487661841804308"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#roc_auc_score\n",
    "display(roc_auc_score(y_test, y_pred_nn_t1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a579b00a-574a-4dd6-af3c-3a0ea07ce0f6",
   "metadata": {},
   "source": [
    "#### 3. iii) - (2nd Trial) Deep learning model using:\n",
    "\n",
    "**Input Features:** 54<br>\n",
    "**Output Neuron(s):** 1<br>\n",
    "**Loss:** Binary Crossentropy<br>\n",
    "**Optimizer:** SGD<br>\n",
    "**Metrics:** Accuracy<br>\n",
    "**Epochs:** 50<br>\n",
    "> *Layer 1*<br>\n",
    "**Hidden Nodes:** 27<br>\n",
    "**Activation Function:** ReLu<br>\n",
    "\n",
    "> *Layer 2*<br>\n",
    "**Hidden Nodes:** 14<br>\n",
    "**Activation Function:** ReLu<br>\n",
    "\n",
    "> *Output Layer*<br>\n",
    "**Activation Function:** Sigmoid\n",
    "\n",
    "**AUC SCORE:** 0.7594148751280957 [Increase of ~0.0067 from baseline]<br>\n",
    "**Changes from Baseline:**<br>\n",
    "Optimizer, Adam --> SGD<br>\n",
    "**Result:**<br>\n",
    "Increase in AUC as compared to baseline. Stochastic Gradient Descent appears to provide a marginal improvement to the AUC over Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e670a2e5-3f85-4344-8a91-2ad8c9e3ef25",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 27)                1485      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 14)                392       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,892\n",
      "Trainable params: 1,892\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the Sequential model instance for 2nd Trial\n",
    "nn_t2 = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_t2.add(Dense(units = hidden_nodes_layer1, activation = \"relu\", input_dim = number_input_features))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_t2.add(Dense(units = hidden_nodes_layer2, activation = \"relu\"))\n",
    "\n",
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn_t2.add(Dense(units = number_output_neurons, activation = \"sigmoid\"))\n",
    "\n",
    "# Display the Sequential model summary\n",
    "nn_t2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0308d90e-8d77-4a21-960c-b89e6968dc83",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn_t2.compile(loss = \"binary_crossentropy\", optimizer = \"SGD\", metrics =[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0af2a8e0-eb91-486c-8660-21e9cbd46484",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.6101 - accuracy: 0.6667\n",
      "Epoch 2/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5270 - accuracy: 0.7474\n",
      "Epoch 3/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5025 - accuracy: 0.7660\n",
      "Epoch 4/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4934 - accuracy: 0.7721\n",
      "Epoch 5/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4883 - accuracy: 0.7744\n",
      "Epoch 6/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4845 - accuracy: 0.7768\n",
      "Epoch 7/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4817 - accuracy: 0.7778\n",
      "Epoch 8/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4794 - accuracy: 0.7793\n",
      "Epoch 9/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4776 - accuracy: 0.7810\n",
      "Epoch 10/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4759 - accuracy: 0.7802\n",
      "Epoch 11/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4745 - accuracy: 0.7816\n",
      "Epoch 12/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4735 - accuracy: 0.7825\n",
      "Epoch 13/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4725 - accuracy: 0.7823\n",
      "Epoch 14/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4715 - accuracy: 0.7820\n",
      "Epoch 15/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4707 - accuracy: 0.7824\n",
      "Epoch 16/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4700 - accuracy: 0.7820\n",
      "Epoch 17/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4692 - accuracy: 0.7837\n",
      "Epoch 18/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4687 - accuracy: 0.7845\n",
      "Epoch 19/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4681 - accuracy: 0.7829\n",
      "Epoch 20/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4675 - accuracy: 0.7835\n",
      "Epoch 21/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4669 - accuracy: 0.7845\n",
      "Epoch 22/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4664 - accuracy: 0.7849\n",
      "Epoch 23/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4659 - accuracy: 0.7843\n",
      "Epoch 24/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4654 - accuracy: 0.7853\n",
      "Epoch 25/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4648 - accuracy: 0.7861\n",
      "Epoch 26/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4644 - accuracy: 0.7856\n",
      "Epoch 27/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4640 - accuracy: 0.7858\n",
      "Epoch 28/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4635 - accuracy: 0.7852\n",
      "Epoch 29/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4629 - accuracy: 0.7860\n",
      "Epoch 30/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4624 - accuracy: 0.7856\n",
      "Epoch 31/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4622 - accuracy: 0.7875\n",
      "Epoch 32/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4618 - accuracy: 0.7867\n",
      "Epoch 33/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4614 - accuracy: 0.7867\n",
      "Epoch 34/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4610 - accuracy: 0.7875\n",
      "Epoch 35/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4605 - accuracy: 0.7880\n",
      "Epoch 36/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4601 - accuracy: 0.7887\n",
      "Epoch 37/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4596 - accuracy: 0.7880\n",
      "Epoch 38/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4593 - accuracy: 0.7876\n",
      "Epoch 39/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4588 - accuracy: 0.7887\n",
      "Epoch 40/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4585 - accuracy: 0.7881\n",
      "Epoch 41/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4582 - accuracy: 0.7890\n",
      "Epoch 42/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4576 - accuracy: 0.7888\n",
      "Epoch 43/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4573 - accuracy: 0.7901\n",
      "Epoch 44/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4570 - accuracy: 0.7882\n",
      "Epoch 45/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4566 - accuracy: 0.7897\n",
      "Epoch 46/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4561 - accuracy: 0.7899\n",
      "Epoch 47/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4558 - accuracy: 0.7903\n",
      "Epoch 48/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4554 - accuracy: 0.7909\n",
      "Epoch 49/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4551 - accuracy: 0.7904\n",
      "Epoch 50/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4548 - accuracy: 0.7903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x173c1bb88b0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "nn_t2.fit(X_train_scaled, y_train, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "de1bfe5c-8513-413a-9e6c-5bfbb09ff2b3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the testing data to make the model predictions\n",
    "y_pred_nn_t2 = (nn_t2.predict(X_test_scaled) > 0.5).astype(\"int64\")\n",
    "\n",
    "# Review the model's predicted values\n",
    "y_pred_nn_t2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ef1fbb18-b2fd-46bb-b343-4f46c94f786f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.78      3540\n",
      "           1       0.75      0.74      0.74      3137\n",
      "\n",
      "    accuracy                           0.76      6677\n",
      "   macro avg       0.76      0.76      0.76      6677\n",
      "weighted avg       0.76      0.76      0.76      6677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "testing_report_nn_t2 = classification_report(y_test, y_pred_nn_t2)\n",
    "print(testing_report_nn_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "62d2b2f2-c2a5-47f3-8a27-292f4d35b1f7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7594148751280957"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#roc_auc_score\n",
    "display(roc_auc_score(y_test, y_pred_nn_t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca593f0a-a1db-4b24-811d-8a5613e65989",
   "metadata": {},
   "source": [
    "#### 3. iv) - (3rd Trial) Deep learning model using:\n",
    "\n",
    "**Input Features:** 54<br>\n",
    "**Output Neuron(s):** 1<br>\n",
    "**Loss:** Binary Crossentropy<br>\n",
    "**Optimizer:** RMSprop<br>\n",
    "**Metrics:** Accuracy<br>\n",
    "**Epochs:** 50<br>\n",
    "> *Layer 1*<br>\n",
    "**Hidden Nodes:** 27<br>\n",
    "**Activation Function:** ReLu<br>\n",
    "\n",
    "> *Layer 2*<br>\n",
    "**Hidden Nodes:** 14<br>\n",
    "**Activation Function:** ReLu<br>\n",
    "\n",
    "> *Output Layer*<br>\n",
    "**Activation Function:** Sigmoid\n",
    "\n",
    "**AUC SCORE:** 0.747782436348377 [Decrease of ~0.005 from baseline]<br>\n",
    "**Changes from Baseline:**<br>\n",
    "Optimizer, Adam --> RMSprop<br>\n",
    "**Result:**<br>\n",
    "Decrease in AUC as compared to baseline. SGD still the best optimizer function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f077d517-679a-49bb-b699-9b2041930911",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 27)                1485      \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 14)                392       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,892\n",
      "Trainable params: 1,892\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the Sequential model instance for 3rd Trial\n",
    "nn_t3 = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_t3.add(Dense(units = hidden_nodes_layer1, activation = \"relu\", input_dim = number_input_features))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_t3.add(Dense(units = hidden_nodes_layer2, activation = \"relu\"))\n",
    "\n",
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn_t3.add(Dense(units = number_output_neurons, activation = \"sigmoid\"))\n",
    "\n",
    "# Display the Sequential model summary\n",
    "nn_t3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "366a7a13-6139-4c6d-961a-c29203ec852d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn_t3.compile(loss = \"binary_crossentropy\", optimizer = \"RMSprop\", metrics =[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2dac150a-45a7-4907-9861-5d78df2398e4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "626/626 [==============================] - 3s 2ms/step - loss: 0.5431 - accuracy: 0.7312\n",
      "Epoch 2/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4856 - accuracy: 0.7770\n",
      "Epoch 3/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4759 - accuracy: 0.7805\n",
      "Epoch 4/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4703 - accuracy: 0.7844\n",
      "Epoch 5/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4667 - accuracy: 0.7865\n",
      "Epoch 6/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4633 - accuracy: 0.7890\n",
      "Epoch 7/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4609 - accuracy: 0.7899\n",
      "Epoch 8/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4584 - accuracy: 0.7905\n",
      "Epoch 9/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4568 - accuracy: 0.7925\n",
      "Epoch 10/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4543 - accuracy: 0.7933\n",
      "Epoch 11/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4525 - accuracy: 0.7943\n",
      "Epoch 12/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4506 - accuracy: 0.7944\n",
      "Epoch 13/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4494 - accuracy: 0.7963\n",
      "Epoch 14/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4480 - accuracy: 0.7941\n",
      "Epoch 15/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4471 - accuracy: 0.7965\n",
      "Epoch 16/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4456 - accuracy: 0.7968\n",
      "Epoch 17/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4442 - accuracy: 0.7986\n",
      "Epoch 18/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4429 - accuracy: 0.7988\n",
      "Epoch 19/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4420 - accuracy: 0.7993\n",
      "Epoch 20/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4408 - accuracy: 0.7977\n",
      "Epoch 21/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4401 - accuracy: 0.7983\n",
      "Epoch 22/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4392 - accuracy: 0.8005\n",
      "Epoch 23/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4386 - accuracy: 0.7994\n",
      "Epoch 24/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4373 - accuracy: 0.8004\n",
      "Epoch 25/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4365 - accuracy: 0.7992\n",
      "Epoch 26/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4362 - accuracy: 0.8008\n",
      "Epoch 27/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4346 - accuracy: 0.8022\n",
      "Epoch 28/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4349 - accuracy: 0.8028\n",
      "Epoch 29/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4341 - accuracy: 0.8031\n",
      "Epoch 30/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4335 - accuracy: 0.8017\n",
      "Epoch 31/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4322 - accuracy: 0.8027\n",
      "Epoch 32/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4319 - accuracy: 0.8039\n",
      "Epoch 33/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4307 - accuracy: 0.8032\n",
      "Epoch 34/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4304 - accuracy: 0.8023\n",
      "Epoch 35/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4297 - accuracy: 0.8050\n",
      "Epoch 36/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4288 - accuracy: 0.8044\n",
      "Epoch 37/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4284 - accuracy: 0.8041\n",
      "Epoch 38/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4280 - accuracy: 0.8041\n",
      "Epoch 39/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4274 - accuracy: 0.8037\n",
      "Epoch 40/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4268 - accuracy: 0.8062\n",
      "Epoch 41/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4260 - accuracy: 0.8056\n",
      "Epoch 42/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4250 - accuracy: 0.8072\n",
      "Epoch 43/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4251 - accuracy: 0.8071\n",
      "Epoch 44/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4251 - accuracy: 0.8089\n",
      "Epoch 45/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4245 - accuracy: 0.8068\n",
      "Epoch 46/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4244 - accuracy: 0.8087\n",
      "Epoch 47/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4236 - accuracy: 0.8091\n",
      "Epoch 48/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4234 - accuracy: 0.8101\n",
      "Epoch 49/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4221 - accuracy: 0.8088\n",
      "Epoch 50/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4219 - accuracy: 0.8087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x173c0dd4070>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "nn_t3.fit(X_train_scaled, y_train, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "770f6db0-0c9a-4856-99e6-a0724d9d3ad4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the testing data to make the model predictions\n",
    "y_pred_nn_t3 = (nn_t3.predict(X_test_scaled) > 0.5).astype(\"int64\")\n",
    "\n",
    "# Review the model's predicted values\n",
    "y_pred_nn_t3[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d7691c34-b07e-4fdc-ba06-5f98859ee007",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.76      0.76      3540\n",
      "           1       0.73      0.74      0.73      3137\n",
      "\n",
      "    accuracy                           0.75      6677\n",
      "   macro avg       0.75      0.75      0.75      6677\n",
      "weighted avg       0.75      0.75      0.75      6677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "testing_report_nn_t3 = classification_report(y_test, y_pred_nn_t3)\n",
    "print(testing_report_nn_t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e331a74c-60a2-40a1-a156-0adc7ef2ba18",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.747782436348377"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#roc_auc_score\n",
    "display(roc_auc_score(y_test, y_pred_nn_t3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e71b13d-79d7-4cda-85d7-9766643d75b1",
   "metadata": {},
   "source": [
    "#### 3. v) - (4th Trial) Deep learning model using:\n",
    "\n",
    "**Input Features:** 54<br>\n",
    "**Output Neuron(s):** 1<br>\n",
    "**Loss:** Binary Crossentropy<br>\n",
    "**Optimizer:** Adagrad<br>\n",
    "**Metrics:** Accuracy<br>\n",
    "**Epochs:** 50<br>\n",
    "> *Layer 1*<br>\n",
    "**Hidden Nodes:** 27<br>\n",
    "**Activation Function:** ReLu<br>\n",
    "\n",
    "> *Layer 2*<br>\n",
    "**Hidden Nodes:** 14<br>\n",
    "**Activation Function:** ReLu<br>\n",
    "\n",
    "> *Output Layer*<br>\n",
    "**Activation Function:** Sigmoid\n",
    "\n",
    "**AUC SCORE:** 0.7519261178318196 [Decrease of ~0.0008 from baseline]<br>\n",
    "**Changes from Baseline:**<br>\n",
    "Optimizer, Adam --> Adagrad<br>\n",
    "**Result:**<br>\n",
    "A slight decrease in AUC as compared to baseline. SGD still preferable to Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f18bf6bc-0105-4de7-ab33-c1e91577b11b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_27 (Dense)            (None, 27)                1485      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 14)                392       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,892\n",
      "Trainable params: 1,892\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the Sequential model instance for 4th Trial\n",
    "nn_t4 = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_t4.add(Dense(units = hidden_nodes_layer1, activation = \"relu\", input_dim = number_input_features))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_t4.add(Dense(units = hidden_nodes_layer2, activation = \"relu\"))\n",
    "\n",
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn_t4.add(Dense(units = number_output_neurons, activation = \"sigmoid\"))\n",
    "\n",
    "# Display the Sequential model summary\n",
    "nn_t4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "20cd4d39-3c82-465d-ab34-6d5d6bf2dba6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn_t4.compile(loss = \"binary_crossentropy\", optimizer = \"Adagrad\", metrics =[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8bd9c5c2-b0cf-463e-bed0-59f48d75f0bf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "626/626 [==============================] - 3s 2ms/step - loss: 0.7041 - accuracy: 0.5545\n",
      "Epoch 2/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.6616 - accuracy: 0.6172\n",
      "Epoch 3/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6378 - accuracy: 0.6501\n",
      "Epoch 4/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.6207 - accuracy: 0.6693\n",
      "Epoch 5/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.6072 - accuracy: 0.6837\n",
      "Epoch 6/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.5962 - accuracy: 0.6958\n",
      "Epoch 7/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.5868 - accuracy: 0.7043\n",
      "Epoch 8/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.5786 - accuracy: 0.7121\n",
      "Epoch 9/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5714 - accuracy: 0.7181\n",
      "Epoch 10/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.5651 - accuracy: 0.7233\n",
      "Epoch 11/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5594 - accuracy: 0.7277\n",
      "Epoch 12/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.5543 - accuracy: 0.7314\n",
      "Epoch 13/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.5497 - accuracy: 0.7348\n",
      "Epoch 14/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.5455 - accuracy: 0.7374\n",
      "Epoch 15/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.5417 - accuracy: 0.7396\n",
      "Epoch 16/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5382 - accuracy: 0.7415\n",
      "Epoch 17/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.5350 - accuracy: 0.7434\n",
      "Epoch 18/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.5321 - accuracy: 0.7446\n",
      "Epoch 19/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5294 - accuracy: 0.7472\n",
      "Epoch 20/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.5270 - accuracy: 0.7490\n",
      "Epoch 21/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.5247 - accuracy: 0.7509\n",
      "Epoch 22/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.5225 - accuracy: 0.7522\n",
      "Epoch 23/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.5206 - accuracy: 0.7538\n",
      "Epoch 24/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.5187 - accuracy: 0.7552\n",
      "Epoch 25/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5170 - accuracy: 0.7564\n",
      "Epoch 26/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5155 - accuracy: 0.7574\n",
      "Epoch 27/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5140 - accuracy: 0.7583\n",
      "Epoch 28/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5126 - accuracy: 0.7594\n",
      "Epoch 29/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.5113 - accuracy: 0.7598\n",
      "Epoch 30/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.5101 - accuracy: 0.7606\n",
      "Epoch 31/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.5089 - accuracy: 0.7611\n",
      "Epoch 32/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.5079 - accuracy: 0.7614\n",
      "Epoch 33/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.5069 - accuracy: 0.7621\n",
      "Epoch 34/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.5059 - accuracy: 0.7624\n",
      "Epoch 35/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5050 - accuracy: 0.7633\n",
      "Epoch 36/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5042 - accuracy: 0.7637\n",
      "Epoch 37/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.5034 - accuracy: 0.7648\n",
      "Epoch 38/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5026 - accuracy: 0.7651\n",
      "Epoch 39/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.5019 - accuracy: 0.7659\n",
      "Epoch 40/50\n",
      "626/626 [==============================] - 3s 4ms/step - loss: 0.5012 - accuracy: 0.7660\n",
      "Epoch 41/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.5005 - accuracy: 0.7665\n",
      "Epoch 42/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4999 - accuracy: 0.7667\n",
      "Epoch 43/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4993 - accuracy: 0.7668\n",
      "Epoch 44/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4988 - accuracy: 0.7671\n",
      "Epoch 45/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4982 - accuracy: 0.7675\n",
      "Epoch 46/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4977 - accuracy: 0.7678\n",
      "Epoch 47/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4972 - accuracy: 0.7681\n",
      "Epoch 48/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.4968 - accuracy: 0.7683\n",
      "Epoch 49/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4963 - accuracy: 0.7687\n",
      "Epoch 50/50\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.4959 - accuracy: 0.7688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x173c0f44370>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "nn_t4.fit(X_train_scaled, y_train, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7d272619-5eb3-4189-859b-37a6806f2910",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 1s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the testing data to make the model predictions\n",
    "y_pred_nn_t4 = (nn_t4.predict(X_test_scaled) > 0.5).astype(\"int64\")\n",
    "\n",
    "# Review the model's predicted values\n",
    "y_pred_nn_t4[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "27f0db76-49b1-42c7-ad53-9629f4247607",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.77      3540\n",
      "           1       0.75      0.71      0.73      3137\n",
      "\n",
      "    accuracy                           0.75      6677\n",
      "   macro avg       0.75      0.75      0.75      6677\n",
      "weighted avg       0.75      0.75      0.75      6677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "testing_report_nn_t4 = classification_report(y_test, y_pred_nn_t4)\n",
    "print(testing_report_nn_t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a69c302d-ecf3-4e1c-8748-99c17d10311d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7519261178318196"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#roc_auc_score\n",
    "display(roc_auc_score(y_test, y_pred_nn_t4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2715082-220c-4a3f-8ca5-8fc3d3e37db1",
   "metadata": {},
   "source": [
    "#### 3. vi) - (5th Trial) Deep learning model using:\n",
    "\n",
    "**Input Features:** 54<br>\n",
    "**Output Neuron(s):** 1<br>\n",
    "**Loss:** Binary Crossentropy<br>\n",
    "**Optimizer:** SGD<br>\n",
    "**Metrics:** Accuracy<br>\n",
    "**Epochs:** 50<br>\n",
    "> *Layer 1*<br>\n",
    "**Hidden Nodes:** 27<br>\n",
    "**Activation Function:** Sigmoid<br>\n",
    "\n",
    "> *Layer 2*<br>\n",
    "**Hidden Nodes:** 14<br>\n",
    "**Activation Function:** Sigmoid<br>\n",
    "\n",
    "> *Output Layer*<br>\n",
    "**Activation Function:** Sigmoid\n",
    "\n",
    "**AUC SCORE:** 0.7619533308479619 [Increase of ~0.0092 from baseline]<br>\n",
    "**Changes from Baseline:**<br>\n",
    "Optimizer, Adam --> SGD;<br>\n",
    "Activation functions in layers 1 and 2, ReLu --> Sigmoid<br>\n",
    "**Result:**<br>\n",
    "Highest AUC so far.<br>\n",
    "Replacing layer 1 & 2 activation functions to sigmoid from ReLu while keeping the optimizer as SGD proves more effective than the baseline for improving model precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9ce90c90-5ae7-4146-8f17-94e3a9f0f9da",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_36 (Dense)            (None, 27)                1485      \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 14)                392       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 1)                 15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,892\n",
      "Trainable params: 1,892\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the Sequential model instance for 5th Trial\n",
    "nn_t5 = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_t5.add(Dense(units = hidden_nodes_layer1, activation = \"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_t5.add(Dense(units = hidden_nodes_layer2, activation = \"sigmoid\"))\n",
    "\n",
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn_t5.add(Dense(units = number_output_neurons, activation = \"sigmoid\"))\n",
    "\n",
    "# Display the Sequential model summary\n",
    "nn_t5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "f0dd4387-3094-445c-a1eb-fb71429ac303",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn_t5.compile(loss = \"binary_crossentropy\", optimizer = \"SGD\", metrics =[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a961583e-6519-4815-a41c-e2adaddda744",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "626/626 [==============================] - 4s 2ms/step - loss: 0.6924 - accuracy: 0.5417\n",
      "Epoch 2/50\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.6772 - accuracy: 0.5654\n",
      "Epoch 3/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6669 - accuracy: 0.6122\n",
      "Epoch 4/50\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.6528 - accuracy: 0.6646\n",
      "Epoch 5/50\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.6332 - accuracy: 0.7019\n",
      "Epoch 6/50\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.6071 - accuracy: 0.7301\n",
      "Epoch 7/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5768 - accuracy: 0.7448\n",
      "Epoch 8/50\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.5476 - accuracy: 0.7541\n",
      "Epoch 9/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5239 - accuracy: 0.7622\n",
      "Epoch 10/50\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.5074 - accuracy: 0.7676\n",
      "Epoch 11/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4965 - accuracy: 0.7736\n",
      "Epoch 12/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4895 - accuracy: 0.7746\n",
      "Epoch 13/50\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.4849 - accuracy: 0.7775\n",
      "Epoch 14/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4823 - accuracy: 0.7773\n",
      "Epoch 15/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4806 - accuracy: 0.7788\n",
      "Epoch 16/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4794 - accuracy: 0.7788\n",
      "Epoch 17/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4787 - accuracy: 0.7801\n",
      "Epoch 18/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4782 - accuracy: 0.7804\n",
      "Epoch 19/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4778 - accuracy: 0.7800\n",
      "Epoch 20/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4776 - accuracy: 0.7818\n",
      "Epoch 21/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4774 - accuracy: 0.7806\n",
      "Epoch 22/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4773 - accuracy: 0.7804\n",
      "Epoch 23/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4772 - accuracy: 0.7809\n",
      "Epoch 24/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4771 - accuracy: 0.7806\n",
      "Epoch 25/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4770 - accuracy: 0.7803\n",
      "Epoch 26/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4769 - accuracy: 0.7811\n",
      "Epoch 27/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4769 - accuracy: 0.7809\n",
      "Epoch 28/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4769 - accuracy: 0.7804\n",
      "Epoch 29/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4768 - accuracy: 0.7808\n",
      "Epoch 30/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4767 - accuracy: 0.7813\n",
      "Epoch 31/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4766 - accuracy: 0.7806\n",
      "Epoch 32/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4765 - accuracy: 0.7816\n",
      "Epoch 33/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4765 - accuracy: 0.7808\n",
      "Epoch 34/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4765 - accuracy: 0.7810\n",
      "Epoch 35/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4764 - accuracy: 0.7814\n",
      "Epoch 36/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4765 - accuracy: 0.7805\n",
      "Epoch 37/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4763 - accuracy: 0.7818\n",
      "Epoch 38/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4764 - accuracy: 0.7808\n",
      "Epoch 39/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4763 - accuracy: 0.7804\n",
      "Epoch 40/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4763 - accuracy: 0.7813\n",
      "Epoch 41/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4763 - accuracy: 0.7818\n",
      "Epoch 42/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4762 - accuracy: 0.7821\n",
      "Epoch 43/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4760 - accuracy: 0.7812\n",
      "Epoch 44/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4761 - accuracy: 0.7822\n",
      "Epoch 45/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4761 - accuracy: 0.7810\n",
      "Epoch 46/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4760 - accuracy: 0.7815\n",
      "Epoch 47/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4759 - accuracy: 0.7820\n",
      "Epoch 48/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4759 - accuracy: 0.7814\n",
      "Epoch 49/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4758 - accuracy: 0.7813\n",
      "Epoch 50/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4758 - accuracy: 0.7807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x173c1d4f460>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "nn_t5.fit(X_train_scaled, y_train, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "203c4790-ce6c-4cb7-b030-41224b66a034",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the testing data to make the model predictions\n",
    "y_pred_nn_t5 = (nn_t5.predict(X_test_scaled) > 0.5).astype(\"int64\")\n",
    "\n",
    "# Review the model's predicted values\n",
    "y_pred_nn_t5[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d8be7bab-e02a-4c29-94a4-a9eb7a0fa6bb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78      3540\n",
      "           1       0.75      0.74      0.75      3137\n",
      "\n",
      "    accuracy                           0.76      6677\n",
      "   macro avg       0.76      0.76      0.76      6677\n",
      "weighted avg       0.76      0.76      0.76      6677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "testing_report_nn_t5 = classification_report(y_test, y_pred_nn_t5)\n",
    "print(testing_report_nn_t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fdac8800-c310-4525-873c-f05b599f141c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7619533308479619"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#roc_auc_score\n",
    "display(roc_auc_score(y_test, y_pred_nn_t5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784a4ab3-2df1-469f-8215-2dfd5e4e78d0",
   "metadata": {},
   "source": [
    "#### 3. vii) - (6th Trial) Deep learning model using:\n",
    "\n",
    "**Input Features:** 54<br>\n",
    "**Output Neuron(s):** 1<br>\n",
    "**Loss:** Binary Crossentropy<br>\n",
    "**Optimizer:** SGD<br>\n",
    "**Metrics:** Accuracy<br>\n",
    "**Epochs:** 50<br>\n",
    "> *Layer 1*<br>\n",
    "**Hidden Nodes:** 27<br>\n",
    "**Activation Function:** Sigmoid<br>\n",
    "\n",
    "> *Layer 2*<br>\n",
    "**Hidden Nodes:** 14<br>\n",
    "**Activation Function:** Sigmoid<br>\n",
    "\n",
    "> *Output Layer*<br>\n",
    "**Activation Function:** Softmax\n",
    "\n",
    "**AUC SCORE:** 0.5 [Decrease of ~0.2527 from baseline]<br>\n",
    "**Changes from Baseline:**<br>\n",
    "Optimizer, Adam --> SGD;<br>\n",
    "Activation functions in layers 1 and 2, ReLu --> Softmax<br>\n",
    "**Result:**<br>\n",
    "Lowest AUC thus far. Softmax not a suitable activation function for the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c1eed48a-04af-497e-b411-6241a6f79373",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_39 (Dense)            (None, 27)                1485      \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 14)                392       \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 15        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,892\n",
      "Trainable params: 1,892\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the Sequential model instance for 6th Trial\n",
    "nn_t6 = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_t6.add(Dense(units = hidden_nodes_layer1, activation = \"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_t6.add(Dense(units = hidden_nodes_layer2, activation = \"sigmoid\"))\n",
    "\n",
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn_t6.add(Dense(units = number_output_neurons, activation = \"softmax\"))\n",
    "\n",
    "# Display the Sequential model summary\n",
    "nn_t6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8aba1f87-857f-4085-967a-4861892fc79e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn_t6.compile(loss = \"binary_crossentropy\", optimizer = \"SGD\", metrics =[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "939e18ef-5706-4dc6-a1ee-d11b8e49dff3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.6950 - accuracy: 0.4642\n",
      "Epoch 2/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6784 - accuracy: 0.4642\n",
      "Epoch 3/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6621 - accuracy: 0.4642\n",
      "Epoch 4/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6414 - accuracy: 0.4642\n",
      "Epoch 5/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6149 - accuracy: 0.4642\n",
      "Epoch 6/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5842 - accuracy: 0.4642\n",
      "Epoch 7/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5539 - accuracy: 0.4642\n",
      "Epoch 8/50\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.5288 - accuracy: 0.4642\n",
      "Epoch 9/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5105 - accuracy: 0.4642\n",
      "Epoch 10/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4983 - accuracy: 0.4642\n",
      "Epoch 11/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4906 - accuracy: 0.4642\n",
      "Epoch 12/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4858 - accuracy: 0.4642\n",
      "Epoch 13/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4828 - accuracy: 0.4642\n",
      "Epoch 14/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4810 - accuracy: 0.4642\n",
      "Epoch 15/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4798 - accuracy: 0.4642\n",
      "Epoch 16/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4791 - accuracy: 0.4642\n",
      "Epoch 17/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4785 - accuracy: 0.4642\n",
      "Epoch 18/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4780 - accuracy: 0.4642\n",
      "Epoch 19/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4779 - accuracy: 0.4642\n",
      "Epoch 20/50\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.4778 - accuracy: 0.4642\n",
      "Epoch 21/50\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.4776 - accuracy: 0.4642\n",
      "Epoch 22/50\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.4775 - accuracy: 0.4642\n",
      "Epoch 23/50\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.4774 - accuracy: 0.4642\n",
      "Epoch 24/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4772 - accuracy: 0.4642\n",
      "Epoch 25/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4773 - accuracy: 0.4642\n",
      "Epoch 26/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4772 - accuracy: 0.4642\n",
      "Epoch 27/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4771 - accuracy: 0.4642\n",
      "Epoch 28/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4770 - accuracy: 0.4642\n",
      "Epoch 29/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4770 - accuracy: 0.4642\n",
      "Epoch 30/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4769 - accuracy: 0.4642\n",
      "Epoch 31/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4768 - accuracy: 0.4642\n",
      "Epoch 32/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4769 - accuracy: 0.4642\n",
      "Epoch 33/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4768 - accuracy: 0.4642\n",
      "Epoch 34/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4768 - accuracy: 0.4642\n",
      "Epoch 35/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4767 - accuracy: 0.4642\n",
      "Epoch 36/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4766 - accuracy: 0.4642\n",
      "Epoch 37/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4766 - accuracy: 0.4642\n",
      "Epoch 38/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4766 - accuracy: 0.4642\n",
      "Epoch 39/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4766 - accuracy: 0.4642\n",
      "Epoch 40/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4764 - accuracy: 0.4642\n",
      "Epoch 41/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4764 - accuracy: 0.4642\n",
      "Epoch 42/50\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.4764 - accuracy: 0.4642\n",
      "Epoch 43/50\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.4763 - accuracy: 0.4642\n",
      "Epoch 44/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4763 - accuracy: 0.4642\n",
      "Epoch 45/50\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.4762 - accuracy: 0.4642\n",
      "Epoch 46/50\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.4761 - accuracy: 0.4642\n",
      "Epoch 47/50\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.4762 - accuracy: 0.4642\n",
      "Epoch 48/50\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.4761 - accuracy: 0.4642\n",
      "Epoch 49/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4761 - accuracy: 0.4642\n",
      "Epoch 50/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4760 - accuracy: 0.4642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x173c2e5a850>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "nn_t6.fit(X_train_scaled, y_train, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "51cdb3c0-8fe4-4643-b935-5afe6efa5f7e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the testing data to make the model predictions\n",
    "y_pred_nn_t6 = (nn_t6.predict(X_test_scaled) > 0.5).astype(\"int64\")\n",
    "\n",
    "# Review the model's predicted values\n",
    "y_pred_nn_t6[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "87a6c023-b7f7-4283-b305-d13288d6e97e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      3540\n",
      "           1       0.47      1.00      0.64      3137\n",
      "\n",
      "    accuracy                           0.47      6677\n",
      "   macro avg       0.23      0.50      0.32      6677\n",
      "weighted avg       0.22      0.47      0.30      6677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "testing_report_nn_t6 = classification_report(y_test, y_pred_nn_t6)\n",
    "print(testing_report_nn_t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "380e9231-88b3-4f63-ae60-eeb0e894a3e7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#roc_auc_score\n",
    "display(roc_auc_score(y_test, y_pred_nn_t6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516f9715-9286-4afb-bd8c-8bc9541d9eed",
   "metadata": {},
   "source": [
    "#### 3. viii) - (7th Trial) Deep learning model using:\n",
    "\n",
    "**Input Features:** 54<br>\n",
    "**Output Neuron(s):** 1<br>\n",
    "**Loss:** Binary Crossentropy<br>\n",
    "**Optimizer:** SGD<br>\n",
    "**Metrics:** Accuracy<br>\n",
    "**Epochs:** 50<br>\n",
    "> *Layer 1*<br>\n",
    "**Hidden Nodes:** 27<br>\n",
    "**Activation Function:** Sigmoid<br>\n",
    "\n",
    "> *Layer 2*<br>\n",
    "**Hidden Nodes:** 14<br>\n",
    "**Activation Function:** Sigmoid<br>\n",
    "\n",
    "> *Layer 3*<br>\n",
    "**Hidden Nodes:** 7<br>\n",
    "**Activation Function:** Sigmoid<br>\n",
    "\n",
    "> *Output Layer*<br>\n",
    "**Activation Function:** Sigmoid\n",
    "\n",
    "**AUC SCORE:** 0.7639905249716794 [Increase of ~0.0112 from baseline]<br>\n",
    "**Changes from Baseline:**<br>\n",
    "Optimizer, Adam --> SGD;<br>\n",
    "Activation functions in layers 1 and 2, ReLu --> Sigmoid;<br>\n",
    "Addition of hidden layer 3, containing 7 neurons & Sigmoid activation function<br>\n",
    "**Result:**<br>\n",
    "Highest AUC score thus far. Adding a third layer of neurons establishes a more capable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7ed772b6-6e66-49ca-8458-42f300192d52",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the third hidden layer\n",
    "hidden_nodes_layer3 = (hidden_nodes_layer2 + 1)//2\n",
    "\n",
    "# Review the number hidden nodes in the third layer\n",
    "hidden_nodes_layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5acf03ce-995b-4f22-90f7-edafdf577e16",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_42 (Dense)            (None, 27)                1485      \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 14)                392       \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 7)                 105       \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,990\n",
      "Trainable params: 1,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the Sequential model instance for 7th Trial\n",
    "nn_t7 = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_t7.add(Dense(units = hidden_nodes_layer1, activation = \"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_t7.add(Dense(units = hidden_nodes_layer2, activation = \"sigmoid\"))\n",
    "\n",
    "# Add the third hidden layer\n",
    "nn_t7.add(Dense(units = hidden_nodes_layer3, activation = \"sigmoid\"))\n",
    "\n",
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn_t7.add(Dense(units = number_output_neurons, activation = \"sigmoid\"))\n",
    "\n",
    "# Display the Sequential model summary\n",
    "nn_t7.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "b057f34a-8de0-4d7f-b0fb-9100c3461a08",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn_t7.compile(loss = \"binary_crossentropy\", optimizer = \"SGD\", metrics =[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0bf71b00-f632-43d3-a431-92bc289078a6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.6954 - accuracy: 0.5152\n",
      "Epoch 2/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6926 - accuracy: 0.5358\n",
      "Epoch 3/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6919 - accuracy: 0.5358\n",
      "Epoch 4/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6913 - accuracy: 0.5358\n",
      "Epoch 5/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6906 - accuracy: 0.5358\n",
      "Epoch 6/50\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.6902 - accuracy: 0.5358\n",
      "Epoch 7/50\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.6896 - accuracy: 0.5358\n",
      "Epoch 8/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6890 - accuracy: 0.5358\n",
      "Epoch 9/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6883 - accuracy: 0.5358\n",
      "Epoch 10/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6877 - accuracy: 0.5358\n",
      "Epoch 11/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5358\n",
      "Epoch 12/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6859 - accuracy: 0.5358\n",
      "Epoch 13/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6848 - accuracy: 0.5358\n",
      "Epoch 14/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6834 - accuracy: 0.5358\n",
      "Epoch 15/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6816 - accuracy: 0.5360\n",
      "Epoch 16/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6794 - accuracy: 0.5371\n",
      "Epoch 17/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6766 - accuracy: 0.5409\n",
      "Epoch 18/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6730 - accuracy: 0.5503\n",
      "Epoch 19/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6680 - accuracy: 0.5808\n",
      "Epoch 20/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6614 - accuracy: 0.6228\n",
      "Epoch 21/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6524 - accuracy: 0.6603\n",
      "Epoch 22/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6401 - accuracy: 0.7081\n",
      "Epoch 23/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6237 - accuracy: 0.7287\n",
      "Epoch 24/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6032 - accuracy: 0.7493\n",
      "Epoch 25/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5794 - accuracy: 0.7568\n",
      "Epoch 26/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5549 - accuracy: 0.7615\n",
      "Epoch 27/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5328 - accuracy: 0.7660\n",
      "Epoch 28/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5154 - accuracy: 0.7701\n",
      "Epoch 29/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5027 - accuracy: 0.7739\n",
      "Epoch 30/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4943 - accuracy: 0.7753\n",
      "Epoch 31/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4886 - accuracy: 0.7769\n",
      "Epoch 32/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4851 - accuracy: 0.7786\n",
      "Epoch 33/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4828 - accuracy: 0.7785\n",
      "Epoch 34/50\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.4813 - accuracy: 0.7792\n",
      "Epoch 35/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4804 - accuracy: 0.7798\n",
      "Epoch 36/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4798 - accuracy: 0.7793\n",
      "Epoch 37/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4793 - accuracy: 0.7794\n",
      "Epoch 38/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4790 - accuracy: 0.7801\n",
      "Epoch 39/50\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.4787 - accuracy: 0.7804\n",
      "Epoch 40/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4785 - accuracy: 0.7802\n",
      "Epoch 41/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4784 - accuracy: 0.7804\n",
      "Epoch 42/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4782 - accuracy: 0.7796\n",
      "Epoch 43/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4781 - accuracy: 0.7800\n",
      "Epoch 44/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4780 - accuracy: 0.7808\n",
      "Epoch 45/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4779 - accuracy: 0.7803\n",
      "Epoch 46/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4779 - accuracy: 0.7797\n",
      "Epoch 47/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4778 - accuracy: 0.7807\n",
      "Epoch 48/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4775 - accuracy: 0.7812\n",
      "Epoch 49/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4778 - accuracy: 0.7804\n",
      "Epoch 50/50\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4776 - accuracy: 0.7804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x173c179d9d0>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "nn_t7.fit(X_train_scaled, y_train, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "04154af0-90c8-4d24-807b-25addb066aaf",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the testing data to make the model predictions\n",
    "y_pred_nn_t7 = (nn_t7.predict(X_test_scaled) > 0.5).astype(\"int64\")\n",
    "\n",
    "# Review the model's predicted values\n",
    "y_pred_nn_t7[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5a3694a0-2e19-450f-8e61-2e214c881120",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      3540\n",
      "           1       0.75      0.75      0.75      3137\n",
      "\n",
      "    accuracy                           0.76      6677\n",
      "   macro avg       0.76      0.76      0.76      6677\n",
      "weighted avg       0.76      0.76      0.76      6677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "testing_report_nn_t7 = classification_report(y_test, y_pred_nn_t7)\n",
    "print(testing_report_nn_t7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a1a2ebcb-ac78-48c9-a053-672afcc6e9ce",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7639905249716794"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#roc_auc_score\n",
    "display(roc_auc_score(y_test, y_pred_nn_t7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01c2464-e4b3-4bbd-b10c-149ddca94109",
   "metadata": {},
   "source": [
    "#### 3. ix) - (8th Trial) Deep learning model using:\n",
    "\n",
    "**Input Features:** 54<br>\n",
    "**Output Neuron(s):** 1<br>\n",
    "**Loss:** Binary Crossentropy<br>\n",
    "**Optimizer:** SGD<br>\n",
    "**Metrics:** Accuracy<br>\n",
    "**Epochs:** 100<br>\n",
    "> *Layer 1*<br>\n",
    "**Hidden Nodes:** 27<br>\n",
    "**Activation Function:** Sigmoid<br>\n",
    "\n",
    "> *Layer 2*<br>\n",
    "**Hidden Nodes:** 14<br>\n",
    "**Activation Function:** Sigmoid<br>\n",
    "\n",
    "> *Layer 3*<br>\n",
    "**Hidden Nodes:** 7<br>\n",
    "**Activation Function:** Sigmoid<br>\n",
    "\n",
    "> *Output Layer*<br>\n",
    "**Activation Function:** Sigmoid\n",
    "\n",
    "**AUC SCORE:** 0.7638738205741928 [Increase of ~0.0111 from baseline, however decrease of ~0.0001 from Trial 7]<br>\n",
    "**Changes from Baseline:**<br>\n",
    "Optimizer, Adam --> SGD;<br>\n",
    "Activation functions in layers 1 and 2, ReLu --> Sigmoid;<br>\n",
    "Addition of hidden layer 3, containing 7 neurons & Sigmoid activation function;<br>\n",
    "Epochs, 50 --> 100<br>\n",
    "**Result:**<br>\n",
    "While the AUC has returned as higher than the baseline, the score is still less than the highest achieved in trial 7 despite the increase in epochs from 50 to 100.<br>\n",
    "Improvements in accuracy after each epoch were discontinued approximately after epoch 50, meaning greater than 50 epochs is unnecessary for this model configuration.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a0af72b7-a86e-4daa-aaf9-624f2cc60ae4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_46 (Dense)            (None, 27)                1485      \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 14)                392       \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 7)                 105       \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,990\n",
      "Trainable params: 1,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the Sequential model instance for 8th Trial\n",
    "nn_t8 = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_t8.add(Dense(units = hidden_nodes_layer1, activation = \"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_t8.add(Dense(units = hidden_nodes_layer2, activation = \"sigmoid\"))\n",
    "\n",
    "# Add the third hidden layer\n",
    "nn_t8.add(Dense(units = hidden_nodes_layer3, activation = \"sigmoid\"))\n",
    "\n",
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn_t8.add(Dense(units = number_output_neurons, activation = \"sigmoid\"))\n",
    "\n",
    "# Display the Sequential model summary\n",
    "nn_t8.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19c64e7-6d43-4e1a-9d13-48d29c706148",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn_t8.compile(loss = \"binary_crossentropy\", optimizer = \"SGD\", metrics =[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d54c07c1-440b-4f6e-b0da-3c34371cf8f6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.6896 - accuracy: 0.5359\n",
      "Epoch 2/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6882 - accuracy: 0.5358\n",
      "Epoch 3/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5358\n",
      "Epoch 4/100\n",
      "626/626 [==============================] - 1s 1ms/step - loss: 0.6853 - accuracy: 0.5359\n",
      "Epoch 5/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6834 - accuracy: 0.5379\n",
      "Epoch 6/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6813 - accuracy: 0.5423\n",
      "Epoch 7/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6785 - accuracy: 0.5475\n",
      "Epoch 8/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6749 - accuracy: 0.5582\n",
      "Epoch 9/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6701 - accuracy: 0.5868\n",
      "Epoch 10/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6637 - accuracy: 0.6336\n",
      "Epoch 11/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6548 - accuracy: 0.6661\n",
      "Epoch 12/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6426 - accuracy: 0.6984\n",
      "Epoch 13/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6260 - accuracy: 0.7233\n",
      "Epoch 14/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6048 - accuracy: 0.7397\n",
      "Epoch 15/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5801 - accuracy: 0.7529\n",
      "Epoch 16/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5548 - accuracy: 0.7585\n",
      "Epoch 17/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5326 - accuracy: 0.7625\n",
      "Epoch 18/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5154 - accuracy: 0.7671\n",
      "Epoch 19/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5033 - accuracy: 0.7699\n",
      "Epoch 20/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4950 - accuracy: 0.7739\n",
      "Epoch 21/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4896 - accuracy: 0.7757\n",
      "Epoch 22/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4860 - accuracy: 0.7773\n",
      "Epoch 23/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4836 - accuracy: 0.7771\n",
      "Epoch 24/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4819 - accuracy: 0.7780\n",
      "Epoch 25/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4809 - accuracy: 0.7784\n",
      "Epoch 26/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4801 - accuracy: 0.7789\n",
      "Epoch 27/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4797 - accuracy: 0.7784\n",
      "Epoch 28/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4792 - accuracy: 0.7800\n",
      "Epoch 29/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4790 - accuracy: 0.7807\n",
      "Epoch 30/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4788 - accuracy: 0.7804\n",
      "Epoch 31/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4786 - accuracy: 0.7812\n",
      "Epoch 32/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4784 - accuracy: 0.7805\n",
      "Epoch 33/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4784 - accuracy: 0.7816\n",
      "Epoch 34/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4783 - accuracy: 0.7819\n",
      "Epoch 35/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4781 - accuracy: 0.7815\n",
      "Epoch 36/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4781 - accuracy: 0.7819\n",
      "Epoch 37/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4780 - accuracy: 0.7817\n",
      "Epoch 38/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4780 - accuracy: 0.7812\n",
      "Epoch 39/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4779 - accuracy: 0.7813\n",
      "Epoch 40/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4779 - accuracy: 0.7814\n",
      "Epoch 41/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4779 - accuracy: 0.7822\n",
      "Epoch 42/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4776 - accuracy: 0.7823\n",
      "Epoch 43/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4777 - accuracy: 0.7822\n",
      "Epoch 44/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4776 - accuracy: 0.7818\n",
      "Epoch 45/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4776 - accuracy: 0.7816\n",
      "Epoch 46/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4775 - accuracy: 0.7819\n",
      "Epoch 47/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4775 - accuracy: 0.7816\n",
      "Epoch 48/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4775 - accuracy: 0.7826\n",
      "Epoch 49/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4775 - accuracy: 0.7819\n",
      "Epoch 50/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4774 - accuracy: 0.7822\n",
      "Epoch 51/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4773 - accuracy: 0.7815\n",
      "Epoch 52/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4773 - accuracy: 0.7815\n",
      "Epoch 53/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4772 - accuracy: 0.7817\n",
      "Epoch 54/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4771 - accuracy: 0.7826\n",
      "Epoch 55/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4771 - accuracy: 0.7818\n",
      "Epoch 56/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4770 - accuracy: 0.7814\n",
      "Epoch 57/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4770 - accuracy: 0.7826\n",
      "Epoch 58/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4769 - accuracy: 0.7820\n",
      "Epoch 59/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4769 - accuracy: 0.7820\n",
      "Epoch 60/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4769 - accuracy: 0.7822\n",
      "Epoch 61/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4768 - accuracy: 0.7819\n",
      "Epoch 62/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4767 - accuracy: 0.7824\n",
      "Epoch 63/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4767 - accuracy: 0.7816\n",
      "Epoch 64/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4766 - accuracy: 0.7823\n",
      "Epoch 65/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4765 - accuracy: 0.7821\n",
      "Epoch 66/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4766 - accuracy: 0.7824\n",
      "Epoch 67/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4764 - accuracy: 0.7820\n",
      "Epoch 68/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4765 - accuracy: 0.7824\n",
      "Epoch 69/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4764 - accuracy: 0.7818\n",
      "Epoch 70/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4762 - accuracy: 0.7819\n",
      "Epoch 71/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4763 - accuracy: 0.7821\n",
      "Epoch 72/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4762 - accuracy: 0.7825\n",
      "Epoch 73/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4761 - accuracy: 0.7820\n",
      "Epoch 74/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4761 - accuracy: 0.7824\n",
      "Epoch 75/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4760 - accuracy: 0.7814\n",
      "Epoch 76/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4760 - accuracy: 0.7828\n",
      "Epoch 77/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4759 - accuracy: 0.7822\n",
      "Epoch 78/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4759 - accuracy: 0.7827\n",
      "Epoch 79/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4758 - accuracy: 0.7820\n",
      "Epoch 80/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4758 - accuracy: 0.7821\n",
      "Epoch 81/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4757 - accuracy: 0.7823\n",
      "Epoch 82/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4757 - accuracy: 0.7825\n",
      "Epoch 83/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4756 - accuracy: 0.7830\n",
      "Epoch 84/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4756 - accuracy: 0.7826\n",
      "Epoch 85/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4755 - accuracy: 0.7823\n",
      "Epoch 86/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4754 - accuracy: 0.7823\n",
      "Epoch 87/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4754 - accuracy: 0.7835\n",
      "Epoch 88/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4753 - accuracy: 0.7823\n",
      "Epoch 89/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4753 - accuracy: 0.7825\n",
      "Epoch 90/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4752 - accuracy: 0.7825\n",
      "Epoch 91/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4752 - accuracy: 0.7826\n",
      "Epoch 92/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4750 - accuracy: 0.7832\n",
      "Epoch 93/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4750 - accuracy: 0.7834\n",
      "Epoch 94/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4750 - accuracy: 0.7823\n",
      "Epoch 95/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4748 - accuracy: 0.7815\n",
      "Epoch 96/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4749 - accuracy: 0.7823\n",
      "Epoch 97/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4748 - accuracy: 0.7829\n",
      "Epoch 98/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4746 - accuracy: 0.7830\n",
      "Epoch 99/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4746 - accuracy: 0.7825\n",
      "Epoch 100/100\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.4746 - accuracy: 0.7831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x173c274d430>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "nn_t8.fit(X_train_scaled, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cba704d8-56e0-4e0a-ab91-d51f8dd5487d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the testing data to make the model predictions\n",
    "y_pred_nn_t8 = (nn_t8.predict(X_test_scaled) > 0.5).astype(\"int64\")\n",
    "\n",
    "# Review the model's predicted values\n",
    "y_pred_nn_t8[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "eb292e47-b480-4172-9ac6-3c07c01b1d27",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      3540\n",
      "           1       0.75      0.74      0.75      3137\n",
      "\n",
      "    accuracy                           0.77      6677\n",
      "   macro avg       0.76      0.76      0.76      6677\n",
      "weighted avg       0.76      0.77      0.76      6677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "testing_report_nn_t8 = classification_report(y_test, y_pred_nn_t8)\n",
    "print(testing_report_nn_t8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3899b5a2-a2fa-4c34-ae7b-b6d5c975f670",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7638738205741928"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#roc_auc_score\n",
    "display(roc_auc_score(y_test, y_pred_nn_t8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df23d0d-a47c-4b19-b744-87c09c1a3df1",
   "metadata": {},
   "source": [
    "#### 3. x) - (9th Trial) Deep learning model using:\n",
    "\n",
    "**Input Features:** 54<br>\n",
    "**Output Neuron(s):** 1<br>\n",
    "**Loss:** Binary Crossentropy<br>\n",
    "**Optimizer:** SGD<br>\n",
    "**Metrics:** Accuracy<br>\n",
    "**Epochs:** 500<br>\n",
    "> *Layer 1*<br>\n",
    "**Hidden Nodes:** 27<br>\n",
    "**Activation Function:** Sigmoid<br>\n",
    "**Dropout Rate:** 0.5<br>\n",
    "\n",
    "> *Layer 2*<br>\n",
    "**Hidden Nodes:** 14<br>\n",
    "**Activation Function:** Sigmoid<br>\n",
    "**Dropout Rate:** 0.2<br>\n",
    "\n",
    "> *Layer 3*<br>\n",
    "**Hidden Nodes:** 7<br>\n",
    "**Activation Function:** Sigmoid<br>\n",
    "**Dropout Rate:** 0.2<br>\n",
    "\n",
    "> *Output Layer*<br>\n",
    "**Activation Function:** Sigmoid\n",
    "\n",
    "**AUC SCORE:** 0.7640047528226074 [Increase of ~0.0113 from baseline]<br>\n",
    "**Changes from Baseline:**<br>\n",
    "Optimizer, Adam --> SGD;<br>\n",
    "Activation functions in layers 1 and 2, ReLu --> Sigmoid;<br>\n",
    "Addition of hidden layer 3, containing 7 neurons & Sigmoid activation function;<br>\n",
    "Epochs, 50 --> 500<br>\n",
    "Addition of dropout technique to prevent overfitting, with rate of 0.5 for input layer and 0.2 for layers 2 and 3.<br>\n",
    "**Result:**<br>\n",
    "Highest AUC score thus far. Epochs were increased to 500 to gauge the taper-off point for the increases to the model's accuracy following each epoch.<br>\n",
    "150 epochs appears to the the point at which accuracy begins to fluctuate around approximately 76%. Epochs will thus be altered to 150 for the next test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9d198b62-f9ef-4a73-905f-89ad71121d38",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_54 (Dense)            (None, 27)                1485      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 27)                0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 14)                392       \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 14)                0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 7)                 105       \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 7)                 0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,990\n",
      "Trainable params: 1,990\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the Sequential model instance for 9th Trial\n",
    "nn_t9 = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_t9.add(Dense(units = hidden_nodes_layer1, activation = \"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the first dropout layer\n",
    "nn_t9.add(Dropout(0.5))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_t9.add(Dense(units = hidden_nodes_layer2, activation = \"sigmoid\"))\n",
    "\n",
    "# Add the second dropout layer\n",
    "nn_t9.add(Dropout(0.2))\n",
    "\n",
    "# Add the third hidden layer\n",
    "nn_t9.add(Dense(units = hidden_nodes_layer3, activation = \"sigmoid\"))\n",
    "\n",
    "# Add the third dropout layer\n",
    "nn_t9.add(Dropout(0.2))\n",
    "\n",
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn_t9.add(Dense(units = number_output_neurons, activation = \"sigmoid\"))\n",
    "\n",
    "# Display the Sequential model summary\n",
    "nn_t9.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "95db557e-998f-433d-9e01-f5335d73032b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn_t9.compile(loss = \"binary_crossentropy\", optimizer = \"SGD\", metrics =[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b712f4e6-6932-43ff-9d5c-66df3bd85624",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.7103 - accuracy: 0.5010\n",
      "Epoch 2/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6969 - accuracy: 0.5203\n",
      "Epoch 3/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6954 - accuracy: 0.5220\n",
      "Epoch 4/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6945 - accuracy: 0.5249\n",
      "Epoch 5/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6925 - accuracy: 0.5272\n",
      "Epoch 6/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6926 - accuracy: 0.5252\n",
      "Epoch 7/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6910 - accuracy: 0.5352\n",
      "Epoch 8/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6916 - accuracy: 0.5313\n",
      "Epoch 9/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6907 - accuracy: 0.5330\n",
      "Epoch 10/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6911 - accuracy: 0.5369\n",
      "Epoch 11/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6903 - accuracy: 0.5370\n",
      "Epoch 12/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6907 - accuracy: 0.5341\n",
      "Epoch 13/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6904 - accuracy: 0.5370\n",
      "Epoch 14/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6900 - accuracy: 0.5394\n",
      "Epoch 15/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6900 - accuracy: 0.5366\n",
      "Epoch 16/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6900 - accuracy: 0.5377\n",
      "Epoch 17/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6899 - accuracy: 0.5393\n",
      "Epoch 18/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6897 - accuracy: 0.5378\n",
      "Epoch 19/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6897 - accuracy: 0.5390\n",
      "Epoch 20/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6899 - accuracy: 0.5391\n",
      "Epoch 21/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6897 - accuracy: 0.5391\n",
      "Epoch 22/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6895 - accuracy: 0.5384\n",
      "Epoch 23/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6891 - accuracy: 0.5423\n",
      "Epoch 24/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6893 - accuracy: 0.5388\n",
      "Epoch 25/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6886 - accuracy: 0.5415\n",
      "Epoch 26/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6885 - accuracy: 0.5452\n",
      "Epoch 27/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6885 - accuracy: 0.5439\n",
      "Epoch 28/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6883 - accuracy: 0.5436\n",
      "Epoch 29/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6889 - accuracy: 0.5439\n",
      "Epoch 30/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6880 - accuracy: 0.5494\n",
      "Epoch 31/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6874 - accuracy: 0.5484\n",
      "Epoch 32/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6882 - accuracy: 0.5513\n",
      "Epoch 33/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6877 - accuracy: 0.5509\n",
      "Epoch 34/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6861 - accuracy: 0.5557\n",
      "Epoch 35/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6872 - accuracy: 0.5547\n",
      "Epoch 36/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6862 - accuracy: 0.5559\n",
      "Epoch 37/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6859 - accuracy: 0.5589\n",
      "Epoch 38/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6852 - accuracy: 0.5564\n",
      "Epoch 39/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6854 - accuracy: 0.5598\n",
      "Epoch 40/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6832 - accuracy: 0.5668\n",
      "Epoch 41/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6837 - accuracy: 0.5652\n",
      "Epoch 42/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6813 - accuracy: 0.5735\n",
      "Epoch 43/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6818 - accuracy: 0.5715\n",
      "Epoch 44/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6807 - accuracy: 0.5762\n",
      "Epoch 45/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6779 - accuracy: 0.5802\n",
      "Epoch 46/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6763 - accuracy: 0.5874\n",
      "Epoch 47/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6753 - accuracy: 0.5881\n",
      "Epoch 48/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6732 - accuracy: 0.5909\n",
      "Epoch 49/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6706 - accuracy: 0.5954\n",
      "Epoch 50/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6661 - accuracy: 0.6022\n",
      "Epoch 51/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6654 - accuracy: 0.6026\n",
      "Epoch 52/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6602 - accuracy: 0.6094\n",
      "Epoch 53/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6564 - accuracy: 0.6184\n",
      "Epoch 54/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6521 - accuracy: 0.6209\n",
      "Epoch 55/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6519 - accuracy: 0.6166\n",
      "Epoch 56/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6444 - accuracy: 0.6320\n",
      "Epoch 57/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6386 - accuracy: 0.6393\n",
      "Epoch 58/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6339 - accuracy: 0.6437\n",
      "Epoch 59/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6265 - accuracy: 0.6526\n",
      "Epoch 60/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6221 - accuracy: 0.6559\n",
      "Epoch 61/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6172 - accuracy: 0.6653\n",
      "Epoch 62/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6121 - accuracy: 0.6658\n",
      "Epoch 63/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6106 - accuracy: 0.6662\n",
      "Epoch 64/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6015 - accuracy: 0.6799\n",
      "Epoch 65/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6027 - accuracy: 0.6793\n",
      "Epoch 66/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5960 - accuracy: 0.6845\n",
      "Epoch 67/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5940 - accuracy: 0.6873\n",
      "Epoch 68/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5871 - accuracy: 0.6972\n",
      "Epoch 69/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5878 - accuracy: 0.6950\n",
      "Epoch 70/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5849 - accuracy: 0.7000\n",
      "Epoch 71/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5814 - accuracy: 0.7067\n",
      "Epoch 72/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5746 - accuracy: 0.7084\n",
      "Epoch 73/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5771 - accuracy: 0.7095\n",
      "Epoch 74/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5722 - accuracy: 0.7132\n",
      "Epoch 75/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5746 - accuracy: 0.7091\n",
      "Epoch 76/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5678 - accuracy: 0.7192\n",
      "Epoch 77/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5661 - accuracy: 0.7208\n",
      "Epoch 78/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5689 - accuracy: 0.7139\n",
      "Epoch 79/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5601 - accuracy: 0.7268\n",
      "Epoch 80/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5622 - accuracy: 0.7228\n",
      "Epoch 81/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5646 - accuracy: 0.7216\n",
      "Epoch 82/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5632 - accuracy: 0.7247\n",
      "Epoch 83/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5597 - accuracy: 0.7264\n",
      "Epoch 84/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5605 - accuracy: 0.7260\n",
      "Epoch 85/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5586 - accuracy: 0.7278\n",
      "Epoch 86/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5505 - accuracy: 0.7345\n",
      "Epoch 87/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5525 - accuracy: 0.7299\n",
      "Epoch 88/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5514 - accuracy: 0.7371\n",
      "Epoch 89/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5445 - accuracy: 0.7414\n",
      "Epoch 90/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5551 - accuracy: 0.7328\n",
      "Epoch 91/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5495 - accuracy: 0.7357\n",
      "Epoch 92/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5496 - accuracy: 0.7352\n",
      "Epoch 93/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5433 - accuracy: 0.7424\n",
      "Epoch 94/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5468 - accuracy: 0.7396\n",
      "Epoch 95/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5472 - accuracy: 0.7406\n",
      "Epoch 96/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5483 - accuracy: 0.7387\n",
      "Epoch 97/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5444 - accuracy: 0.7425\n",
      "Epoch 98/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5452 - accuracy: 0.7394\n",
      "Epoch 99/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5451 - accuracy: 0.7397\n",
      "Epoch 100/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5426 - accuracy: 0.7481\n",
      "Epoch 101/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5437 - accuracy: 0.7433\n",
      "Epoch 102/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5448 - accuracy: 0.7446\n",
      "Epoch 103/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5424 - accuracy: 0.7457\n",
      "Epoch 104/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7461\n",
      "Epoch 105/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5382 - accuracy: 0.7474\n",
      "Epoch 106/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5400 - accuracy: 0.7459\n",
      "Epoch 107/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5399 - accuracy: 0.7486\n",
      "Epoch 108/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5384 - accuracy: 0.7475\n",
      "Epoch 109/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5389 - accuracy: 0.7465\n",
      "Epoch 110/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7482\n",
      "Epoch 111/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7486\n",
      "Epoch 112/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7505\n",
      "Epoch 113/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5342 - accuracy: 0.7511\n",
      "Epoch 114/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5323 - accuracy: 0.7535\n",
      "Epoch 115/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5406 - accuracy: 0.7470\n",
      "Epoch 116/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7493\n",
      "Epoch 117/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5325 - accuracy: 0.7507\n",
      "Epoch 118/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5363 - accuracy: 0.7534\n",
      "Epoch 119/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5349 - accuracy: 0.7511\n",
      "Epoch 120/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7535\n",
      "Epoch 121/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5344 - accuracy: 0.7522\n",
      "Epoch 122/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5336 - accuracy: 0.7535\n",
      "Epoch 123/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7539\n",
      "Epoch 124/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5347 - accuracy: 0.7511\n",
      "Epoch 125/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5316 - accuracy: 0.7560\n",
      "Epoch 126/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5280 - accuracy: 0.7562\n",
      "Epoch 127/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5332 - accuracy: 0.7513\n",
      "Epoch 128/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5282 - accuracy: 0.7549\n",
      "Epoch 129/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5301 - accuracy: 0.7547\n",
      "Epoch 130/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5278 - accuracy: 0.7568\n",
      "Epoch 131/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5291 - accuracy: 0.7526\n",
      "Epoch 132/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5277 - accuracy: 0.7566\n",
      "Epoch 133/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5305 - accuracy: 0.7567\n",
      "Epoch 134/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5277 - accuracy: 0.7573\n",
      "Epoch 135/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5273 - accuracy: 0.7567\n",
      "Epoch 136/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5274 - accuracy: 0.7575\n",
      "Epoch 137/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5274 - accuracy: 0.7580\n",
      "Epoch 138/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5307 - accuracy: 0.7548\n",
      "Epoch 139/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5299 - accuracy: 0.7555\n",
      "Epoch 140/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5274 - accuracy: 0.7584\n",
      "Epoch 141/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5237 - accuracy: 0.7606\n",
      "Epoch 142/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5258 - accuracy: 0.7601\n",
      "Epoch 143/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5263 - accuracy: 0.7567\n",
      "Epoch 144/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5235 - accuracy: 0.7591\n",
      "Epoch 145/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5276 - accuracy: 0.7590\n",
      "Epoch 146/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5257 - accuracy: 0.7594\n",
      "Epoch 147/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5265 - accuracy: 0.7577\n",
      "Epoch 148/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5258 - accuracy: 0.7602\n",
      "Epoch 149/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5262 - accuracy: 0.7569\n",
      "Epoch 150/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5238 - accuracy: 0.7602\n",
      "Epoch 151/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5234 - accuracy: 0.7594\n",
      "Epoch 152/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5284 - accuracy: 0.7545\n",
      "Epoch 153/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5248 - accuracy: 0.7563\n",
      "Epoch 154/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5202 - accuracy: 0.7632\n",
      "Epoch 155/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5231 - accuracy: 0.7585\n",
      "Epoch 156/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5227 - accuracy: 0.7617\n",
      "Epoch 157/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5215 - accuracy: 0.7607\n",
      "Epoch 158/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5241 - accuracy: 0.7572\n",
      "Epoch 159/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5250 - accuracy: 0.7611\n",
      "Epoch 160/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5247 - accuracy: 0.7596\n",
      "Epoch 161/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5238 - accuracy: 0.7616\n",
      "Epoch 162/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5232 - accuracy: 0.7604\n",
      "Epoch 163/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5198 - accuracy: 0.7612\n",
      "Epoch 164/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5228 - accuracy: 0.7620\n",
      "Epoch 165/500\n",
      "626/626 [==============================] - 2s 3ms/step - loss: 0.5206 - accuracy: 0.7641\n",
      "Epoch 166/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5236 - accuracy: 0.7605\n",
      "Epoch 167/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5207 - accuracy: 0.7630\n",
      "Epoch 168/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5239 - accuracy: 0.7607\n",
      "Epoch 169/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5228 - accuracy: 0.7627\n",
      "Epoch 170/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5225 - accuracy: 0.7612\n",
      "Epoch 171/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5216 - accuracy: 0.7603\n",
      "Epoch 172/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5217 - accuracy: 0.7595\n",
      "Epoch 173/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5170 - accuracy: 0.7670\n",
      "Epoch 174/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5198 - accuracy: 0.7641\n",
      "Epoch 175/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5220 - accuracy: 0.7616\n",
      "Epoch 176/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5228 - accuracy: 0.7620\n",
      "Epoch 177/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5188 - accuracy: 0.7642\n",
      "Epoch 178/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5230 - accuracy: 0.7582\n",
      "Epoch 179/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5191 - accuracy: 0.7628\n",
      "Epoch 180/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5173 - accuracy: 0.7628\n",
      "Epoch 181/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5202 - accuracy: 0.7634\n",
      "Epoch 182/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5212 - accuracy: 0.7616\n",
      "Epoch 183/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5178 - accuracy: 0.7648\n",
      "Epoch 184/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5194 - accuracy: 0.7632\n",
      "Epoch 185/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5208 - accuracy: 0.7649\n",
      "Epoch 186/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5199 - accuracy: 0.7633\n",
      "Epoch 187/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5174 - accuracy: 0.7643\n",
      "Epoch 188/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5197 - accuracy: 0.7624\n",
      "Epoch 189/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5174 - accuracy: 0.7672\n",
      "Epoch 190/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5192 - accuracy: 0.7634\n",
      "Epoch 191/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5182 - accuracy: 0.7658\n",
      "Epoch 192/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5197 - accuracy: 0.7649\n",
      "Epoch 193/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5202 - accuracy: 0.7627\n",
      "Epoch 194/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5173 - accuracy: 0.7641\n",
      "Epoch 195/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5177 - accuracy: 0.7644\n",
      "Epoch 196/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5183 - accuracy: 0.7637\n",
      "Epoch 197/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5195 - accuracy: 0.7629\n",
      "Epoch 198/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5178 - accuracy: 0.7643\n",
      "Epoch 199/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5160 - accuracy: 0.7642\n",
      "Epoch 200/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5184 - accuracy: 0.7648\n",
      "Epoch 201/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5190 - accuracy: 0.7635\n",
      "Epoch 202/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5147 - accuracy: 0.7656\n",
      "Epoch 203/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5190 - accuracy: 0.7643\n",
      "Epoch 204/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5206 - accuracy: 0.7612\n",
      "Epoch 205/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5164 - accuracy: 0.7657\n",
      "Epoch 206/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5197 - accuracy: 0.7591\n",
      "Epoch 207/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5170 - accuracy: 0.7652\n",
      "Epoch 208/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5161 - accuracy: 0.7646\n",
      "Epoch 209/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5190 - accuracy: 0.7666\n",
      "Epoch 210/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5134 - accuracy: 0.7648\n",
      "Epoch 211/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5174 - accuracy: 0.7665\n",
      "Epoch 212/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5197 - accuracy: 0.7643\n",
      "Epoch 213/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5197 - accuracy: 0.7622\n",
      "Epoch 214/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5171 - accuracy: 0.7667\n",
      "Epoch 215/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5151 - accuracy: 0.7649\n",
      "Epoch 216/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5172 - accuracy: 0.7669\n",
      "Epoch 217/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5184 - accuracy: 0.7622\n",
      "Epoch 218/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5146 - accuracy: 0.7646\n",
      "Epoch 219/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5180 - accuracy: 0.7651\n",
      "Epoch 220/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5130 - accuracy: 0.7668\n",
      "Epoch 221/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5172 - accuracy: 0.7663\n",
      "Epoch 222/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5183 - accuracy: 0.7653\n",
      "Epoch 223/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5147 - accuracy: 0.7672\n",
      "Epoch 224/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5164 - accuracy: 0.7661\n",
      "Epoch 225/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5156 - accuracy: 0.7652\n",
      "Epoch 226/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5159 - accuracy: 0.7659\n",
      "Epoch 227/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5161 - accuracy: 0.7653\n",
      "Epoch 228/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5184 - accuracy: 0.7636\n",
      "Epoch 229/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5175 - accuracy: 0.7657\n",
      "Epoch 230/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5189 - accuracy: 0.7668\n",
      "Epoch 231/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5163 - accuracy: 0.7650\n",
      "Epoch 232/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5166 - accuracy: 0.7663\n",
      "Epoch 233/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5162 - accuracy: 0.7677\n",
      "Epoch 234/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5170 - accuracy: 0.7648\n",
      "Epoch 235/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5155 - accuracy: 0.7657\n",
      "Epoch 236/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5144 - accuracy: 0.7661\n",
      "Epoch 237/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5184 - accuracy: 0.7653\n",
      "Epoch 238/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5156 - accuracy: 0.7667\n",
      "Epoch 239/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5148 - accuracy: 0.7658\n",
      "Epoch 240/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5145 - accuracy: 0.7644\n",
      "Epoch 241/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5146 - accuracy: 0.7660\n",
      "Epoch 242/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5165 - accuracy: 0.7663\n",
      "Epoch 243/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5131 - accuracy: 0.7690\n",
      "Epoch 244/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5140 - accuracy: 0.7680\n",
      "Epoch 245/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5121 - accuracy: 0.7668\n",
      "Epoch 246/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5138 - accuracy: 0.7696\n",
      "Epoch 247/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5115 - accuracy: 0.7658\n",
      "Epoch 248/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5153 - accuracy: 0.7678\n",
      "Epoch 249/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5138 - accuracy: 0.7668\n",
      "Epoch 250/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5128 - accuracy: 0.7682\n",
      "Epoch 251/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5110 - accuracy: 0.7686\n",
      "Epoch 252/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5133 - accuracy: 0.7663\n",
      "Epoch 253/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5142 - accuracy: 0.7662\n",
      "Epoch 254/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5159 - accuracy: 0.7681\n",
      "Epoch 255/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5121 - accuracy: 0.7668\n",
      "Epoch 256/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5124 - accuracy: 0.7720\n",
      "Epoch 257/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5119 - accuracy: 0.7662\n",
      "Epoch 258/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5158 - accuracy: 0.7676\n",
      "Epoch 259/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5133 - accuracy: 0.7671\n",
      "Epoch 260/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5139 - accuracy: 0.7677\n",
      "Epoch 261/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5113 - accuracy: 0.7637\n",
      "Epoch 262/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5143 - accuracy: 0.7667\n",
      "Epoch 263/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5134 - accuracy: 0.7662\n",
      "Epoch 264/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5128 - accuracy: 0.7680\n",
      "Epoch 265/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5117 - accuracy: 0.7657\n",
      "Epoch 266/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5099 - accuracy: 0.7686\n",
      "Epoch 267/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5097 - accuracy: 0.7706\n",
      "Epoch 268/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5106 - accuracy: 0.7689\n",
      "Epoch 269/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5127 - accuracy: 0.7668\n",
      "Epoch 270/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5106 - accuracy: 0.7705\n",
      "Epoch 271/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5138 - accuracy: 0.7675\n",
      "Epoch 272/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5133 - accuracy: 0.7664\n",
      "Epoch 273/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5113 - accuracy: 0.7696\n",
      "Epoch 274/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5112 - accuracy: 0.7715\n",
      "Epoch 275/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5129 - accuracy: 0.7691\n",
      "Epoch 276/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5111 - accuracy: 0.7700\n",
      "Epoch 277/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5122 - accuracy: 0.7676\n",
      "Epoch 278/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5123 - accuracy: 0.7681\n",
      "Epoch 279/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5133 - accuracy: 0.7650\n",
      "Epoch 280/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5127 - accuracy: 0.7686\n",
      "Epoch 281/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5102 - accuracy: 0.7675\n",
      "Epoch 282/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5122 - accuracy: 0.7659\n",
      "Epoch 283/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5118 - accuracy: 0.7682\n",
      "Epoch 284/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5098 - accuracy: 0.7690\n",
      "Epoch 285/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5081 - accuracy: 0.7696\n",
      "Epoch 286/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5098 - accuracy: 0.7673\n",
      "Epoch 287/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5101 - accuracy: 0.7691\n",
      "Epoch 288/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5128 - accuracy: 0.7667\n",
      "Epoch 289/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5093 - accuracy: 0.7684\n",
      "Epoch 290/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5097 - accuracy: 0.7660\n",
      "Epoch 291/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5084 - accuracy: 0.7714\n",
      "Epoch 292/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5110 - accuracy: 0.7697\n",
      "Epoch 293/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5113 - accuracy: 0.7690\n",
      "Epoch 294/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5111 - accuracy: 0.7687\n",
      "Epoch 295/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5118 - accuracy: 0.7700\n",
      "Epoch 296/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5099 - accuracy: 0.7703\n",
      "Epoch 297/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5112 - accuracy: 0.7684\n",
      "Epoch 298/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5099 - accuracy: 0.7688\n",
      "Epoch 299/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5098 - accuracy: 0.7677\n",
      "Epoch 300/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5127 - accuracy: 0.7681\n",
      "Epoch 301/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5094 - accuracy: 0.7690\n",
      "Epoch 302/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5128 - accuracy: 0.7684\n",
      "Epoch 303/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5078 - accuracy: 0.7694\n",
      "Epoch 304/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5088 - accuracy: 0.7696\n",
      "Epoch 305/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5097 - accuracy: 0.7699\n",
      "Epoch 306/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5112 - accuracy: 0.7695\n",
      "Epoch 307/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5086 - accuracy: 0.7689\n",
      "Epoch 308/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5105 - accuracy: 0.7690\n",
      "Epoch 309/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5086 - accuracy: 0.7702\n",
      "Epoch 310/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5078 - accuracy: 0.7688\n",
      "Epoch 311/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5115 - accuracy: 0.7695\n",
      "Epoch 312/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5102 - accuracy: 0.7661\n",
      "Epoch 313/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5131 - accuracy: 0.7675\n",
      "Epoch 314/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5074 - accuracy: 0.7702\n",
      "Epoch 315/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5093 - accuracy: 0.7692\n",
      "Epoch 316/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5091 - accuracy: 0.7664\n",
      "Epoch 317/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5123 - accuracy: 0.7662\n",
      "Epoch 318/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5071 - accuracy: 0.7672\n",
      "Epoch 319/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5095 - accuracy: 0.7670\n",
      "Epoch 320/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5083 - accuracy: 0.7668\n",
      "Epoch 321/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5096 - accuracy: 0.7696\n",
      "Epoch 322/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5104 - accuracy: 0.7680\n",
      "Epoch 323/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5089 - accuracy: 0.7701\n",
      "Epoch 324/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5069 - accuracy: 0.7681\n",
      "Epoch 325/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5100 - accuracy: 0.7672\n",
      "Epoch 326/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5072 - accuracy: 0.7698\n",
      "Epoch 327/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5112 - accuracy: 0.7669\n",
      "Epoch 328/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5066 - accuracy: 0.7715\n",
      "Epoch 329/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5071 - accuracy: 0.7718\n",
      "Epoch 330/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5090 - accuracy: 0.7692\n",
      "Epoch 331/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5094 - accuracy: 0.7679\n",
      "Epoch 332/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5076 - accuracy: 0.7719\n",
      "Epoch 333/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5079 - accuracy: 0.7695\n",
      "Epoch 334/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5080 - accuracy: 0.7704\n",
      "Epoch 335/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5070 - accuracy: 0.7682\n",
      "Epoch 336/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5079 - accuracy: 0.7709\n",
      "Epoch 337/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5074 - accuracy: 0.7660\n",
      "Epoch 338/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5086 - accuracy: 0.7723\n",
      "Epoch 339/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5085 - accuracy: 0.7720\n",
      "Epoch 340/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5097 - accuracy: 0.7690\n",
      "Epoch 341/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5091 - accuracy: 0.7685\n",
      "Epoch 342/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5090 - accuracy: 0.7690\n",
      "Epoch 343/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5085 - accuracy: 0.7702\n",
      "Epoch 344/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.7694\n",
      "Epoch 345/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5080 - accuracy: 0.7680\n",
      "Epoch 346/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5100 - accuracy: 0.7679\n",
      "Epoch 347/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5086 - accuracy: 0.7703\n",
      "Epoch 348/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5078 - accuracy: 0.7733\n",
      "Epoch 349/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5085 - accuracy: 0.7693\n",
      "Epoch 350/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7690\n",
      "Epoch 351/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5075 - accuracy: 0.7710\n",
      "Epoch 352/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5092 - accuracy: 0.7693\n",
      "Epoch 353/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5084 - accuracy: 0.7688\n",
      "Epoch 354/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5071 - accuracy: 0.7706\n",
      "Epoch 355/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5037 - accuracy: 0.7683\n",
      "Epoch 356/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5085 - accuracy: 0.7711\n",
      "Epoch 357/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5065 - accuracy: 0.7678\n",
      "Epoch 358/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5088 - accuracy: 0.7694\n",
      "Epoch 359/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5090 - accuracy: 0.7693\n",
      "Epoch 360/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5059 - accuracy: 0.7706\n",
      "Epoch 361/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5053 - accuracy: 0.7713\n",
      "Epoch 362/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5066 - accuracy: 0.7720\n",
      "Epoch 363/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5089 - accuracy: 0.7707\n",
      "Epoch 364/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5076 - accuracy: 0.7679\n",
      "Epoch 365/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5080 - accuracy: 0.7699\n",
      "Epoch 366/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5067 - accuracy: 0.7702\n",
      "Epoch 367/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5062 - accuracy: 0.7712\n",
      "Epoch 368/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5070 - accuracy: 0.7694\n",
      "Epoch 369/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5095 - accuracy: 0.7675\n",
      "Epoch 370/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5110 - accuracy: 0.7683\n",
      "Epoch 371/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5067 - accuracy: 0.7691\n",
      "Epoch 372/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5066 - accuracy: 0.7688\n",
      "Epoch 373/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5065 - accuracy: 0.7666\n",
      "Epoch 374/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5084 - accuracy: 0.7714\n",
      "Epoch 375/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5037 - accuracy: 0.7704\n",
      "Epoch 376/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5062 - accuracy: 0.7722\n",
      "Epoch 377/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5066 - accuracy: 0.7716\n",
      "Epoch 378/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.7690\n",
      "Epoch 379/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5081 - accuracy: 0.7706\n",
      "Epoch 380/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5066 - accuracy: 0.7666\n",
      "Epoch 381/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5078 - accuracy: 0.7687\n",
      "Epoch 382/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5066 - accuracy: 0.7712\n",
      "Epoch 383/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5056 - accuracy: 0.7711\n",
      "Epoch 384/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5077 - accuracy: 0.7700\n",
      "Epoch 385/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5066 - accuracy: 0.7697\n",
      "Epoch 386/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5061 - accuracy: 0.7707\n",
      "Epoch 387/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5081 - accuracy: 0.7688\n",
      "Epoch 388/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5056 - accuracy: 0.7732\n",
      "Epoch 389/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.7694\n",
      "Epoch 390/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5050 - accuracy: 0.7724\n",
      "Epoch 391/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5059 - accuracy: 0.7685\n",
      "Epoch 392/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5088 - accuracy: 0.7725\n",
      "Epoch 393/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5068 - accuracy: 0.7706\n",
      "Epoch 394/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5104 - accuracy: 0.7685\n",
      "Epoch 395/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5085 - accuracy: 0.7696\n",
      "Epoch 396/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5076 - accuracy: 0.7691\n",
      "Epoch 397/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5035 - accuracy: 0.7721\n",
      "Epoch 398/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5060 - accuracy: 0.7731\n",
      "Epoch 399/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5047 - accuracy: 0.7682\n",
      "Epoch 400/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5072 - accuracy: 0.7685\n",
      "Epoch 401/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5041 - accuracy: 0.7727\n",
      "Epoch 402/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5049 - accuracy: 0.7714\n",
      "Epoch 403/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.7690\n",
      "Epoch 404/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5060 - accuracy: 0.7726\n",
      "Epoch 405/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5079 - accuracy: 0.7727\n",
      "Epoch 406/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5069 - accuracy: 0.7685\n",
      "Epoch 407/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5044 - accuracy: 0.7705\n",
      "Epoch 408/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5044 - accuracy: 0.7714\n",
      "Epoch 409/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5067 - accuracy: 0.7718\n",
      "Epoch 410/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5041 - accuracy: 0.7722\n",
      "Epoch 411/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5055 - accuracy: 0.7702\n",
      "Epoch 412/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5048 - accuracy: 0.7668\n",
      "Epoch 413/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5071 - accuracy: 0.7695\n",
      "Epoch 414/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5055 - accuracy: 0.7701\n",
      "Epoch 415/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5068 - accuracy: 0.7664\n",
      "Epoch 416/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5073 - accuracy: 0.7702\n",
      "Epoch 417/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5056 - accuracy: 0.7712\n",
      "Epoch 418/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5040 - accuracy: 0.7691\n",
      "Epoch 419/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5100 - accuracy: 0.7724\n",
      "Epoch 420/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5066 - accuracy: 0.7685\n",
      "Epoch 421/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.7705\n",
      "Epoch 422/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7685\n",
      "Epoch 423/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5042 - accuracy: 0.7718\n",
      "Epoch 424/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5075 - accuracy: 0.7700\n",
      "Epoch 425/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5038 - accuracy: 0.7712\n",
      "Epoch 426/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5079 - accuracy: 0.7698\n",
      "Epoch 427/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5045 - accuracy: 0.7711\n",
      "Epoch 428/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5069 - accuracy: 0.7713\n",
      "Epoch 429/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5044 - accuracy: 0.7714\n",
      "Epoch 430/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5044 - accuracy: 0.7728\n",
      "Epoch 431/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5047 - accuracy: 0.7709\n",
      "Epoch 432/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5063 - accuracy: 0.7696\n",
      "Epoch 433/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5059 - accuracy: 0.7683\n",
      "Epoch 434/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5084 - accuracy: 0.7681\n",
      "Epoch 435/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5036 - accuracy: 0.7716\n",
      "Epoch 436/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5027 - accuracy: 0.7696\n",
      "Epoch 437/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5029 - accuracy: 0.7709\n",
      "Epoch 438/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5066 - accuracy: 0.7711\n",
      "Epoch 439/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5043 - accuracy: 0.7696\n",
      "Epoch 440/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5038 - accuracy: 0.7728\n",
      "Epoch 441/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5055 - accuracy: 0.7719\n",
      "Epoch 442/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5070 - accuracy: 0.7713\n",
      "Epoch 443/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5039 - accuracy: 0.7719\n",
      "Epoch 444/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5027 - accuracy: 0.7719\n",
      "Epoch 445/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5032 - accuracy: 0.7718\n",
      "Epoch 446/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.7719\n",
      "Epoch 447/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5050 - accuracy: 0.7708\n",
      "Epoch 448/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5040 - accuracy: 0.7714\n",
      "Epoch 449/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5047 - accuracy: 0.7694\n",
      "Epoch 450/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5035 - accuracy: 0.7704\n",
      "Epoch 451/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5046 - accuracy: 0.7701\n",
      "Epoch 452/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5032 - accuracy: 0.7703\n",
      "Epoch 453/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5031 - accuracy: 0.7707\n",
      "Epoch 454/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.7698\n",
      "Epoch 455/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5046 - accuracy: 0.7712\n",
      "Epoch 456/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5033 - accuracy: 0.7752\n",
      "Epoch 457/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5062 - accuracy: 0.7705\n",
      "Epoch 458/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5047 - accuracy: 0.7708\n",
      "Epoch 459/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5079 - accuracy: 0.7680\n",
      "Epoch 460/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5062 - accuracy: 0.7705\n",
      "Epoch 461/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5042 - accuracy: 0.7712\n",
      "Epoch 462/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5025 - accuracy: 0.7715\n",
      "Epoch 463/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5035 - accuracy: 0.7715\n",
      "Epoch 464/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5050 - accuracy: 0.7689\n",
      "Epoch 465/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5032 - accuracy: 0.7715\n",
      "Epoch 466/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5025 - accuracy: 0.7713\n",
      "Epoch 467/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5028 - accuracy: 0.7728\n",
      "Epoch 468/500\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.5051 - accuracy: 0.7708\n",
      "Epoch 469/500\n",
      "626/626 [==============================] - 3s 4ms/step - loss: 0.5056 - accuracy: 0.7721\n",
      "Epoch 470/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5015 - accuracy: 0.7713\n",
      "Epoch 471/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5050 - accuracy: 0.7708\n",
      "Epoch 472/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5011 - accuracy: 0.7703\n",
      "Epoch 473/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5068 - accuracy: 0.7699\n",
      "Epoch 474/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5031 - accuracy: 0.7710\n",
      "Epoch 475/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5047 - accuracy: 0.7697\n",
      "Epoch 476/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5026 - accuracy: 0.7709\n",
      "Epoch 477/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5053 - accuracy: 0.7724\n",
      "Epoch 478/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5029 - accuracy: 0.7720\n",
      "Epoch 479/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5022 - accuracy: 0.7719\n",
      "Epoch 480/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5048 - accuracy: 0.7734\n",
      "Epoch 481/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5029 - accuracy: 0.7702\n",
      "Epoch 482/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5080 - accuracy: 0.7674\n",
      "Epoch 483/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5036 - accuracy: 0.7697\n",
      "Epoch 484/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5026 - accuracy: 0.7741\n",
      "Epoch 485/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5049 - accuracy: 0.7694\n",
      "Epoch 486/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5060 - accuracy: 0.7707\n",
      "Epoch 487/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5038 - accuracy: 0.7709\n",
      "Epoch 488/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5052 - accuracy: 0.7708\n",
      "Epoch 489/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5023 - accuracy: 0.7741\n",
      "Epoch 490/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5049 - accuracy: 0.7700\n",
      "Epoch 491/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5028 - accuracy: 0.7716\n",
      "Epoch 492/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5044 - accuracy: 0.7701\n",
      "Epoch 493/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5037 - accuracy: 0.7707\n",
      "Epoch 494/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5053 - accuracy: 0.7695\n",
      "Epoch 495/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5073 - accuracy: 0.7688\n",
      "Epoch 496/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5032 - accuracy: 0.7722\n",
      "Epoch 497/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5031 - accuracy: 0.7698\n",
      "Epoch 498/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5061 - accuracy: 0.7706\n",
      "Epoch 499/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5047 - accuracy: 0.7709\n",
      "Epoch 500/500\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5023 - accuracy: 0.7715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x173ae77c6a0>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "nn_t9.fit(X_train_scaled, y_train, epochs = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "898a37ee-eaf5-471e-9347-a36606a0904e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the testing data to make the model predictions\n",
    "y_pred_nn_t9 = (nn_t9.predict(X_test_scaled) > 0.5).astype(\"int64\")\n",
    "\n",
    "# Review the model's predicted values\n",
    "y_pred_nn_t9[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "05d2a13d-60b9-438c-a9ae-2b2b66f5e337",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78      3540\n",
      "           1       0.75      0.75      0.75      3137\n",
      "\n",
      "    accuracy                           0.76      6677\n",
      "   macro avg       0.76      0.76      0.76      6677\n",
      "weighted avg       0.76      0.76      0.76      6677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "testing_report_nn_t9 = classification_report(y_test, y_pred_nn_t9)\n",
    "print(testing_report_nn_t9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b2c02237-7253-4c4d-b789-85451bc2932e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7640047528226074"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#roc_auc_score\n",
    "display(roc_auc_score(y_test, y_pred_nn_t9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688b8fc4-5a9b-44ee-9f04-af7fc8399bb9",
   "metadata": {},
   "source": [
    "#### 3. xi) - (10th Trial) Deep learning model using:\n",
    "\n",
    "**Input Features:** 54<br>\n",
    "**Output Neuron(s):** 1<br>\n",
    "**Loss:** Binary Crossentropy<br>\n",
    "**Optimizer:** SGD<br>\n",
    "**Metrics:** Accuracy<br>\n",
    "**Epochs:** 150<br>\n",
    "> *Layer 1*<br>\n",
    "**Hidden Nodes:** 27<br>\n",
    "**Activation Function:** Sigmoid<br>\n",
    "**Dropout Rate:** 0.5<br>\n",
    "\n",
    "> *Layer 2*<br>\n",
    "**Hidden Nodes:** 14<br>\n",
    "**Activation Function:** Sigmoid<br>\n",
    "**Dropout Rate:** 0.2<br>\n",
    "\n",
    "> *Layer 3*<br>\n",
    "**Hidden Nodes:** 7<br>\n",
    "**Activation Function:** Sigmoid<br>\n",
    "**Dropout Rate:** 0.2<br>\n",
    "\n",
    "> *Layer 4*<br>\n",
    "**Hidden Nodes:** 4<br>\n",
    "**Activation Function:** Sigmoid<br>\n",
    "\n",
    "> *Output Layer*<br>\n",
    "**Activation Function:** Sigmoid\n",
    "\n",
    "**AUC SCORE:** 0.7645604494560099 [Increase of ~0.0118 from baseline]<br>\n",
    "**Changes from Baseline:**<br>\n",
    "Optimizer, Adam --> SGD;<br>\n",
    "Activation functions in layers 1 and 2, ReLu --> Sigmoid;<br>\n",
    "Addition of hidden layer 3, containing 7 neurons & Sigmoid activation function;<br>\n",
    "Addition of hidden layer 4, containing 4 neurons & Sigmoid activation function; <br>\n",
    "Epochs, 50 --> 150<br>\n",
    "Addition of dropout technique to prevent overfitting, with rate of 0.5 for input layer and 0.2 for layers 2 and 3 (no dropout for layer 4).<br>\n",
    "**Result:**<br>\n",
    "An even higher AUC score than the last test. Epochs were altered to 150 and a 4th hidden layer was added to the model.<br>\n",
    "No dropout layer was added after the fourth hidden layer as testing showed that doing so greatly decreased the model's ability to generate valuable predictions.<br>\n",
    "Doing so reduced the AUC score to 0.5 (by setting dropout rate for layer 4 to 0.2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "584c393f-fb8b-45de-801f-18a7580f6f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the fourth hidden layer\n",
    "hidden_nodes_layer4 = (hidden_nodes_layer3 + 1)//2\n",
    "\n",
    "# Review the number hidden nodes in the third layer\n",
    "hidden_nodes_layer4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "cd1ce9a4-8b39-4a00-a998-2b79866d83ae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_63 (Dense)            (None, 27)                1485      \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 27)                0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 14)                392       \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 14)                0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 7)                 105       \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 7)                 0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 4)                 32        \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,019\n",
      "Trainable params: 2,019\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the Sequential model instance for 10th Trial\n",
    "nn_t10 = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_t10.add(Dense(units = hidden_nodes_layer1, activation = \"sigmoid\", input_dim = number_input_features))\n",
    "\n",
    "# Add the first dropout layer\n",
    "nn_t10.add(Dropout(0.5))\n",
    "\n",
    "# Add the second hidden layer\n",
    "nn_t10.add(Dense(units = hidden_nodes_layer2, activation = \"sigmoid\"))\n",
    "\n",
    "# Add the second dropout layer\n",
    "nn_t10.add(Dropout(0.2))\n",
    "\n",
    "# Add the third hidden layer\n",
    "nn_t10.add(Dense(units = hidden_nodes_layer3, activation = \"sigmoid\"))\n",
    "\n",
    "# Add the third dropout layer\n",
    "nn_t10.add(Dropout(0.2))\n",
    "\n",
    "# Add the fourth hidden layer\n",
    "nn_t10.add(Dense(units = hidden_nodes_layer4, activation = \"sigmoid\"))\n",
    "\n",
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn_t10.add(Dense(units = number_output_neurons, activation = \"sigmoid\"))\n",
    "\n",
    "# Display the Sequential model summary\n",
    "nn_t10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b3518ea1-d5a8-4667-90b4-fa70713bfed9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn_t10.compile(loss = \"binary_crossentropy\", optimizer = \"SGD\", metrics =[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "15f79dae-54a8-4aa3-91e2-72cfdc198108",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "626/626 [==============================] - 2s 2ms/step - loss: 0.7165 - accuracy: 0.5358\n",
      "Epoch 2/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6913 - accuracy: 0.5359\n",
      "Epoch 3/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6916 - accuracy: 0.5360\n",
      "Epoch 4/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6913 - accuracy: 0.5350\n",
      "Epoch 5/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6905 - accuracy: 0.5356\n",
      "Epoch 6/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6908 - accuracy: 0.5349\n",
      "Epoch 7/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6911 - accuracy: 0.5349\n",
      "Epoch 8/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5361\n",
      "Epoch 9/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6903 - accuracy: 0.5359\n",
      "Epoch 10/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6908 - accuracy: 0.5359\n",
      "Epoch 11/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6905 - accuracy: 0.5361\n",
      "Epoch 12/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6907 - accuracy: 0.5345\n",
      "Epoch 13/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6910 - accuracy: 0.5356\n",
      "Epoch 14/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6905 - accuracy: 0.5361\n",
      "Epoch 15/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6912 - accuracy: 0.5353\n",
      "Epoch 16/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6909 - accuracy: 0.5354\n",
      "Epoch 17/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6907 - accuracy: 0.5357\n",
      "Epoch 18/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6905 - accuracy: 0.5356\n",
      "Epoch 19/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6905 - accuracy: 0.5365\n",
      "Epoch 20/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6907 - accuracy: 0.5363\n",
      "Epoch 21/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6905 - accuracy: 0.5357\n",
      "Epoch 22/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6909 - accuracy: 0.5358\n",
      "Epoch 23/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6906 - accuracy: 0.5367\n",
      "Epoch 24/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6906 - accuracy: 0.5361\n",
      "Epoch 25/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6907 - accuracy: 0.5357\n",
      "Epoch 26/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6908 - accuracy: 0.5355\n",
      "Epoch 27/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6901 - accuracy: 0.5361\n",
      "Epoch 28/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6900 - accuracy: 0.5354\n",
      "Epoch 29/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6902 - accuracy: 0.5362\n",
      "Epoch 30/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6902 - accuracy: 0.5358\n",
      "Epoch 31/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6903 - accuracy: 0.5357\n",
      "Epoch 32/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6902 - accuracy: 0.5357\n",
      "Epoch 33/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6898 - accuracy: 0.5358\n",
      "Epoch 34/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6905 - accuracy: 0.5361\n",
      "Epoch 35/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6902 - accuracy: 0.5357\n",
      "Epoch 36/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6904 - accuracy: 0.5355\n",
      "Epoch 37/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6900 - accuracy: 0.5357\n",
      "Epoch 38/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6902 - accuracy: 0.5359\n",
      "Epoch 39/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6901 - accuracy: 0.5360\n",
      "Epoch 40/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6899 - accuracy: 0.5360\n",
      "Epoch 41/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6900 - accuracy: 0.5357\n",
      "Epoch 42/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6899 - accuracy: 0.5360\n",
      "Epoch 43/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6903 - accuracy: 0.5360\n",
      "Epoch 44/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6901 - accuracy: 0.5355\n",
      "Epoch 45/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6897 - accuracy: 0.5360\n",
      "Epoch 46/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6900 - accuracy: 0.5362\n",
      "Epoch 47/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6893 - accuracy: 0.5357\n",
      "Epoch 48/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6895 - accuracy: 0.5358\n",
      "Epoch 49/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6896 - accuracy: 0.5362\n",
      "Epoch 50/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6896 - accuracy: 0.5364\n",
      "Epoch 51/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6897 - accuracy: 0.5359\n",
      "Epoch 52/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6894 - accuracy: 0.5359\n",
      "Epoch 53/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6901 - accuracy: 0.5363\n",
      "Epoch 54/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6894 - accuracy: 0.5358\n",
      "Epoch 55/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6896 - accuracy: 0.5363\n",
      "Epoch 56/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6894 - accuracy: 0.5357\n",
      "Epoch 57/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6889 - accuracy: 0.5359\n",
      "Epoch 58/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6894 - accuracy: 0.5362\n",
      "Epoch 59/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6886 - accuracy: 0.5361\n",
      "Epoch 60/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6889 - accuracy: 0.5364\n",
      "Epoch 61/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6884 - accuracy: 0.5372\n",
      "Epoch 62/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6885 - accuracy: 0.5362\n",
      "Epoch 63/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6883 - accuracy: 0.5368\n",
      "Epoch 64/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6882 - accuracy: 0.5382\n",
      "Epoch 65/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6881 - accuracy: 0.5380\n",
      "Epoch 66/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6885 - accuracy: 0.5378\n",
      "Epoch 67/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6879 - accuracy: 0.5400\n",
      "Epoch 68/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6879 - accuracy: 0.5391\n",
      "Epoch 69/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6877 - accuracy: 0.5422\n",
      "Epoch 70/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6869 - accuracy: 0.5452\n",
      "Epoch 71/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6873 - accuracy: 0.5413\n",
      "Epoch 72/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6871 - accuracy: 0.5445\n",
      "Epoch 73/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6865 - accuracy: 0.5506\n",
      "Epoch 74/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6868 - accuracy: 0.5473\n",
      "Epoch 75/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6862 - accuracy: 0.5493\n",
      "Epoch 76/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6863 - accuracy: 0.5509\n",
      "Epoch 77/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6856 - accuracy: 0.5582\n",
      "Epoch 78/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6853 - accuracy: 0.5564\n",
      "Epoch 79/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6849 - accuracy: 0.5537\n",
      "Epoch 80/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6846 - accuracy: 0.5613\n",
      "Epoch 81/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6840 - accuracy: 0.5661\n",
      "Epoch 82/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6838 - accuracy: 0.5616\n",
      "Epoch 83/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6826 - accuracy: 0.5706\n",
      "Epoch 84/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6816 - accuracy: 0.5753\n",
      "Epoch 85/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6819 - accuracy: 0.5769\n",
      "Epoch 86/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6808 - accuracy: 0.5763\n",
      "Epoch 87/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6802 - accuracy: 0.5834\n",
      "Epoch 88/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6784 - accuracy: 0.5879\n",
      "Epoch 89/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6774 - accuracy: 0.5859\n",
      "Epoch 90/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6770 - accuracy: 0.5921\n",
      "Epoch 91/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6748 - accuracy: 0.6005\n",
      "Epoch 92/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6745 - accuracy: 0.5975\n",
      "Epoch 93/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6735 - accuracy: 0.5980\n",
      "Epoch 94/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6709 - accuracy: 0.6069\n",
      "Epoch 95/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6690 - accuracy: 0.6074\n",
      "Epoch 96/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6662 - accuracy: 0.6159\n",
      "Epoch 97/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6653 - accuracy: 0.6166\n",
      "Epoch 98/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6619 - accuracy: 0.6192\n",
      "Epoch 99/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6589 - accuracy: 0.6225\n",
      "Epoch 100/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6562 - accuracy: 0.6300\n",
      "Epoch 101/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6524 - accuracy: 0.6317\n",
      "Epoch 102/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6488 - accuracy: 0.6339\n",
      "Epoch 103/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6445 - accuracy: 0.6384\n",
      "Epoch 104/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6400 - accuracy: 0.6425\n",
      "Epoch 105/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6356 - accuracy: 0.6507\n",
      "Epoch 106/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6308 - accuracy: 0.6582\n",
      "Epoch 107/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6281 - accuracy: 0.6582\n",
      "Epoch 108/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6200 - accuracy: 0.6696\n",
      "Epoch 109/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6183 - accuracy: 0.6677\n",
      "Epoch 110/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6139 - accuracy: 0.6758\n",
      "Epoch 111/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6073 - accuracy: 0.6840\n",
      "Epoch 112/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6026 - accuracy: 0.6848\n",
      "Epoch 113/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.6012 - accuracy: 0.6871\n",
      "Epoch 114/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5944 - accuracy: 0.6947\n",
      "Epoch 115/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5944 - accuracy: 0.6937\n",
      "Epoch 116/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5908 - accuracy: 0.6988\n",
      "Epoch 117/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5834 - accuracy: 0.7019\n",
      "Epoch 118/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5822 - accuracy: 0.7059\n",
      "Epoch 119/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5835 - accuracy: 0.7052\n",
      "Epoch 120/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5781 - accuracy: 0.7077\n",
      "Epoch 121/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5724 - accuracy: 0.7158\n",
      "Epoch 122/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5707 - accuracy: 0.7189\n",
      "Epoch 123/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5681 - accuracy: 0.7191\n",
      "Epoch 124/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5640 - accuracy: 0.7207\n",
      "Epoch 125/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5686 - accuracy: 0.7201\n",
      "Epoch 126/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5618 - accuracy: 0.7224\n",
      "Epoch 127/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5633 - accuracy: 0.7233\n",
      "Epoch 128/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5645 - accuracy: 0.7217\n",
      "Epoch 129/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5580 - accuracy: 0.7283\n",
      "Epoch 130/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5578 - accuracy: 0.7284\n",
      "Epoch 131/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5550 - accuracy: 0.7332\n",
      "Epoch 132/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5508 - accuracy: 0.7343\n",
      "Epoch 133/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5532 - accuracy: 0.7336\n",
      "Epoch 134/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5494 - accuracy: 0.7361\n",
      "Epoch 135/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5512 - accuracy: 0.7337\n",
      "Epoch 136/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5502 - accuracy: 0.7367\n",
      "Epoch 137/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5453 - accuracy: 0.7408\n",
      "Epoch 138/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5498 - accuracy: 0.7375\n",
      "Epoch 139/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5494 - accuracy: 0.7364\n",
      "Epoch 140/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5462 - accuracy: 0.7415\n",
      "Epoch 141/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5436 - accuracy: 0.7435\n",
      "Epoch 142/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5421 - accuracy: 0.7408\n",
      "Epoch 143/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5441 - accuracy: 0.7413\n",
      "Epoch 144/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5429 - accuracy: 0.7430\n",
      "Epoch 145/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5432 - accuracy: 0.7412\n",
      "Epoch 146/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7470\n",
      "Epoch 147/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5411 - accuracy: 0.7451\n",
      "Epoch 148/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.7458\n",
      "Epoch 149/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5364 - accuracy: 0.7482\n",
      "Epoch 150/150\n",
      "626/626 [==============================] - 1s 2ms/step - loss: 0.5393 - accuracy: 0.7437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x173c4cdd310>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "nn_t10.fit(X_train_scaled, y_train, epochs = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "17464182-f7c8-4687-beb3-51b46679504d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "209/209 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the testing data to make the model predictions\n",
    "y_pred_nn_t10 = (nn_t10.predict(X_test_scaled) > 0.5).astype(\"int64\")\n",
    "\n",
    "# Review the model's predicted values\n",
    "y_pred_nn_t10[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9c1e9e80-20f3-4f22-aebd-da6fe104e45f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.78      3540\n",
      "           1       0.76      0.73      0.75      3137\n",
      "\n",
      "    accuracy                           0.77      6677\n",
      "   macro avg       0.77      0.76      0.77      6677\n",
      "weighted avg       0.77      0.77      0.77      6677\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "testing_report_nn_t10 = classification_report(y_test, y_pred_nn_t10)\n",
    "print(testing_report_nn_t10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f3a27125-bc27-4a60-a7ba-b6dd9c9a5761",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7645604494560099"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#roc_auc_score\n",
    "display(roc_auc_score(y_test, y_pred_nn_t10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "de00f594-d1ac-48fb-90c0-ae2ef057b376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABfcAAACICAYAAABKr9EFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAACSq0lEQVR4nO2dd3hU1533P0dCDZDoQvReRe+9d4PBNm7YRsTp2cTJZnez2Z4t77vZ7Lsl2RTH6yQIbNxLwDRjug3GgOmoAKKqF9T7zHn/OHfEaFDXFM3o93kePTAzt5x7z/ee8j3n/K7SWiMIgiAIgiAIgiAIgiAIgiAIgv8Q5OsECIIgCIIgCIIgCIIgCIIgCILQPMTcFwRBEARBEARBEARBEARBEAQ/Q8x9QRAEQRAEQRAEQRAEQRAEQfAzxNwXBEEQBEEQBEEQBEEQBEEQBD9DzH1BEARBEARBEARBEARBEARB8DPE3BcEQRAEQRAEQRAEQRAEQRAEPyOgzH2l1E+UUq81cdsjSqmvufHcbyilNlj/f04p9bH1/zClVKJSKtpd5/IWzvfI+ZqEummL+rM+Fyulhlr//0+l1LfcdV7hAX6S/y8rpf7O+v8EpdQJd6VBMLRVHTSy3xdKqVh3pUN4QFvRQyPbSVngIfwk/+crpZKcPkt54Cb8NP+vKKUWWf9/SSn1U3elqb0RAPn/10qpV63/91ZKJSilwtyVxvZKW9GFtBN9T1vRQiPbSRvRg/iJBqSd6C9orRv8A24BmUAnp+++Bhxx+qyBS0CQ03f/Amyt55iLrH3ed/l+ovX9kcbSVc9xfwK81sRtjwBfq+e3Z4AkoADIAuKBqAaONQG4Cqh6fv8R8B8tuSan+2UHiq2/VOAfW3q8Zpy33nvkhXN3sq61tA79aeCUy+dM57wHfmblyR3rONeB/wZ6ulN/wCTgrJXONGB3A9teccpDm/W3y+U6SoByK78rnfT3Tes8hcA96/o6OOnPWR+O4/9PHWnoA9wFQluYH3vq+E0Dw12+q/UsAlHW/X8oPxo576068r/e8scpP6qAHGBSPc+Ttu6l8z2rriv/gTjr+685facwZVwqppw4AvzKcc3AYGAPcB/IAH7pyK/Gni3cXP40cn/3AOtasN9W6371reP7f3H5brB1/5yvfxNwxrrv6cBeYJ67dGB9DgPOY56jDOCH9ejgfeCvnXRQan2vHfq0rqvSRS/BTsdaB1y2vr+L03Ptcs5DzveiDengKeC9FuznuIc/quP7e3VsX+t6gZHAO5hntQC4CPzQ+d66Qw+W3m5beXgH6N7AtVS75LNDC67lwh9wKfuoXcY7ypQkHpQLS4AvMWVPCvCNhu6PN/WAn5QFLcz/MOD3QAVQhktZ4JL/rnlYbn3/mdN1NVQWvGLlkx3YglNdaKXjvzBthfvAr4GQtpD/Lvu26fKgufnv9N2/WPnnKA9KgA+B7tTRLgQG8qA+sPGgPPgzp216ATuAfCtPX3f67f8BuZj2SCKw2eU6JvGg/XgW8xz4PP9djhOOaXNGN3M/hSnjrtbz/C5z+W4L8KnT51DMs3PNyqdbmGd4cGvz3+W8g4HDPHjOj7v8XtMvsNJTRe1nf2gdxyq18nsZtZ//h3TntG8Ypvwro+72ik/yv47j/hr4Xgv2+4l1H2fU8f1D/XYerltXAseAIiAbOAo8WoeuWlMuKODfMM9sLqaftYi6+4t/Re1ywVFOTHXaZoqV5mIrXd93vW5gobWfa13prJUc4KV67qvUC3Wfs9lasO55PuYZ/xCXdqLTdeyldhngyPvrTts2VC/8DNNPKLTy+CC1+8vO/YkTwNj67o03tYAftRFboIFwTP3i8AW+aETLzv2EMkx7r6afgCn7v8Q8v3eBp+o4Vpy1z9eoXU/8KaYOKLDSFNbQ8+FNDbjs6zflQUv+aKC+dtluILXLg2a1E5226Y6p2z51+T4YU0elYeq/c0DXhtLe1Jn7HYDvN7JNX4yomko2MEcp1cPpuzgguRnH8BSfAXO11l2AoZjr/5cGtv8mJqN0Pb/vAOJaOdshTWvdWWvdGZgHfLUpI21+zEZMRzwCCKFx/UViKgWUUqHA80BXYBXGWJ6DaazNsLZvtf6s8/wR00DrBlwAFlrfP4TWOtYpD48DeZgCypmJwAhMRyqUB/p7BvgBZnBiJrAU+HNrn28Cf+d07N6Yysb12Git0zGdjkebep0WjvxYoZTq05wdrftxEIil/vxoiKaWP8/xID/+H3AD+GM9+ZGNaZANsu5ZJKZAznBJezdMI/6Ky/5PAi8C8zEF8kngcafff42pWPtgOvALge80cg0O3F3+NMTr1v5NRinVCXgCU6k+19wTKqV+iBnY+b8YrQ7E3K/1jeza3HroJ5i8eRdYDPxIKbXKZftsjBZ/6/T8vIzRZr7WOsdp2585trH+bNb1jMDcx29hypwkYJFSqoPLdT9nXUNT8aYOdgKLm/tsY8rMPOvfZqGUGgacwjR8x1vX+SQwDfM8NkZT9fBnwG+BFzDGajVGb3WRjWkwOsqF8ZhGWopL2ucBw1x3dinjIzEDCVetfUKAD6y0dAGeBv5TKTWx0Ss1eFoP/lQWQPPKg59g6tX/AfZRd1kAJv97YOW/lY/nMHVFldN2dZYFFhcwZf2XdRz/xxh9j8N0UKYAf9vINTiQ8qA2Le2XdOVBedAbk7eO8qBWu1BrfQdTHyRj2mzjMZ3495yO9z6m3TAIiMa0PRyUAG8Ab2Huyc+VUnOs63VtP8ZjdBFcz7V4M/9r0FqXY8yUzc3cdQHmfgxVSk1vwanfxbRTN2HKy4mYAZCl1u/u6pe+gXnGH8UYO3OVUiOdfnftF7zl8uyn1HGsHsDfWNfQEcCa4Vif7sCUURHAX1J3e8Un+V8HLaknFOa6W1o2bMT0Z7YB/TH37+8xJqgrrdHFN4ANGK1NANZidFFXf7EXVrlg1RPfwbQTvrTS3BNT1/wWo4fhgOsMeQX8HFPuOV+vq1ZsmD5tXUi9UD9N1oLTPd+JKa9dn08H2cBkarcRdli/OfcXGqoXfgeM1lo7+sLjgQHW9br2J3YBO137E/UgbcSHaaoG3sK0EQcB24Hx9bQR4eF+wr9hBsCTrTSPxWjibzB11yRM3eV8XXV6C0qplZh24lKMpzUU+MdGr/IBUh64gSbU1zVore84twlofjvRwb8BCXV8/4+YcmI2xj97ATMZoV6aau7/O/DnSqmuDWzzM+Afm1gAgZn59CFWBauUCsaMAr3uvJFSao5S6rRSqsD6d47Tb0OUUkeVUkVKqQMY49N531lKqRNKqXyl1AXHMsPG0FrfdTF1bJiKuT5WY2YROM67RSn1qdPx7mFGamY15fxNSN9NrNFcp3P+XCl1VylVqJQ6q5Sa7/TbDKXUGeu3TKXUfzr91qR75HpNSimtlPqWUuqaUuq+UupXVgPO8fuLyizfvK+U2q+UGtTMy4zDdKoqMcZpY/r7DJhg6W8z5gE4pLW+qrW2a62ztNb/rLXeY23fav1hzJkY4J+AjzBmssLMzmzs3nbBFETODz9Qr/7KtNbHtdaVWutUK51zrd9r6Q9TEXbAdEYdeeWs3yPAIw/dwYZx5MdFml9Bb8ZUyI81kB8N0dTy56eY6/5vzD1LwCk/XKiV/5gR4yjgVZftfo8Z0R8N/I1T/g/BdOL+gBmJXYhp7OP0+wXMTO1ETOWwrIH01+Du8sc5/5VSW5VSzhX9EWCpat7A4xOYa/4nmlk5K6W6WPv9idb6fa11ida6Smu9S2v9F43s3tx6aDPmGajUWicA/4uZHehMfeVAELUHenoBL9ZTDmzCGH97rb9ETCd9oXXMWUqpU5iOaZMbQe7UgTLhmGo1JpRSf7Qazg4D5yywoqnpU0p1xAz6/QkwQik1ran7WvwjcEJr/UNr0BGtdZLWepPWOr8J+zdVD38FfKS1PobJp3PA40qpuhqCruVCnPVdvGMDS1u/xwwcAbxfV7sEY+wNxMwcwto+CqOPz4ADGJ090YRrbZUelAkPmK+UGueUzl5KqTL1IGTgEfynLIBmlAeYsuCfMQ3iAuouC6Du8mA6sN9lu/4NtAv2YIynSZgBeOd26TpMGfERZkZyH+DbDV+mwZP5r5RapJS653QufygPWtovGYpZWXVMa10M/B1mYD6CxtuFmzEzcfta+V6CmaDwvta6QGtdBeQ7+iWYDhnWtZzC1EdPKxPeIA9jKpzTWldorX9hbTq6rgvxZv4rpW4ppZzbK0doWZvxj5jnobllwzJgObBea31aa11t3d9faa1/Z23W6n6pMib+FOAfMHlfhCmv/9H6vcn9Aqdj/R5j6m7FDAw7Bjaewxh1lRiTdy3wlFJqtfX7ZswswdK62iu+yn/1cLiIU5gBm+b06eZjtP59jJFa5wSoulBKKeA/gX/WWr9q6cCutT6qtf56Hbu0RhdxmFX296x+1n9gJiQ1pb8Yh1m18YVSyjGb9Eut9eta6wpMPfCyqu1XjMVoIRHo5+gvYvoNp5zKqJvAlLraLG5uJ85RSuUopRxG80RLN6Otc/lDveBMc9oIz2OezzuYCSB/R93txLq08CQmj8qt71Zg8mC+dbwTmPrF+Rh7rDriDcyAruM8KzEzyX+GMZCfwRj/Cxu5Vndo4TdKqXedPv+bUuqg9QyC/7URoekaeAT4P1rr+5jJXcnU3UYEJw1Y9+YFoDMPyoO/xRjDBRj/KgV406Wd+EtMvo/GzNR3tBPjMIM/kcBujGn9Z8p7/mW9GvDTdmJLeY462ol1lcF1sBk4prW+BTXlwQDgLxztRK31OecdlFKzMZM7/uDyfTfMxN6va61va8Nl697XS1PN/TOYh/rPG9jmfcyshy1NPCYYs8MxG2QlZgQrzfGjUqo7Rty/wIx8/yewWz0YPd+BEVZPTMctzmnffta+/4LpVP858J5SytmAqxel1Dyrgi7CFE7/Xc92nTBGXlJdvzuRgJkN0GqUGdmdC3zu9PVpTGeyO+a+vKOUCrd++znwc21GiYcBb1vHadU9wjROp2Ou6ylMHqLMioK/xnSYemE6NG84pf8jpdSPG7i+gRiz9XWMQTKGxvWXgDFutmBM1BuYCrohnPV3HWPA/hiYZzVoCoBPMQV0Xfr7Z4xenfV3H4htwr2NAc5qrUtc0nRMKZVhdQ4LqV9/C4Ar9ehvLpDVwEhsLS02Mz9ep/kzuJYB+6wCskkopS5ajdyBmIqyM5BhfVfX4ML7mJHSPJfrvohZMVAXzvn/V5jlfred0rAMY8b8PQ/MOEf+v4lpbN3A5OUtTEfOQTxmsOHfMQV2CWaE21flT51YHZgqYJR1vE1KqYuN7BaHeZ7fBEYrpaY045SzMYMlHzR1B0ubdengF5hVTM446qHvYDqTWU6/XaBuLbjWQ2mY2XY51vm7YzQchWko9QA+dioHtljndC4HFDDOqRzIAv6CBzMwag1EN3Dt7tLBDoyppKztu2EaZG86beNaLuQrM0O9Pp7ArHZ5B2N+tqRceLfRrR6kZ6CVpnzq1kNdq4Dex7RzQpy+K8I0zkfWsT3U1sM3MSZsmtPvf22d/9+sz7+n7nbJ25gy4zkArXUmpkOwGzMLaQ1mNdT3PF0uWObC+8CzTps9BRzVWmdZ2/hFWdBA/v+ijl3ex5S9fTHPv4P6ygKonf9/Zv170On3UOv3MZh2w6fUnf+nMDOb4lz2/SsetAt2AL2U9U6UxvBk/tdBmy4PMKbJQ/WBUxkBdfdLuuKkBa31DUx5MMD6qqF+yWYrjY5+yb9jjLmDSqk8pdRpzMDNQ/0SpVQEZtXlVzD5//eYgUbndmEJ0K++C/Zy/jvjqoVfK6XqW/3k3IF3tBmbZehitPCF1vpuA9u49ku/x8P5/zeY+3D2ob0NsUCK1rrI6bvPgMXW/x/ql2Jmcn+KGZj7a6x+ASZvUzCmvCP/D/NgEk4sxgB09Au6Ysr/N5SZfNEX8/w4eKiM8mH+16C1rsaUexOd0pTfyG5xGOP0Levz2macchTm2Wxq2XDGSl9D5cJJ6vYrYnm4nhhs/b/eckGZgY4FGJPX4VfkYVZwfqGUysJoIpkH5cIWTH/8nzDtzad5UC/cAGY7lQvlmP5snW0Wd7UTtdYnMKZkvFVebQf+Vmud6LRZm64XHO1E6m8jRLvs4qgjVlF3vVDXPXfVQgimLHKwGJPPlZh86w7sd2kjBGH6CfMxK7duWb91xfgqDi38CNNumNmEy2+tFv4MM0lyizITRL8KxDn61P7URmxAA3XxCcZoH+v0XR71txHhgQYcA5df8qCemGWl+zhmNcBHmOdqt1Kqh1JqBmblwS5MffMRD9qJsZi2jaOeGIKZtPi+l/yDBjVQB35RHjTwt6meXWvVBY2UB65sxmlCGEYPSZhyNVeZCQE1g3XKDBD+CvgutX0kMKsAqoGNyniDyUqpP2ksAU0198E0RBvqhGrMyMbfqyaO6lkVSXel1CjMzdjmsskjwDWt9XZr5sYbmIb0OmUMx+mYcCQV1qy8XU77Po+JD77HGuU/gKn01zQxbZ9qs9yjP6YBf6ueTbta/xbV8ztOv3dtZJuG6GsJsRDTQDiFaWA60vua1jrXuk//gYnfOMr6uQoYrpTqqbUu1lo7BgVadY+An2qt87VZunwYM7gAxhD5V611gtUQ/L/AJKsBhNZ6rda6oRd0bQYuaq2vYjo7gzCVYWMmyAWMTntSu5FcJy76O4VpbL2EiXfVFfOgndFaL6tHfwOs3531V4UZca333lodn16Y0XxnFmIakqMxI/d3rGuvpT+l1Fcwo7n/Dxf9WekazYPZonVRS4vNzI83MIMXkxvY3pUeGOO8yWitJ1h5cAezTHYKpiPkWLL40C4YDQ51KX8KqGepllP+T8Q0xmpGTK3C9hUgWWu9zTr+F1j5j6lsO2I66gWYRojzKgSHBt/BLB87islvX5U/DVGjB631Dq31hPo2tPS1GNhhmZUHad5sjB5AjlUuNAlLm3Xp4CWcykDH5ph66C+tz86j23VqoY56qBTTEXOE2ngEY/A6ltN9FzML50+dyoFojAY+x3TwgzD6eN76bgCmY+FIr2O2XmPX7i4dHMfcG8eKro3ASa21s2nhWi501Vq73l9n4jAhCmyY8vlZZULPNJVmlQvaLH3s2kC58EVdu2Hu2ZIWlAubMM/xfzl+U2ZG258AV7TW262vP+Lhdsn/xQxu/xu12yUFmE7Eh5gZwD+y0u2NcmEHtc2dTTxYTu6gzZcFDeT/S3XtgjHfwISqc9CU/B+FacucsM7h4CrmXR5dMWXN1zDvXqnVLrXOnUzt/M+20nEaU2Y4VpU1yezyQv4706bLA8yA6UP1gVMZAXX3Szpg8t+ZAqzwKQ30S7pgJoBUYPVLMJ36CZgl+X+Bma09FvjvOvolL2NmMP5RmxWLnTB1hXObuxpjCtSJl/PfmSLM9TvS8R2tdUNhBh/H3KePMeVjB5o387+pWnDul/4PD+f/FIwZ362efmlnHtZCEtCxnn7p25gBgzMYc9wRUisRU7eW4dQvxRgfjpmOnTEDgjX9AoyBlMyD8DLO4b0eKqN8mP+uONcTnzrd74ew+jtPYuqJKowx09x6AppXNrxIw+VCGnX7Fa56KMCacd2IX7EZk49JDr8CY8h2wKzUmou5X+OcyoV84II2k56GYuK1O3RRhslb53ZBGfXXWe7sL/wE86x/gblPv3L5vU3XC452IvW3EVwHsxx1xBiM3+BMU/oMP8S0950HEGdh8v73mMlff4PR0bNObYRV1rGnYAaKKq19u1rHK7WO4Zi00qQ+d2u0oLUuxfRZ/hMTLu572kSecMYv2ogNaKAuHKsqfuBUHlTSQJgXhwYwmsqg9ozr/hg/6Yr1/3DMfXCERH7V+s7RTrzGg3ZCZ4w+9ljthHzr+0t4oZ/QRA044xflQQN/9dWBdbUN6u03OLAGRHpTewCiP2Yy3WFMefAfmJDRjkl+L2FWatU1CaE/pjweiRmI2Qj8RCm1vKF0NNnc11pfxjTS6p3hawnxDiZuXVPZjjFLFvPw6FxfnGbSWtzGzGzpC9zXtWc+O287CHjSeYQGM8uzWbGhtBmp3EftGY7O5Fv/NrZUI9Jp21oopYqd/gbWs3+aJcQozINURu1QAX+mTBicAutau/BgduhXMcJItEaMHB3J1t4j57AVpZiHwXHcnzsdMw8zQl3vjCQXNvPAwLVhZl/P44H+7NbxnOmAyf87mFHwzjSN1uivDNNBc/4tBFPYNXRvH+fBixZr0Gb5T6U2S4u+j3mQu+CkP2VWRfwUWK3N0qt8a3eH/hyNTGczwpV6tVgPNflhmYFHqV1B26g9MxbrsyNGcS7NfO5caUr5g5kFV0Ht8ieKhhuy2zGVXxDGkHPwHUy6r7hs78j/v8Vc9wBMJf2PmMGZYKVUEMYUisIY/IWY2buL8V350xDN0cMLQILW+rz1+XVgk1PlXE3dWrBbf7lAT9X08G21aGY9BGaQ00FDWnAuB6ZQe+CtL+aaHYOnezAz8BZZv93HPA+/xDQ6KjGNgHuYcmA1ZoZWDqYsAy/rQGutrX0dnftNPDxI1mQdWCb3Yqdj/BHzHDgMnLp0AL4pF25j8qO55cLfYK7D+Z7/N2aGVkod56hpl2A6bnmYsvI2gDJL25/DmPvFmDrzZUy54Q09HAIilFIzrYH2STxc5/lNWQBNzn9Hp8l5tktT8t9RB/9fl9+qgBtOZcHrmPZHU9ql1zEdwkzMgICjY+zcjmgUD+a/M22+PGhhv6Qak//ORGGeRwd1tQtjMGEUe/AgTx0m3Gnrd8egsLMRc9v6PA4zoPek1R78a8wsNuc2dzCNxFK1rskb+e9MJA93dBsiDnjbekYcs8ad24z1lQ3N0oIb+qXF1K2Fq9TRL9BmgktH4LZl7vwc09m+jXmGu1H7+Y/C1AOOc8Xg1C/AlBfjeWCOBLuko84yygf570pz6onHMPntmPzyOrDaaaLWQ1pwqkOqMFqA5oU0bKkuXPUQRe1B4fr6i5sx5ptzWV9mHb+SBzP5Zymluiil1mGu27F9Z2Csky4WYIxI52uOoJFJPO7oL1gDMFsx5dV/WG1HZ9p8veBMM7RQwsOhU5vSZ5iLMfKc+9whmPBav9MmBMebGG3NwqmNoA3nMH0Dx+znjpj20UFMXfC3GAPY3rQrrrmmFmlBa/0Fpn2rsKI8uOBXbURokgYcdX86D8qDUBqfNPcGxqzvQu3yoAzjRyRZg3eOlbq3Mf7PbepvJxZjDF1HO8ERYmcaXuo3NkEDzvhVedAM6msbNKaJOMxLhp0nGJcBt1zKg7uY9/v0xZj7f1PP8Rz1zz9prcu01hcx+dngQE9zZu6DiUv4dRo2af/WSmTHJh5zO8ZI22ONGDmThjFHnBmI6RSlY2ZjdHL5zcFdYLvLCE0n3fAM5froQB0vzwOwHs4bNL5UYwy1l/s5H8P55Ux36trGZfsCzIjXOqgZKfpLzEySbtaIZQGWAa61vqa1fhYzU+zfgHet++bOe+TMXeCbLseNsBrDDaJMTLIRwF8ppTIw5ulojCn1Txj9FfDw7Kb+mMLxbzHxxYbTtJdXOvQXihnR/yUwXylVjDFsH1dKvey0vbP+IoCJStXEoxuIaaRfoeF7G4fLi1vrQWPysAMwTJmXu/wv5m31l6BO/W3GLPNqiHq16Iprflh5MhMz2uq4v3d4sHTVwRAeVFafACtdntXGznvFyoOBwC7r/xswsyTqe6HPFUzH2rn8mcDDBr0z2zGxXS+5lD9LMTPw1lvXPAcz2roQk/8DMeXnfasDu9U6ZxeMedMZ85KarvrBC1+SfVj+1IlVsYTS9LA+mzGrIxxa+E/MIKJjJnp9WrirzYykk5gG64ZmpNERBsVVB7/iwUx0V/4K0zh0rhMmUr8WHOVAIqYT5nw/6qqHOmMq/3RMh36v1nqc1roHxvjvhDF8sjHPcAnmuh0dgJeU03tRmkhrdfAGZmnfIMwz/J7L700uFzCN9iBMnmRgGoLhPFhieQfTKK8ZZLXKyUHULheeaOL5HMsrixsoF1bVs+sVjKnqKBc6YwZ9khs43duY5/9oHeXCKh6UC2A0PQWndglmRc82q2Ps0OA4jB7inQbq/wd41RvlgvX8vY2pSzdh3kNQ01D1l7Kggfx3nWEIgH4QQ/UveFAvNFQWgCkPvoV5bve7/OZaHmhMo78p7dJbwB+01kFa62DMAMLnWut/bSAt9eHW/K+DNl0eANF11QdOZYQzzv2SfGovIx+KKQ/uOm3v2i8Jway2jKd2/l/E5L9zuzCY2oPKj2D6TCsw92W71UZfjxnk6ez0/He2jtMUPJ3/zjSnzdgfsyLleaeyYSNm1apjwlFT2owzrGM1hqNf+pc8nP8XrP+HUHe/9AqmDHM2NyZiBgSb0i91tNEHYrTQh9rP/0QezMa/Yp3fkf9TMIZFtNb6HzDacZ6U1FgZ5c38r8Fq9w+n6WVDHOa67lhaeAeTH46JBvVpwYZ5FpIwz2Zz2grP0XC54DCHXP2KK9QOnzuR2rNe6/IrojCG7QFq1wsXMe1AR7nQ1ZE8TDuiH/CEdU+GYbR01NLGvwPvOJUL4Zj8bqjN4qBV7URlQkn+A2Ym8n+oh1e8tOl6wdFOpP42gmtYHgd7MSF2OlrHcdQL9d1zhxaCMTP0nUnk4Rejh2DaIXW1ERx9RjBaj9daB2utgzCzgEswedJcmq0FZUJ+hGHKuR+5/OY3bcQGNFCXf1mIyRfHyqyOmHZ8Q+UvmL5iCGY1nnM9cZEHkzydGWidfwFG95k88BYet7a5grnHjnriMSDTm/5lQxqoA78oDxr4e66eXWvVBU0oDxyhF5+kdkgeeNBOrIsZmProqnVPfo5p+2QoE0HCMSGwvv3rRmvd4B+mYlvm9Pl/MQXUEafvNDDc6fMBa5ut9RxzEXDP6fM8oK/1/685jo0Z7c7HNEQ6YGLS5QM9rd8/x4QmCbWOUQi8Zv02AGOgrsQUsuHWeftbvx8BvlZP+p7DPIQOUR3FvDCrvnv0C+CvnT5vwSwDdHzuZ92PsMbudxPvV2dMxXLK+rwG8xDGWPfi7zENo2XW788Dvaz/L8MUluHNuUd1XJNrnm8F/sX6/2PAZSDW+twFeLKJ1/pbzFLeGOvvrpX+Isxgxv9iRrIKMIZ+kJWWYsySRzAPfzWmUTXa2qYHZqbUmjruZ0v1d8pKxw8xo5FlVjpCG7i306y0fY6T/jDxvSZZ276IeaFKEqZQPooJq5ELLKhPf5hKogRjSjSUVx8DT7UwP2IwlW8RZpAB4F8xAwqO/Fhm/e7IjzCM0bmvrvxwV/lj3ffbmIZVrnWPbwOh9T1PVpqrgdnO+Y9piI+x8vfbmJnc2xz5j2loFWLenh6GiaGpMcvNsM5bhGnEdMeMUB/AN+VPTf7j9JxanzdhOipN0cJs616Nd9HD65iRajA6LsYYGcGYTs8xTAgvx3F+iDE1NmAaUSHWffqZO3Tg9PkmpvO8A6O7dGBVA+XqPOte/xMPlwMlGMM2BPg/1rnWW79/jimPwzHhNaqAm9ZvAzCDhs9Y92Kute80jF69pgPru6uWDj9w+T4M6wWPTdRCImb5trMOHsUMXvSwtjmB6Uw5zPQfWfkYbv0+zDrnvwMx1nfDMUtBu7qxXIjFPKunrW1uAG/WccwaPWCeiwxc6gVMx9C5XNCYzkA+D+qFLzEDS6NxapdY11tiXfNKzKDpDev6PV4uWN/NxDwHl7H0629lQUvKA8xqt/vWvf8Al7KgnvLgC+A/nfPf6bnKt/JjFQ/qfed2wX9h9P9v1G6XTsOUBysx9fVdTMxwn+Z/HdfepsuD5ua/9dnRL/nQypP5GPPtNcxMKNd74NwufAXTblbUbhf2svK+BFM2bMQ8F7/ClO8vY9ri71rHcW4XhmPaCf+DCcvxXesc32wD+e96f18BftRELfwVJhxNjMtfCmaJP5gJGkmYMlJhnosMatfPOzFl9lRM+zsS07Z9sZX5v9UlvY5+5ArMLMl8K18f6hdgBmSGWtv8HaaP8SsetAs/x/TF/gvTyS+y/l7DlIdFVhoexZSVb1v3vj+mjMrHzOKrq73ik/zHPNevOf02B7jaRC30w+h/hYsWfop55xiY5yYfY/yEYNrL7+JUR2OeqwJMGywK04eYB7zixnJhK0ZfCTxYhXUFY0g21F9Mw/QNXPuL/4RpByyyrisds5ozFDOhqMi6zhiM1kus6wzGrPQpwRh+nTB15BeeKBdwaidaxziAqbcUZmD7Z07btul6oTVawDyf1RidvWb9velyzEUuWviJlaeK2m2EYVbe/8bK7/+0Po/EaDcFU+6HYgYm7cBpa98BmHJoNcbYfwfjaXij7zgS006aiGmf3gcmOf3uN23E5moAUyYdxYROuY+Zzb+qjmPWaADjjfyBh+uJFzF1eyHm+XrHuq58TP0Rg1nl92vMAMb/8KCfsArTRszGmNiHMNpf5GsN4GftxNb88aDfWKud2Mg+m6x8Vy7fd+fBCv9gTDmfh2kzhLncj+9j+hAxTvsfw3hxYZj+ZxawtMG0tODhGIBpgNZZQFqfZ1rfba3nmLUE4vLb11yOPQ/zEBRY/85z+m0oxvQsxlRIv6R2I2SmJew8zIOyGxjYhIfj/2AK7BLr31ccwqtn+3GYRoCyPm+htrn2F1idxBaKbBGm8C+2/nKta3FUSsEYM9gx+uh4GByNs9csMRRb6dzQ3HtUxzW55vlWapuGL2CWKRZiOrC/d/ptLy6NTuv7cMwDsM5Vf5hC8F0n/d2xfiuw0vJNl2vSGCPrrnXdNzAVbA/cq78vMY1Xm3WPdzv9/vc8MHMc9/anGM3W3Ftr2yWYzk6J9VeGqVwc+juOqSiLnf72uujvtxiTsd68wowQ3sPJ8G5Ofjj99msedFgjeBDXrcC6J4+6bN8FE9LiofxwZ/mDaRQnWN/lApOdtnvOuk81+Y/piB5vQv5XW2mZ53RvtmOW3GqMznfywMSZZO1XhXl2KzBllC/KH+f7s5Xaz+lu57xy3KN6zvMyVqPM5fsZ1vV1tz6v48Ezc9vSRoTLPs9h4taWYDr1u4E57tKBU95pK48ygR+6HLMM8+Jpx+d+Vj4Pr0MHFzDPuMY8l//gUg44yqEqTMf5jXrK2FxruyHe1oH13d9Z53/S5fsncWkAYp7T+XWcZ5Z173vV8dsV4LtOefSOlb85mI7iWJftR1nb5Fr38ALwAyDYzeWCw6zXmLqju4uuX6Z2ubAf+OcmlAvaym/neuFn1rU81C7BrK67YenMbmnJK+0Sp++vW1p0HfT0i7KghfkfhpmNqzHPvWtZUIx5Iacj/2vKAtf850Gb01Hvp7jk/+fWeZz/Dli/LcCYQY59C9tC/vNwp61NlwfNzX/rc02/BFMe3LHu5R8xna9F1n19GXjZ5XyXMcuqXZ//Aky77YZ1f85gnnGHRrSVz1U8aLf9mgf1wX3rGOWYdtOZNpL/NfcX09a5B/R2ef5frue8iVgmvsv3P8K8owqMwfVjTKzhQkxb/asu24diVs9et675NiZW8cDW5r/LeQZjnrsKK5+cjzvfyjOHafMGRpul1vnKcOoXWMf63Mpzu/Wbc/nvqIdsmHZJDtbzjymj0q1j1tVe8VX+/4Ta/epfAS+53qN60vBjLBPf5fu+1r12TACag3kf0X1M+fg7zCp0531W8eC5yrby4xE3lwsKU3/nWX8/o3a74ArwnNO+38LUE0vrKBfOYgaNUq3rOogxbepqF2zFzP527oufs/YtsXTyUj332G3tRIyxdNGhDSufsrHKfdp4veAGLTjax1VY9YJLmbeT2s9JTTuRh9uI38E8y9rKm+84lX1HrXM4fjtJ7WfsPA/aiGWYiXEebSNgBqS+AH7s9Pu3MT5OmPXZb9qIzdUApvz9vXUOjctgGpbOedBOqNVGdNUApu66b+VzpZWndfmXNisPnMuDH2K0Xm3dK6/4l41pAD9rJ7b2jzraiS76dm0n1uo3uvw237qPjnbiQ/fI2m4LD/fb+2HKgGJMf6POCSDOf47CXWglSqkdmBiTH7p8H4YR3gKtdZYv0iYEPvXpr47t/gMTL/jXXkmY4BWamv8u+4zHzHya7bGECV6lJTqw9juFMVcueyRhgk9oRr0gZUEAIuVB+6al+e9yjO8BA7TWjS3PF9oY7sh/l+NFY4zJyVrrcnccU/A+Ui8IDqSNKEh5EHiIuS8IgiAIgiAIgiAIgiAIgiAIfkZzX6grCIIgCIIgCIIgCIIgCIIgCIKPEXNfEARBEARBEARBEARBEARBEPwMMfcFQRAEQRAEQRAEQRAEQRAEwc/o4OsEtBd69uypBw8e7Otk+A1nz57N0Vr38nU63I3ooHmIDgQQHQgG0YEAogPBIDoQAlUDIDpoDqIDAQJXB6KB5iE6ECBwddAYYu67oJT6PbAWyNJaj6vjdwX8HFgDlAJbtNZfNnbcwYMHc+bMGXcnN2BRSt328flFB20A0YEAogPBIDoQQHQgGEQHgq81YKVBdOBjRAcCBK4ORAPNQ3QgQNvQgS+QsDwPsxVY1cDvq4ER1t83gN94IU0BT0W1zddJcGUrogOvU1lt93USXNmK6MDrSHkggOhAMJRXiQ4EKQ8EowEpDwSQ/oIAWmupFwS01lIeCNjtbVIHXkdm7rugtT6mlBrcwCbrgW1aaw18rpTqqpTqo7VO904KA4fyKhtHkrI4cPI8n98t5Y3vr2Zgj46+ThYgOvAmheVVHEzI5MjJs5zK1Oz90Rq6dQr1dbIA0YE3KSir4pOrmRw98QVn8kI49NdrCA8J9nWyANGBNykoq2Lf5XSOnzjFpZJIDv14JcFBytfJAkQH3qSovIo9l9I59ukJbupodv/pYsxEJ98jOvAe6QVl7L6QxukvTpHfaSBvfXuer5NUg+jAu5SUV/A3v/2Q/MhB/H7LTIKkXmhXaK25ml7Ivov3uHz+HD2HjuPfn5rk62TVIDrwDlprLqcWsuf8LS5fusToCVP4m0fG+jpZNYgOvIPdrvnyzn32fnmTywmJLJgzkz9ZPNzXyapBdOAd7HbNubv3+ej0dS4k3mDj8rlsmjnQ18nyKWLuN59+wF2nz/es7x56GJVS38CMxjFwYPsWmoOySmPo776UzqHELFRVGU+EX2Jp1960kX57UxEdtIK8kkoOXM1g7+UMPrueQyd7KRvCr7Cqx0AqbX416io6aAUOQ3/PpXSOX8uhqy7gkbAkVkWPoLzK1mbM/SYgOmgFJRXVfJKQya4L6RxLzqa3zmNZ2HVW9B9HeZWNTmF+01QRHbSCKpudY8nZfHAulQNXMxmgs5gfeouBQyOpsmlCO/hNI0F00ArSC8rYcymD3RfT+PJOPrEdMpgRco9RA6LRWreZQZ4mIDpwE+VVNv72N+/QrfAGscMHthljv4mIDlqIzTLw9l/OYP/VDO7mlTEn5DYjO+QwuNsYXyevuYgOWojDwNt7KYN9VzK4d7+MxaE3GBpcwMguU3ydvObSJB2IBh6mymbn85Rc9l3O4OOrmWQXVbA6LJnRwSUMjprl6+Q1F9FBCzHlQT57LqWz51I66QVlrA9LYFyHavpGLvB18nyO3/SY2xB1tSh1XRtqrV8BXgGYNm1andu0B8oqbRy2DP3DiVmUVtro0SmUDZP78cj4PnStHMXwYcMICwvzdVKbg+igmWQVlrP/ijH0T93Mw2bXDOgewVfmDmHVuBhCCkYzevQoQkJCfJ3U5iA6aCaF5VUcuPLA0K+02enbJZzNswexenwMIQVjiY2NJTjYb4x9EB00m/IqG4cTs/joYjoHEzMpr7ITE2V0sHbCLILy7zJ+/Hh/MvJAdNBstNacv5vPh+dS2XUxnbySSrp1DOHp6QN4dOIMQgtTRQftAFdDH2BMnyj+YuUoVo6ZR0XuPWJjY32byOYjOnAD5VU2vvXaWT7NjOJHc5bw9Udm+zpJzUV00Awqq+2ctAy8A1czySmuIDQ4iLnDe/Ani4Yzd/AcyvKzGTlypK+T2lxEB82g2mbni1t57Lucwf4rGWQWGh3MG9GTl5aMYNaAmVSXFjJ06FBfJ7W5NEkHogFDWaWNY9ey2X8lg0+uZlJYXk3H0GAWj4pmRWxvJkVPI8hWyYABA3yd1OYiOmgGWluG/kVj6KcVlBMaHMSCkb340apRjO8+ic5hHYiJifF1Un2OmPvN5x7gXIL0B9J8lJY2S2llNYcTs9ljzdAvq7LRs3Moj1mGflR5Jh07RjB0aE+gp6+T2xJEB03g3v1S9l3OYN/lDM7euY/WMKxXJ769cBirxsVQlZVCr16R9O/fDejm6+S2BNFBEygsNzP0d1982NBfM6EP1RnXGDy4J9HR3YHuvk5uSxAdNIHKajvHr2Xz0cV0Pr6SQUmlqReemjaAtRP6UJmaSGxsH7p16wYDpTwIZG7nlvDhuTQ+PJ/KzZwSQjsEsXxsbzZM7EtwViLTpw0iMjIS6OHrpLYE0UETaMjQXxXbmztXzjBrVj8iIiIgpotvE9syRAetpLisgr/9zTt8mhXFPz8+iWdn+OXMRdFBI5RWVnM0KZt9VzI4lJhFkcPAGx3NytgY5g6O4sLZL1gwpS8dOnSAaGkfBCKV1XZO3MipmZmdV1JJeEgQC0f2Ys34Pswa2JmrF75k4dR+BAUFIf5BYFJYXsXhxCz2Xc7gSFI2ZVU2ukSEsHxsDKvGxTCxdyiJVy4xf+Jkf5v44YzooBEck392X0xn7+UMUvPLLEO/J3++chRTY0JIvXWDOZP7+zqpbQox95vPTuC7Sqk3gZlAgcTHMpRWVnMoMYs9l9I5nJhdY+g/MbUfa8b3YeaQHgQHKa5cucJ777/HkCFDGDJkiL8WzKKDekjJLmavZehfSi0ATIf9T5eNZPW4GEb0jgTg7NmzfPTRR8TGxrJx40ZfJrk1iA7qoTFDf/KAriil+Oyzz/jkk0+YOnUqa9eu9XWyW4rooB6qbWYW3kcX0tl3JYOCsiq6RISwbmJf1k3sy8wh3QkOUhw8eJDPPvuMysoKlixZ4utktxTRQQPcL6nko0vpfPDlPb68k49SMGtIDzPYOz6GyLAOfPTRR3z55ZdEhIcxe7bfzdB1IDqoB4ehv+dSOmdv3wdM++DPV4xkzfg+DO3VGbvdzvvvv8+VK1fo1q0bkyZN8m2iW47ooBUUl1Xwz794lW7lOfx47lJ/NfZBdFAn+aWVfJKQxf4rGRxLzqai2k63jiGsijUG3tzhPQkPCaaiooLXX3+de/fuMWzYMAYNGuTrpLcU0UEdlFfZOJaczb7LGXySYGZmdwoNZsmY3qweF8OiUb3oGNqB0tJStm3bRm5uLmPGjPHnGbqigzrILa7gwNVM9l0x4XqrbJpekWE8MbUfq2L7MHNod0KCgygoKCA+Pp6SkhLGjx9vJgP5J6KDOtBac+FeAbsvprHnkjH0Q4IVC0b04s9WjGTZ2N5EhYeQm5tLfHw8NpuNCRMm0LlzZ18nvc0g5r4LSqk3gEVAT6XUPeAfgBAArfXLwB5gDXAdKAW+4puUtg1KKpwM/aQsyqvs9Owcxsap/Vkzvg8zLOPGwZUrV3jvvffo378/Tz31VJs19kUHTUdrTVJmkYmFeDmDpMwiACYO6MqPV49m9bgYBvXoVGsfh7E/fPhwNmzY4INUNw3RQfNozNCf1L9rrVi5n376KQcPHmTcuHGsWbPGhylvGNFB87DbNadv5bHrYhp7L2WQW1JJ57AOrBjbm3UT+zJ3eE9COwQBpvz45JNPOHHiBFOnTmXx4sU+Tn39iA6aT3mVjUOJWXxwLpUjSVlU2TQje3fmL1eNZv2kvvTtGgEYHezatYtz584xb948Zs1qu/FTRQfNoymGvgObzcb777/P1atXWb58eZs29kUHnqOotJx/+cWrRJTn0mfCPL62ru28SNkV0UHTySws5+MrJm765ykmPGefLuE8O2MgK2J7M2NwdzoEB9VsX1FRwWuvvUZaWhobN25s08a+6KDplFRUczgpi72XM2rC9TpmZq8eF8O8ET1rvXOrpKSEbdu2kZeXxzPPPNOmjX3RQdNJyy9j/xXjHZy+lYddw4DuEWyZM5hV42KYPKBbrT6jw9gvLS3lhRdeaNPGvuig6WituXivgN2X0tl9Mb3G0J8/ohc/XG4M/S4RD0I25+bmsnXrVux2O3FxcWLsuyDmvgta62cb+V0Df+Kl5LRJSiqqOZiYxZ6L6RxJNoZ+r8gwnpo2gDXj+zB9cG1D38Hly5d5//33GTBgAJs2bWrTMfZFBw2jteZSakHNDP2bOSUoBdMHd+cf1o1lZWxMjWnjypkzZ9i9ezcjRozgqaeeMkts2yiig8ZxGPp7LqVzLLlxQ9+Bs7H/2GOPWUts2yaig8ZxLJ/cdcHEQ8woLCc8JIilY3qzbkJfFo3q9dALkp2N/WnTprFmzZo2O+ALooOmYrdrvriVx4fnUtl9KZ2i8mqiI8PYMmcwj03uz5g+kbXy2dnYnz9/PosXLxYd+DnNMfQdOBv7K1asaPMrN0QHnsHZ2O87cR7feGypr5PUIKKDhrmZU1Jj4J2/mw/A0F6d+OaCoayMjWFC/y51lveuxv6YMW37Bbqig4YpKKviYEImey8/WKnRs3Mo6yf1Y/W4GGYP60FI8MP9AGdj/9lnn23zMfZFBw2Tkl3MvisZ7L+cwYV7ZnX/qN6RfHfJCFbG9mZsn6g6ywNnY//555+nf/+2HYpFdNAwDkN/z6V0dl9K5959Y+jPG96TP10+kuUuhr6DnJwc4uPja4z96OhoH6S+bdN2XTWhTVFcUc3BBGPgHUkylbLD0H9kfB+m1WPoO3Pz5k0GDBjAc889R2hoqJdSLrgLu11z9s599l4yLzdKzS8jOEgxZ1gPvjZ/CCvGxtArsuEBG601KSkpfmHsC/XTUkPfgd1u5+bNm4wfP54NGza0aWNfqB+tNVfTC9l1IZ2PLqZx776Jh7hwVC/+euIYlo6OplNY/c94dXU1t2/f9gtjX2ica5lFfHAulT+eTyM1v4yOocGsGhfDY5P7MWdYz3rbCBUVFdy7d48FCxawaNEi0YGf0hJD35mysjLS0tL8wtgXPEN5lY2Xtp+kV3kh/SbO5+uP+W2ItnaLo12w/3IG+69k1qzmHd+vC3++YiSrxsUwPDqy0ePk5+dz//59vzD2hbpxhFrZezmDEzdMqJWYKLNSY9W4mHonAzqTl5dHcXGxXxj7wsNorbmSVlizYic5sxgwq/v/ctVoVsb2brRtAJCdnU1FRQUvvPAC/fr183SyBQ/gmBjqmKF/734ZHYIU80b05PtLR7BibAxdOj5s6DuTmZkJIMZ+A4izJtRLXYZ+dGQYz0w3M/SbYuiDMXA6dOjA2rVrqa6uJiSk4QdXaDtU2+ycupnH3svp7L+SSXZRBaHBQcwf0ZMfLBvB8rG96dqxaQM1Dh088cQTaK3F2PczWmvoO3Do4JlnniE4OFiMfT/kelYROy+k89GFNFJySggOMrMtfrCs/tkWzmitsdvthISEsHnzZkJCQsTQ9VOyCsvZeSGND86lciWtkOAgxfwRPfnRqlEsH9ubjqH1l/MOHYSHh/O1r31NdOCHtNbQBzNjPygoiM6dO/Ptb39bJn+0U4rLKvnWa1/y2a1SfrrhWZ6eOcTXSRKaiM2u+fLOffZfNgbevftlBFmref9+7VhWxPamf7eOTTqWo43Yu3dvXnrpJSkP/IzMwnL2X8lg76UMTt3MrQm18pW5Q1g1LqbZfYUBAwbw/e9/X3TgR9it8mCfS3kwY0h3frJuLCsaWN3vikMHw4cPFx34IVprLqcWGkP/Uhp38x4Y+i8tHcGKJvpIDh3ExsYyYsQI0UEDiLsm1MJh6O++mM6R5GwqLUP/2RkDjaE/qFuTKmUHly5d4siRI8TFxREVFSXGvh9QUW3jxPVc9l5O58DVTO6XVhEREsyiUb1YNS6GJaOjiQxvXj6ePn2aM2fOEBcXR8eOTWvgC76nPkP/hdmDeKQZhr6DY8eOkZyczAsvvNCmw3IJD3M7t4SPLqaz60IaiRlFNS9D/dr8oawaF0P3Tk1raGmt+fjjj8nKyuLZZ5+VBpofUlJRzf4rGXxwLpXPrudg1zChfxf+Yd1Y1k7o2+gKLjA62LlzJxUVFWzcuFF04Ee4w9B3YLPZePfdd4mIiGDdunWig3ZKYUk5//KL/6W8NIR/37iWjVPbdsgFASqr7Zy4kcP+K5kcuJpBTnElocFBzB3eg+8tGc6yMb3p0bl57bzy8nJee+01Ro8ezbx586Q88BPu3S9l3+UM9l7O4Ms799EahvXqxHcWDWfVuBhi+9YdaqU+HKF4ZsyYwdSpU0UHfkCVzc7nKbnsu5zBx1fNZEBHmJWWlgf5+fls376dJUuWEBsbKzrwExyrNT66aMK03skrpUOQYu7wnnxv8QhWxDZ9YiiYVRuvv/46a9euZfjw4aKDRhBzX6CovIqDCVnsvpTOUcvQ7x0VxqYZA3lkQh+mDmyeoe/g4sWLfPjhhwwaNIjw8HAPpFxwF2WVNo4mZ7PvcjoHE7IoqqgmMqwDS8ZEs3pcDAtHRhMRGtz4gergiy++YO/evYwcOVIKZD/A3Ya+g6NHj3LkyBEmTJggg3x+Qlp+GbsvprPrYhoXrdiYUwd14yfrxrJmfB+io5pXrjuM/c8//5wZM2YQHNyyMkXwPtU2O59ez+HDc6nsv5JJWZWNfl0j+M6i4WyY3I/h0U03dO12O7t27eL8+fMsXLhQVu/4AXUZ+qNjIltk6DtwGPuJiYmsWrVKVm20UxzGfseKPFZPWyDGfhumtLKao0nZ7LuSwaHELIrKq+kUGsyi0dGsjI1h8ahezZ7846C8vJzt27eTkZHB/Pnz3Zxywd2kZBfXvHftUqppH47pE8WfLhvJ6nExjOjdeOiluiguLmbbtm3k5+fTo0cPdyZZcDPlVTaOJZvy4GBCFgVlZjLg4tG9THkwOpqoFpYH+fn5xMfHU15e3qZfnCsYHIb+7kvG0L+dW0qwZeh/d/HwZhv6DrKzs4mPjwegS5cu7k52QCLmfjulsLzKmqGfwbFrxtCPiQrnuZkDeWR8H6a00NB34Gzsy+zMtklReRWHk4yhfzgxm7IqG906hrB6fAyrx/VhzvAehHVonfnmMPZHjRrFk08+KWZeG+VBeeBeQ9+Bw9ifOHEijz76qJh5bZisonL2Xspg14U0zlgm3vh+XfjrNaN5ZEJf+jVxKa0rWmv279/PqVOnmDFjhph5foBjOe0H51LZeSGNnOIKosI7sGFyPx6f0q9FA/92u52dO3dy4cIFFi5cyKJFizyTeKHVpBeUsfdSBrvdaOg7sNlsvPPOOyQlJbFq1SpmzpzprmQLfkR+cSn/939+R8eKPAZOWcCLjy72dZIEF/JLK/kkIYt9lzM4fs2EaO3WMYTV42JYGRvD3OE9CQ9pXdu+rKyM1157jYyMDJ566ilGjRrlptQL7kJrTXJmMXsupbPvckbNuxQmDujKj1ePZlVsDIN7dmrVOYqLi4mPj6egoIBNmzYxePBgN6RccCdF5VUcSsxi/5WMGu+gS0QIS8dEsyo2hgUje7W6PMjPz2fr1q01Mfb79u3rptQL7sRh6Dteiusw9OcM68F3Fg1jxdgYujVxVXddOIx9pRRxcXH07NnTjakPXMTcb0fUNSO3T5dwnp85iEcmxDB5QOsMfQdJSUl88MEHDB48mE2bNsks3TZEfmklB65mmkb69RwqrRcjPzG1H6vH9WHmkO50CHaP8XrhwgUx9tswReVVfOJBQ9/B559/LsZ+G+d+SSX7rhhD//MUEyN1VG9j4q2d0LfVHTaAI0eOcOrUKWbOnMnKlSvF2G/D3M0rrYmjfz2rmNDgIJaMjmbD5H4sHt2rVYO+e/fu5cKFCyxatIiFCxe6MdWCO6jP0P+z5SNZM6EPw1ph6DvzwQcfkJSUxOrVq5kxY4Zbjin4FyUVVfyf//k9HSvyGDRlIV95dJGvkyRYZBSU8/HVDPZfyeDzlDxsdk2fLuZFqCtjY5g+uJvb+gp2u53XX39djP02iOMFmPusGfopOSUoBdMHmXcprBrX9NjpjVFVVSXGfhslt7iCTxKMd/DZ9VwqbQ+8g1WxfZg5tDshbioPysrKxNhvwzhemL7HeinuLSdD/9sLh7EitulhWhuisLBQjP0WIuZ+gFNQ9sDQP36ttoG3ZnwfJg9wj4HnzMCBA5kxYwbLli0TY78NkF1UwcdXTcPs5I1cqu2afl0jeH7mIFaPj2HKwG5NejFycxk6dCgzZ85k+fLlYuy3ER4Y+hkcS872SnkwatQoioqKWLp0qRj7bYjC8ioOXMlk18U0Pr2WQ7VdM6RnJ767eDhrJ/ZlZAuXVNdHbGwsAIsWLRJjvw1SUFrFnsvpfPBlKl/cygNgxuDu/N/HxrNmfEyLltPWxcSJE+natStz5851y/GE1uMtQ9+ZyZMnM2jQIKZPn+72Ywttn9LKar4af4aM4q7EzRrPV9bJQJ+vuZlTwv4rpq9w/m4+YOKmf3OBea/O+H5dPFJ3BwUFMXXqVDp16sTIkSPdfnyhedjtmnN377P3komhn5pfRnCQYvbQHrw4bwgrYnsTHen+ULshISFMnTqVPn36MGjQILcfX2geafllNeXB6Vt5NS9GjpsziFXj3Dch1JXw8HCmTJnCiBEj6NOnj9uPLzQfrTUJ6UU1M/Rv5pTUlAnfXDiMlW4y9J2JjIxk8uTJTJw4UYz9ZiLmfgBSUFbFgRpDP5sqm6Zvl3A2zx7EGjfOyHXl+vXrDB48mIiICFavXu324wtNJ72grOblRqdv5aE1DO7Rka/NH8rqcTFM6O+ZRjpAcnIyw4cPJzIyklWrVnnkHELT8YWhr7UmOTmZkSNH0q1bN5YvX+7W4wsto7SymoMJWey6kMaRJKOFfl0j+Or8Iayb0LfZLz1rDGcdREdHEx0d7bZjC62notrGkaRsPvgylUOJWVTa7Azt1Yk/XzGS9ZP6MaC7e15+brfbuX79OiNHjqR///707y8xtX1NRkF5TUfNW4Z+dXU1t27dYvjw4QwbNoxhw4a5/RxC2+d+USk//MMhvkhX/NfTi1k/qZ+vk9QucYRU+PhKBvuuZJCcWQyYMHx/sXIUK2N7MzzavYP8zpSVlZGVlcWgQYOYPHmyx84jNE61zc4Xt/LYd9ms1sgsrCA0OIh5I3ry/WUjWD6md6vCazREUVERhYWF9OvXj1mzZnnkHELTSMkuZt+VDPZfzuCC9Z6tkb07893Fw1k5LoaxfdzbR3AmLy+P6upqoqOjWbBggUfOITQdrTWJGUXstl6Km5JTQpCCOcN68vX5Q1kZ2/wXJDeFrKwsOnToQPfu3Vm6dKnbj98eEHM/QCgoreLjq+ZlZ59ez6HKZmZnx80ebEJsDOjq0dmS58+f549//CMLFixg8WKJmekLbueW1Bj6jlk3o3pH8tKSEawaF8PomEiPz5g9efIkH3/8scTQ9TF1Gfp9PGzoO9Bac+TIEY4dO8Zjjz3GhAkTPHIeoWmUV5mXZe+6kMbBhCzKqmxER4bx3KyBrJvYl8keqhu01uzdu5fTp0+zadMmRowY4fZzCM1Ha83Z2/d5/1wquy+mU1BWRc/OoTw3ayCPTe7n9tmZdrudDz/8kEuXLvHVr35VjH0f4jD091xKr3mfhqcNfQfV1dW8/fbbXL9+ne985zsyE6udcr+olH/9n/9lQGUB/77+WTH2vYzNbsr//VeMiXvvfhlBCqYP7s4/rBvLitiYFr9XpzmUlZWxbds27t+/zw9+8APCw90/E1xomMpqOydu5LDvcgYfX80kr6SS8JAgFo2MZvX41r0MtakUFRURHx9PZWUlL730Eh06iC3lTRwhVvZfrj3AN7F/F360ahQrY2M82i5wkJeXR3x8PKGhoXz729+WVd4+QmtNUqYx9HdfSicl2xj6s4f14Kvzh7AyNoaeHjD0HWRmZrJt2za6d+/Oiy++KKu8W4iUon5MQWkV+y1D/zMnQ3/LnMGsGe95Q9/BuXPn2LlzJ0OHDmXevHkeP5/wALtd8/vPbvLel6kkpBcCD2bdrB4X06oX3jUXh7E/duxYpk2b5rXzCoZahr71kmxvGfoOtNYcPnyY48ePM3nyZMaPH+/R8wl1U2Wz8+m1HHZdTOPAlUyKKqrp3imUx6f0Y93Evkwf3N0jobgcaK3Zs2cPZ86cYc6cOQwfPtxj5xKaxo3sYj48l8qH51O5m1dGeEgQK2Nj2DC5H/OH93Rb/GRnnI39pUuXirHvA3xp6DtwGPvXrl3jkUceEWO/neIw9iMq8xk6fQlPzJIBX2/gMHH3X8ngwNVMcoora2Zlf2/JcJaN8cwMzPpwGPvZ2dk8/fTTYux7kfIqG8eSs9l3OYMDCZkUlVfTOawDS0ZHs3pcDAtH9aJjqHesIYexX1RUxHPPPSfGvpdwhF3aZxn6d/N8M8DnwGHsV1VV8eyzz4qx72UcL8refTGNj5wM/VlDe/DVeZ439B04jP3g4GA2bNggxn4rkJLUD7meVcy/7L5aEye5X9cIvjJ3CGvG92GiB8Ot1IXD2B82bBhPP/20xNj3MkeSs/iX3QlMHNCVv31kDCtjY9wWSqE5nDhxggMHDjB27Fgef/xxibHvJeo19Gd5z9B34Grsr1u3TipnL2K3a06m5PLRxTT2Xs4gv7SKyPAOrBoXw7qJfZkzrIdHDFxXXI39ZcuWiQ58RE5xBbsupPHhuVQu3CsgSMHc4T35wdKRrBwXQ+cwzzUB7XY7H3zwAZcvX2bp0qUy8O9F2oKh78DZ2F+7di1Tp0712rmFtkNeYQk//eWrRFTmM2zGEjavme/rJLULbueW8PivT5BbUkmn0GAWj45mZWwMi0b1ItLDs7LrorS0lO3bt5Odnc0zzzwjA/9e4sLdfF45nsLhxCxKK210iQhhZWwMq8fFMHd4T8JDvNtnc7wss7i4mOeee46BAwd69fztlWPJ2fzZOxfILqogJFgxb3hPvrvY+wN8DvLy8ti6dSvV1dVs3ryZmJgYr6ehvZKcWcRHF9PZfTGNG5ahP3NID16cawz9XpHe00NmZibx8fF06NCBLVu20L17d6+dOxARc98P+dm+RM7eus9X5xlD35Px0xuivLycTz75RIx9H7LzfBpdIkJ455uzCe3gm9HuoqIijh49Ksa+l0nNL2P1fx+jsLzaZ4a+M3l5eZw4cYIpU6awdu1aMXS9zC8PX+c/DyTTMTSY5WN7s25CX+aP7ElYB+8+j2lpaZw9e5a5c+eydOlS0YGXKau08fHVDD48l8qxaznY7JqxfaL4mzVjeHRSX3pHeWeW5M2bN7l8+TLLli2Tl+d6kR++fZ73v0wFfGfoO5OUlCTGfjunuKKaH//vR/SpzGf4zGW8sFrKA2/x4bk08kor+e0LU1k4spfXTVxXzpw5I8a+l9Fa853Xv6SkspoNk/uxelwMs4b2IMQLkz3q4+TJkxQXF/P8888zYMAAn6WjvfGbIzcICVL8/JlJXgm71BjHjh3DZrMRFxdH7969fZqW9sI7Z+7y22MpXM8qRimYOaQ7W+YOYZWXDX1nDh06REhICHFxcWLsuwEx9/2MkopqjiZn8+yMgfzVmjE+TUt4eDhf+cpX6Nq1qyyn8wHGxMlk/aS+PjP2wbzR/Ktf/So9e/aU5XReZO+ldArLq9n+1RnMHdbTJ4a+Mz169ODrX/860dHRYuh6Ga01b52+y6yh3fnDlhlEhPquA9+vXz++8Y1v0Lt3b9GBFzl35z6vfX6HfZfTKam00adLOF+fP5THJvdjVIznXopYH8OGDeOb3/ymzMTyInfzSnn/y1Qem9yP7y4Z7jND35nY2Fh69OghOminFJVXseUPpzmf25mfrn6CJ+eP83WS2hWHEjOZNKArK2PbxvM3f/58Ro0aJUaeF0nKLCI1v4yfPj6eZ2a0jRnyy5YtY/LkyURHR/s6Ke2GgrIqTt/K4xsLhraZd5088sgjFBQUSKg+L1FUXsVfvX+J4dGd+ef1sawcF0N0pO/Doj322GOUlZXRrVs3XyclIBAnzs84kpRNRbWdVeN811A7e/YsR44cAaBnz55i7PuIg4mZlFbaWDexr0/O/9lnn/H5558DEB0dLca+lzmUmMWo3pHMH9HLZ8a+1ppPPvmECxcuAIih6yMu3isgNb+Mxyf394mx7wjFk5iYCEBMTIzowIvkl1by9Cuf8/GVDB6Z0IcdX5/JZ3+5hB+vHu1VY99ms/Hhhx9y8+ZNADF0vcyRpCwAvudjY7+qqop3332XtLQ0QHTQXskpKObv/+t/uXkvnV8+O0WMfS+TVVjOhXsFLB3tWwO1pKSEN998k/z8fJRSYux7mUOJpl5Y7GMdFBQU8MYbb1BcXExwcLAY+17mWHI21XbN0jG+ve+5ubm89dZblJeXExISIsa+Fzl5I5dqu+Ynj8bywuzBPjX209PTeeedd6iqqiI8PFyMfTcibpyfsedyOj07hzJ9sG+WrZw9e5aPPvqItLQ07Ha7T9IgGHZdSCM6MoyZQ3p4/dyffvopn3zyCampqWitvX7+9k5heRVf3MxjiQ8baQ5j/7PPPiM1NdVn6RBgz6V0OgQpVsR6v9OstWbXrl2cPn2a9PR0r59fgKPJ5n0b8V+dwc82TmSOD1by2Gw23n//fS5cuEBmZqZXzy0YDidlM6hHR4b07OSzNFRVVfHmm29y5coVsrOzfZYOwbfkFBTzs1++SlRFDn++sC+rx/fxdZLaHQ5Td+kY35npJSUlbNu2jRs3bnD//n2fpaM9czgxi9i+UV4LyVcXBQUFxMfHc/v2bQoLC32WjvbMocQsunUMYdIA35moOTk5bN26lTt37lBcXOyzdLRXjiZn0yk0mCkDfWukp6ens23bNlJTUyktLfVpWgIRMff9iPIqG4cTs1g+NoZgH8zUPXPmDB999BEjRozgqaeekpnaPqSwvIrDSdk8MqGP17Vw/PhxDh48yLhx43jsscdkhq4POJpkZmAs85G5r7XmwIEDnDhxgmnTprF69WqfpEMwebH7Ujpzhveka8dQr597165dnDt3jvnz57No0SKvnl8wHEzIokenUCb17+qT89tsNt577z2uXr3KihUrmDVrlk/S0Z4pr7Jx4kYOi0f5Liyaw9hPSUnh0UcfZeLEiT5Jh+BbsguK+NkvXyWiqpBRs5exacVsXyepXXIwMYt+XSMY7YOwbPDA2M/Ly+PZZ59lyJAhPklHeya/tJKzt++zxIez9h3GfmlpKc8//zx9+/pmtXl7xmbXHE7KYvGoaJ/4R2CM/fj4eOx2O3FxcTJj38torTl2LZvZw3r6NJSzw9gPCwsjLi6OLl26+CwtgYq4s37EseRsSittrBnv/SXOZ86cYffu3TXGvoTi8S37L2dQWW3nUS+H5Dl+/DiHDh1i/PjxPPbYYzLA4yMOJWbRvVOoT2ZgOIz9kydPMm3aNNasWSMDPD7kUmoB9+6X8YiX6wVXY3/x4sWiAx9QbbNzNDmbRaOifRKey2HsJyQksGLFCmbPFiPPF5xMyaW8ys6iUb18cn5nY3/9+vVMnjzZJ+kQfEt2QRH/XmPsL2fTyjm+TlK7pLzKxqfXclgy2jeDfSUlJcTHx9cY+0OHDvV6GgQzU9eufReSp6CggK1bt9YY+/379/dJOto75+7cJ7+0ymervR3GvtaauLg4CcnkA27llnI3r4yFPmojAqSlpdUy9iUUj2cQh9aP2Hc5gy4RIcwa6v0wLCEhIYwaNYqNGzeKsd8G2HkhjYHdOzJpQFevnjc0NJTx48ezYcMGMfZ9RLXNzuGkLJaM9s0MDKUUoaGhTJ8+ndWrV4uh62N2X0onOEixYqz3B31DQkJYsGABixYtEh34iC/v5FNQVuWzOKpKKUJCQsTY9zFHErMIDwnySfsQICgoiNDQUNavX8+kSZN8kgbBtxSUVfGN7eeIroTJc5fzrMzY9xknU3Ipq7L5rF4ICgoiIiKC1atXy4x9H3LYmgg00Uer+oKDg+ncuTMbN26kX7+28RLX9sjBxCw6BCnmj/CNsRscHExUVBQbNmygVy/fmcvtmaPWO5kW+kgDAB06dKBHjx5s3LiRrl27+iwdgY64tH5CZbWdAwmZrIyNISTYe6ZqQUEBXbp0YeLEiUyYMEEMnDZATnEFJ27k8q2FQ72WHw4dzJw5E6216MCHnLubT35pFUtHezeOqtaaoqIioqKiWLRokeigDaC1Zs+ldOYM60G3Tt4JyWO32ykuLiYqKopVq1YBiA58yMHETKvT5t0lzjabjbKyMjp37syGDRtEAz5Ea83hpGzmDutJeIh3X6hdVVVFVVUVHTt25KmnnhIdtFMy7xfxrdfOcjmjlF8++wwrx0mMfV9yMCGTjqHBXh/sKykpISwsjIiICLZs2SLlgQ+x2TVHk7N9EoqlqKiITp060blzZ1588UXRgY85lJDF9MHd6RIR4tXzFhYWEhkZSbdu3fja174mOvAhx67lMLhHRwb26Oj1cxcUFBAVFUV0dDRf/epXRQceRqbe+gmf3cihqLya1eO8Nzvziy++4H/+53+4d+8eIAZOW2HPpXRsds2jE70zC+Lo0aP8+te/rnk5nujAt3ySYMy8BSO9Z+Zprdm/fz8vv/wyBQUFgOigLXA5tZC7eWU84qWXFdrtdnbu3Mmrr75KWVkZSinRgY85nJjFjCHdiQz3XqfNZrPx7rvv8oc//IGqqirRgI9JySnhTl4pi7wceqGqqoo33niD7du3Y7fbRQftlMz7RfzHr14lJudLfr1pihj7PkZrzaGELOYN9+5gX3FxMfHx8bz//vuAtBF9zfm797lfWuX1kDz5+fn87ne/Y/fu3YDowNfczSslKbPI66t4srOzeeWVVzh48CAgOvAlFdU2Tt7IZcFI78/aT01N5Te/+Q0nTpwARAfeoN2Y+0qpYKXUc75OR0vZdymDzmEdmOel2XlffPEFe/fuZfjw4fTpEzgNdX/XAcCuC2mM6h3JKC+8JOvIkSMcOXKEMWPG0KOHb5b7ewJ/1sGhhCxmDvWemecw9k+dOsWECROIioryynm9gT/rAJxC8sR6ftDXYexfuHCBqVOnEhER4fFzegt/1cHdvFKSM4u9+rI8m83GO++8Q2JiIjNmzCAkxLszwTyJv+rgcKJZbr3Iix23yspKduzYwa1bt5g9e3ZAhenzVx34gsy8Qv7jV/9LeHURi+fPZbkX6iJv4a86SEgvIq2gnGVjvLe602Hs5+fnM2PGDK+d19P4qwbAvJsrOEh51dDLz89n69atVFRUMHXqVK+d19P4sw4OW+FYvNlOzM7OJj4+HqVUQIXp81cdnLl1n7IqGwu9bO6npqayfft2IiIiGDdunFfP3Z4JnNa4hVIqSin1V0qpXyqlVijD94AU4Clfp68lVNvsfHw1gyWjownr4PlZGKdOnWLv3r2MHj2aJ598kuBg7y7zdgeBqAOA1PwyTt+6z7qJnh9wOXLkCEePHmXSpEk8+uijftl5DzQd3Mkt5VpWsddC8mit2bdvH6dOnWLmzJmsXLnSL0fdA00HUDskT3cPh+Sx2+388Y9/5MKFCyxatIiFCxd69HyeItB0cCjRu502h7GflJTE6tWrmTlzplfO624CTQdHkrIZEd2ZAd29s9y6srKSN954g9u3b7NhwwYmTJjglfO6m0DTgbfJzCvkP379KuHVxYyfv4qnlkl50BY4mJAJwKLR3jFyioqKiI+Pp6CggE2bNjF48GCvnNedBJoGAA4lZjN1UDevhWK5f/9+jbG/efNm+vbt65XzupNA1MHBhCyG9OzE0F6dvXK+rKysGmM/Li6Onj29GzLSHQSaDo4lZxMSrLwapu3evXts376djh07smXLFrp06eK1c7d3AjHm/nbgPnAS+BrwF0AosF5rfd6H6WoxX9zM435pFWvGe35GzM2bN9m3bx+jR49m48aNfmnsWwScDgA+upAGwLqJnm00Xb16tcbYX7dunV8a+xYBpYODiabT5q3llV9++SVffPEFs2bNYsWKFX5p7FsElA4ArqQVcievlG8vGubxc3322WdcvHiRxYsXs2DBAo+fz4MElA4OJXq303bw4MEaY9/PZ2cGjA5KKqo5dTOXr8z13ksr9+7dy+3bt3nssccYP368187rAQJGB94mv7SSf315O1HVxUxYsIqNS6Q8aCt8kpjFxAFdiY4M9/i5tNa8++67FBQU8NxzzzFo0CCPn9NDBJQG0gvKSEgv5MerR3vlfHa7nTfeeIPKyko2b97szyv+A0oHJRXVnLyRy+bZ3nkuq6ur2bFjB0FBQcTFxfnziv+A0sHR5GymDepOpzDv2L7l5eXs2LGDjh07EhcXJ8a+lwlEc3+o1no8gFLqVSAHGKi1LvJtslrO3ssZRIQEs3Ck5w29wYMHs3btWiZNmuTPxj4EoA4Adl5IY+KArgzq0cmj5xk9ejRr165lypQp/mzoQoDp4GBCFsOjO3s8/x1MnDgRpRSTJ08WHbQxHCF5VnohDMKMGTOIiopi4sSJHj+XhwkYHTg6bS94qdMGMG/ePPr27RsIy2sDRgefXs+hyqZZNMp7y60XL17MqFGjGD3aO8aRBwkYHXiT/NJKnnv1FBklffnrZTN5YvE0XyeptQSMDrKLKrhwN58/Wz7SK+dTSrF69WoqKir82diHANIAwOFE8440b63qCwoKYu3atYSEhPizsQ8BpoPPrudQabOzxEsTwjp06MC6devo2rWrPxv7EEA6yCwsJzGjyGsDfQDh4eE8+uij9OnTR4x9H+C303EboMrxH621Dbjpjw+jA7tds+9KBotG9SIi1HNm+9mzZ7l//z5KKaZOnervxj4EmA4AbmQXcyWtkEc9NGtfa82pU6coKioiKCiIqVOn+ruhCwGkg6LyKk7dzGWphxvrWmtOnDhBWVkZHTp0CIQBHgggHcCDkDyzh3ouJI/dbufTTz+lsrKSsLCwQDD2IYB0UNNp83B5UF1dzfHjx6murqZjx46BYOxDAOngSFIWncM6MH1wd4+ep7Kykk8//RS73U5UVFQgGPsQQDrwFhm5BfzZL9/hWlYR/2/z3EAw9iGAdOB4/4anzbyioiJOnToFQExMjL8b+xBAGgCzqq9f1whGRHt2VV9eXh5ffvklAAMHDvR3Yx8CUAeRXmgfZGZmcunSJQCGDRvm78Y+BJAOjiWbgb4FIzw/AeTu3bskJSUBZpKoGPu+IRDN/YlKqUKlVJFSqgiY4PS5sCkHUEqtUkolKaWuK6V+XMfvi5RSBUqp89bf37v9KizO3rlPdlEFq8Z5bnbmyZMn+eijjzh58qTHzuEDAkoHADvPp6EUrJ3g/saT1prDhw+zb98+zpw54/bj+5CA0cHxa2aG5lIPviRNa82ePXs4cOAAFy9e9Nh5fEDA6ABMSJ7buaU84oGyAIyx/+GHH3Lw4EESExM9cg4f0SodtCUNHPaCqVtdXc3bb7/NoUOHuHnzpsfO4wMCQgdaaw4nZjN/RE9Cgj3XnK+srOT111/n0KFDpKameuw8PiAgdOAt0nLy+c/fvEq/0hv816NDWTzKey9o9DABo4ODiZn06RLO2D5RnjoFhYWFbN26lUOHDlFQUOCx83iZgGkjllfZ+Ox6DktGR3t0Yk5eXh7x8fF88sknlJaWeuw8XiZgdGC3aw4lZrFgVC+Ptg8yMzPZtm0bn3zyCVVVVY3v4B8EjA6OXcuhV2QYY/pEeuLwNdy9e5fXXnuNgwcPYrfbPXouoWECLiyP1rpVU86VUsHAr4DlwD3gtFJqp9b6qsumx7XWa1tzrqaw91IGocFBHpudd+LECQ4cOMDYsWNZuXKlR87hCwJNB1prdl1MY+aQ7vSOcm8cTa01hw4d4tNPP2Xy5MksWrTIrcf3JYGkg08SMunaMYQpA7t65Phaa3bv3s3Zs2eZM2eOv8fUrkUg6QBgjwdD8tjtdj744AMuX77M0qVL/fZlmXXRGh20JQ1obXXaRvYktINnOm3V1dW89dZbXL9+nbVr1zJixAiPnMcXBIoOEjOKyCgs96jJWlFRwY4dO7h79y5PPPEEAwYM8Ni5vE2g6MAbpOXk898v/47w6hImLXqER2YExMoNIHB0UF5l4/i1HB6b3M9jpm5hYSHx8fEUFxfz/PPPB8zMzEBqI566mUdZlc2jq/ry8vLYunUr1dXVbN68mY4dvfMyd08TSDq4klZIVlGFR1d7Z2RksG3bNkJCQoiLiyMkxDsvb/Y0gaIDm11z/Fo2S0f39uhA3507d3j99dfp3Lkzzz//vD+/pzEgCDhzXykVDnwLGA5cBH6vta5uxiFmANe11inW8d4E1gOuD6TH0Vqz/0oG80f0JDLc/QWms7H/+OOPB0IonhoCSQdgKumU7BK+Nm+oW4/rbOxPmTKFtWvXBkIIlhoCRQc2u+ZIUjaLRvaigwdmYDgb+3PnzmXp0qWig9q0CR2AZ0PyOBv7y5YtY+7cuW49vq9ppQ7ajAaupBWSWVjhMVPX1difOnWqR87jKwJFB4eTTAiOhR6Kt19RUcHrr7/OvXv3eOKJJ4iNjfXIeXxFoOjA06Rm5/Pzl39HuK2EyYsf4bGFUh440WZ08HlKLqWVNpZ5aHWnq7EfSAN9gdRGPJyYRXhIELOHeSY0Sm5uLvHx8dhsNuLi4ujd23Orib1NIOngYGImSsEiD7UTXY397t09G/rHmwSKDi6lFpBfWsWCkT09dg6HsR8ZGUlcXByRkZ5dISA0TiAOrcQD04BLwBrgP5q5fz/grtPne9Z3rsxWSl1QSu1VStXZ41FKfUMpdUYpdSY7O7uZyYCL9wpIzS9j9Xj3h16w2WwkJCQQGxvLE088EVDGvkXA6ABg14U0OgQpVrs5PFNVVRVJSUlMnTo14Ix9i4DQwfm798krqfRYSJ7S0lJu3LjBvHnzAs7YtwgIHQBcTS/kVm4pazxQLxQVFXHr1q2ANPYtWqMDt2kAWqeDQ4lZHu203b9/n9TUVNatWxdwxr5FQOjgSGI2sX2j3L6az0FOTg5ZWVls3Lgx4Ix9i4DQgSfJK6nkT+OPEGIrY0oAGvsWAaGDQ4lZRIQEe8zUTU1NpbS0NOCMfYs200aEluvAsapvzrCehId4pl9/584dbDYbmzdvDihj36LN6KC1dcKhxCymDOzmsfdypaSkBKSxbxEQOjiWnI1SMN+D8faTk5PF2G9jBNzMfWCs0xuufwd80cz963K1tMvnL4FBWutipdQa4EPgoTXrWutXgFcApk2b5nqMRtl7OYMOQYrlbjb07HY7wcHBPP/884SEhATq8pmA0YHdrtl1IY0FI3vRzU2VtNYarTWhoaG8+OKLhIWFBaKhCwGig4MJWXQIUiwY6d4K2qGDTp068Y1vfIPw8HDRQd20CR2Ac0ge99ULdrsdpRRdunThO9/5DhEREW47dhujNTpwmwagleVBYhYT+3elV2RYc3ZrFLvdTlBQEL169eJ73/ue6KBu2oQOCkqrOHvnPt9eOKypuzQZhw769evH97//fdFB3bQJHXiS7MIyXvj9aW7mh/GtZ+NYEhtwhq4Dv9eB1pqDCVnMHe5+U9dRHowZM4bBgwcHannQZtqI0HId3Mgu4U5eKV9f4N5V3vBAB5MnT2b06NGig7ppE32FzMJyLt4r4C9WjmrObk3CoYM5c+YwefJk0UHdtAkdHE3OZkK/Lh4Z4HHoYOnSpcybN4/wcM9MMhGaTyC6us5vuG7OEhoH9wDnFmx/IM15A611oda62Pr/HiBEKeXWNS9aa/ZeTmf2sB506ei+kDzHjx/ntddeo6qqirCwsEA19iFAdADmpcppBeU8OrGvW46nteaTTz7hnXfewWazBbKhCwGig4MJWUwf3J0uEe4rC7TW7Nq1i127dqG1JiIiQnRQP21CByYkTwazhnanR2f3GLs2m413332Xjz/+GCBQG+oOWqODNqGB7KIKLt7Ld3s83aqqKl5//XWOHTsGiA4aoE3o4Ni1bGx2zeLR7h3wLS8v5w9/+AOnT58GRAcN0CZ04CnuZd3n33/+a+y5d/hd3PRANvYhAHSQlFlEan4Zy8a4t14oKCjgN7/5DdeuXQMCujwIiDbi4UQTqs3d7YOcnBx+9atfcefOHUB00ABtSgdL3VwepKen86tf/YqMjAxAdNAAPtdBQVkV5+/mu31SIMDt27f51a9+RW5uLkopMfbbGIHo7E5S5o3Whaplb7g+DYxQSg1RSoUCzwA7nTdQSsUoywVTSs3A3Mdcd15EQnoRt3NLWT3OfaEXjh8/zqFDh+jcuXMghuFxJSB0ALDzfBphHYJYNrb1M3W11hw4cIATJ04QGRkZyIM7DvxeB3fzSknKLHJrI81h7J87d46oqCi3HbcN4/c6AFMv3MwpcVtIHpvNxnvvvUdCQoLooHEdtAkNHEnKQmv3dt6rqqp48803SUlJER34iQ4OJ2XRtWMIkwZ0c9sxy8vLee2110hLS6Nz585uO24bxu914AnuZOXxi9/+jjBbKd9bOY55I/xiPKI1+L0ODia439QtKChg69atFBUVBcwLUxsgINqIhxKzGNU7kn5d3We65uTkEB8fT0VFRSCbuQ4CQgcHE7Po1zWCUb3dFyYlPT2dbdu2YbPZCAtz76rRNojf6+DE9Rxsdu12c//WrVu8/vrrBAUFtQcd+CWBGJbngtZ6ckt31lpXK6W+C+wHgjEv0biilPqW9fvLwEbg20qpaqAMeEZr7dZltPsupxOkYIWbQi8cO3aMw4cPM378eDZs2NAeTN2A0EG1zc6eS+ksG9ObzmGte1wdxv7JkyeZPn06q1evDuSZ2g78XgeHamZguKcs0Fqzc+dOzp8/z4IFC1i0aJHooBHagg7AhOQJUrAytvXv3nA29leuXMmsWbPckMI2T4t10FY0cCgxi95RYcT2dY8J72zsr1+/nkmTJrnluG0cv9aB3a45mpTNwpG9CA5yT9ntMPbT09N58sknGT16tFuO28bxax14gjtZefzyt78jzFbOzGXrWDtvkq+T5A38XgefJGQyoX8Xot30/o38/Hzi4+MpKyvjhRdeoF+/usJFBxR+30YsLK/i9K08vjbffSF5HMa+1pq4uDh69fJc7O42gt/roLzKxqfXctg4tb/b+nZpaWls376dsLAwtmzZQteuXd1y3DaM3+vgaHI2keEdmDygq7sOya1bt9ixYwddunQhLi6uvUwC8TsC0dxv9YNhLY/Z4/Ldy07//yXwy9aepyH2Xs5g+uDu9HRD6IWTJ09y+PBhJkyYwPr169uDsQ8BooMTN3LJLalknRtC8hw5coSTJ08yY8YMVq1a1R4MXQgAHRxMzGJoz04M6dnJLcfbs2cP58+fZ+HChSxatMgtx/QD/F4HJiRPOrOG9nBLvfDBBx+0N2MfWqkDX2ugstrO8Ws5rJvYxy3lt9aat956q70Z++DnOriUWkBuSSWL3fRCZZvN1h6NffBzHbibtNyi9mjsg5/rIKe4gvN38/nB0pFuOV5paWl7M/YhANqIn17Lodqu3bZ6w7FyA2gvxj4EgA4+T8mlrMrGEjet9s7Ozmb79u2Eh4cTFxfXHox98HMdaK05lpzN3GE96RDsHs8vNTWVHTt20LVrVzZv3izGfhsmEM39aKXUD+v7UWv9n95MTEu4nlXMtaxi/vHROl+c3WyGDRvGjBkzWLlyZXsx9iEAdACw80IakWEdWDSq9Y2qESNGYLPZWLp0aXsx9sHPdVBcUc3nN3KJmzPIbcccM2YMkZGRLFiwwG3H9AP8WgcAiRlFpOSU8OK8IW453tixYxkwYAAzZ850y/H8BL/WwelbeRRXVLNktHtW8SiliI2NZfz48UycONEtx/QT/FoHh5OyUAq3LbcODg4mNjaWefPmtSdjH/xcB+4ku6iCuK1n6VLVja+snM4jc6U8cNDWdXA40YRqc1foxoiICMaOHUtsbCx9+7rnXV9+gF9rAMyqvi4RIUwZ2NUtx4uMjGTs2LFMnz69vRj7ECA6iAgJZvbQHm45Xrdu3Rg7dizz589vL8Y++LkObmQXk1ZQzneXuO+57dmzJ7GxsSxdulSM/TZOIJr7wUBn6n5TtV+w73I60PrQCykpKQwZMoTo6GhWr17tjqT5E36vg/IqG/svZ7ByXAzhIS17R4LWmlu3bjFkyBD69+9P//793ZzKNo9f6+DTazlU2uytNvPsdjt37txh8ODBDB06lKFD3bds10/wax3Ag5A8q8a1vF6w2Wzcu3ePQYMGMXbsWDemzm/wax0cTMgitEMQc4e3rtNWWVlJZmYmAwYMYPLkFq889mf8WgeHk7KZNKAr3TuFtuo45eXl5OXl0bdvX2bPnu2m1PkVfq0Dd3ErI4eXtp/iXmEw//yVx5jlJlPIj/BrHRxKzCImKrzVodry8/Ox2+10796d5cuXuyl1foNfa8Bu1xxJymLByF6tnqmbnZ1NeHg4kZGRrFmzxk0p9Bv8Wgdaaw4mZDF3eM8W+wYO0tPT6dq1KxEREaxbt85NKfQb/FoHR5KyAVgwsvXvy7l37x7R0dGEhYWxfv36Vh9P8DyBaO6na63/ydeJaA17LmUwZWBXYrq0PHbikSNHOHr0KBs3biQ21j0rAPwMv9fBkaRsiiqqWxySR2vN/v37OXXqFJs3b2bIEPfM+PUz/FoHBxMyiQrvwLTBLX9pot1uZ+fOnVy4cIFvfOMb9Onjvpd0+xF+rQOtNbsvpTNzSMtD8thsNt555x2uXbvGd7/7Xbp1c9+LOP0Iv9bB4aQsZg/tQcfQljfdKisreeONN0hNTeX73/8+nTq5J9yXn+G3OsgpruDivXz+dFnrQnCUlZXx2muvkZ+fz0svvdReX4zmtzpwF7cycvjNK39glN3Gjze/2B6NffBjHVRU2ziWnM36yf1atSL3/v37xMfHEx4ezje/+c32tLrXgd9qAEyotpziSpaMbt1M3aysLLZt20bPnj3ZsmWLexLnX/i1DpIzi0nNL+N7S4a36jipqals376doUOH8tRTT7kpdX6FX+vg2LUchvXqRP9urXsRekpKCm+88QYTJkxojwM8fksgxmjx6xbJndxSrqYXsnpcyw04h7E/adIkxowZ48bU+RV+rQOAXRfT6NEplLnDmt/Z0lqzb98+Tp06xaxZsxg8eLD7E+gf+K0O7HbN4aQsFo6KJqSFM3Hsdjt//OMfuXDhAosXL26vxj74sQ4AkjKLSMkuYc2EluVfdXU1b7/9NklJSaxcubK9GvvgxzpIyS7mZk5Jq0IvVFZWsmPHDm7fvs26devaq7EPfqyDo0nZaE2r4u2XlZWxfft2MjMzWb9+fXs19sGPdeAObqYZYz/EXs6SlWuYM8I9YV38EL/VwamUPEoqbSxtRZx1h7FfUVHB+vXr26OxD36sATCrN5SChSNbroOsrCzi4+NRSrF27Vo3ps6v8GsdHEzMBGBxK8qDe/fusX37djp27MjKlSvdlTR/w291UF5l41RKbqvDNjqM/e7du7NkyRI3pU7wBoE4c3+prxPQGvZaIXlaEnpBa82RI0c4duwYkyZNYt26de0pxr4rfq2DkopqDiZk8uTUAc1eYqm1Zu/evZw+fZpZs2axYsWK9tpYBz/WwYV7+eQUV7KshWaew9i/ePEiixcvbm8x9l3xWx0A7LloheRpQai26upq3nnnHZKTk1mzZg3Tp0/3QAr9Br/VwaHELKDlpq7D2L9z5w6PPfYY48ePd2fy/A2/1cHhpCx6RYa1OASHw9jPysriqaeeYuRI97yE00/xWx20lptpObz86u8JsVcwb9UGVs2S8sAfOZSYRXhIEHOHtyz8Ql5eHvHx8VRVVbF58+b2PAHEbzUApl6Y3IpQbQ5jPygoiLi4OHr2bH04Dz/Fr3VwKCGL8f260DuqZZEfHMZ+p06diIuLo0uXLm5Ood/gtzo4dTOPimo7C1th7t+4cYM333yT7t27s3nz5vY8EcgvCTjnV2ud5+s0tIa9lzMY1y+KAd2bv5QmOzub48ePM2nSJB599NH2bOz7vQ4OXM2kvMrOo5OaH5Ln7t27nD59mtmzZ7d3Y9+vdXAwIYvgINXiCvratWtcvHiRJUuWtHdj36914AjJM2NId3pFNn+G7eXLl8XYt/BnHRxKzGJk784tahsAnDlzRox9C3/VQbXNzrHkbBaN7EVQUMvq9RMnTpCVlcXTTz/d3o19v9VBa8ksLOenf3ifEHsF81e3e2Pfb3WgteaThEzmDmt5fO2DBw+KsY//agAgq6ici/cKWNKK2dr79u0jODiYLVu2tGdj3691kFdSyZd37rdYB1prdu/eTadOndiyZUt7Nvb9WgfHkrMJ7RDEzCEtC7Fns9nYvXs3PXr0IC4uTox9PyQQZ+77LWn5ZZy/m89frBzVov2jo6N58cUX6devdbEXBd+z80IafbuEM3Vg88NnDBw4kBdffJH+/fuLDvyYg4lZTB3Uja4dWzYTZ9SoUbz44osMGDDAzSkTvElyZjE3skvYMmdwi/afOHEiPXr0EB34MYXlVXxxM4+vzW/5i7Bnz57NwIED2+NL1QOGc3fzKSyvbtWS+0WLFjF69Gj69evnxpQJ/kJmYTnPvvI5ORX9+a/1C1k6tWX9DcH3JGcWc+9+Gd9Z1PL42uvWraOwsJDo6HYbksnvcbw8szX1whNPPEF5eTk9erTLd24EBEeTs7BrWhy6USnFM888g1KKqKjWvZxb8B3HkrOZOaQ7EaEtG/ANDg7mueeeIyIigo4dWxezX/AN7Xdqdxtk3+UMAFY3IySP1prDhw+TmJgIIIZuAHC/pJJjydmsm9i3ybPzHC/PvXnzJgADBgwQHfgxqfllJKQXNjuOqt1u56OPPiI1NRVADN0AYPeldJSClc2oF6qrq/nwww/Jzs5GKSU68HM+vZZDtV03e0ZWRUUF77//Pvn5+SilxNj3cw4nmtVc80Y0b2ZlaWkp7733HsXFxQQHB4ux3065kZrNP/7iD+QVFvP7F2eJse/nOOJrN7deyMvL44MPPqCqqorw8HAx9v2cw4lZxESFM7ZP8wzZjIwM/vjHP2Kz2ejUqZMY+37OwQQTsm9c3+bNuL979y67d+/GbrfTpUsXMfb9mLT8Mq5lFbdoxf/169c5cOAAWmt69Oghxr4fI+Z+G2Lf5QxG9Y5kaK/OTdpea82hQ4c4duwYN27c8HDqBG+x93IG1XbNuolNC8njWEr3+eef15j7gn/jiK+9dEzvJu9jt9v54IMPOHv2LHfv3vVU0gQvs+dSOjMGdyc6smkxNKurq3nrrbe4cOECaWlpHk6d4A0OJmTRJSKEKQO7NnmfiooKXn/9dS5fvkxGRobnEid4jcNJ2Uwb1I2o8JAm71NaWsq2bdtISEggJyfHg6kT2jI3UrN55Xd/oHt1Lv+xfjjTBnf3dZKEVnIwIYtx/aKI6dL0+Nq5ubls3bqV69evU1BQ4MHUCd6gstrO8Ws5LB7dq1kTujIyMti2bRspKSkUFxd7MIWCN6iy2TmanM2SUdHNCtl3584dXnvtNVJSUigvL/dgCgVvcCzZrOJp7st0r1+/zptvvklKSgpVVVWeSJrgRcTcbyNkFZVz+nZek1+kq7Xm4MGDfPrpp0ydOpU1a9Z4OIWCt9h1IY2hPTs16YV5DmP/7NmzzJ07l8WLF3shhYKnOZiQyeAeHRnWq2mx7ux2O++//z6XL19m2bJlzJo1y8MpFLxBcmYR17OKeWRC02LhOoz969evs27dOiZOnOjhFAqexm7XHEnKYuHIXk1+ubrD2L937x5PPPEEo0eP9nAqBU+TUVBOQnphs0IvOIz93Nxcnn32WQYPHuy5BAptlmv3snjld78nxF7JokceZ+lUKQ/8HUd87aWjmz4BJDc3l/j4eGw2G5s3b27XsdUDhTO38iiuqGbxqKbXCw5jPyQkpL2/NDVgOHPrPkXl1SxpRkieO3fu8PrrrxMZGcmWLVtkpnYAcOxaNjFR4YyIbtokYTDv53vzzTfp1asXmzdvJjS0ZaGAhbaDmPtthI+vZKI1rB7fuLnvMPY/++wzpk6dyiOPPCIhWAKEzMJyPr+Zy7qJfRvNU601H330EWfPnmXevHksXbpUdBAAlFZWc+JGLktG925SfjqM/StXrrB8+XLmzp3rhVQK3mD3RROSpymDvtXV1bz55ps1xv6UKVO8kELB01y4l09uSWWT46g6G/sbN24kNjbWwykUvMHhJLOaq6kmjrOx/8wzzzBs2DBPJk9ooyTfzeLV3/+BEHsVi9c+zrLpY32dJMENHE7MQjcjvrarsd+7d9MHBYS2y6HELEKDg5g7vGkDNenp6TXG/pYtW+jeXVbwBAIHEzIJDQ5iXhN14JixHxkZSVxcHJGRkR5OoeBpqm1mFc/CkU1fxXPt2jXeeustoqOj2bx5MxERER5OpeAN5IW6bYR9lzMY0rMTo3o3rYCtrq5m2rRprFmzRgzdAOKji+loDY9Oajwkj9Yam83GvHnzWLJkieggQPj0Wg6V1XaWNbHTprWmurqa5cuXM2fOHA+nTvAmey6lM72JIXnsdjt2u51HH32UyZMneyF1gjc4lJhFkKLJMTS11mit2bhxI2PHipEXKBxOzKJf1whG9m7ajCy73U5QUBDPPvssQ4e2/EXMgv+Sll/Gd18/S6w9iJXrnmDJ1DG+TpLgJg4mZhLdjPjadrudiIgInnjiCYmxH0AcSspi5tDudAprmp1jt9uJiori6aefplu3bh5OneAtDiVmMWtYjybrwGaz0aNHDzZt2iTGfoBw4V4+ReXVzQrJY7PZ6NOnD5s2bRJjP4AQc78NcL+kkpMpuXxzwdAGDVqtNaWlpXTq1ImVK1cCiKEbYOy8kEZs3yiGNfDeBa01ZWVldOzYkfXr1wOig0DiUGIWkWEdGo2Ja7PZqKysJCIigqefflo0EGBcyyziWlYx//howzOvq6qqsNvthIWF8cILL4gOAoyDCVlMHdSNrh0bXipbUVFBcHAw4eHhvPjii6KDAKKi2sZn13PYMLlfo/laVlZGaGgonTt35utf/7rooJ1yPS2XF7df4H5ZED998atMGSQzdAOFymo7x5JzWDexT6PxtUtKSujYsSO9evXiW9/6lpQHAcTt3BJSskt4YdagRrctKSmhU6dO9OvXj29+85uigwAiJbuYlJwS4uYMbnRbhw6GDBnCN77xDdFBAHE0OYcgRZNWbzh0MHr0aEaNGiU6CDAkLE8b4MDVTGx2zepx9cdV1lpz4MABfvvb31JcXIxSSh7GAON2bgkX7uY3+CJdrTW7du3i1Vdfpby8XHQQYNjtmoOJWSwY1YvQDvUXzzabjffee4/4+Hiqq6tFAwHI7ksmJM/qBkLyVFVV8eabb7Jjxw7sdrvoIMDIKCjnanohSxqJq1xeXs727dt555130FqLDgKMM7fuU1JpazQkT0lJCVu3bmXXrl2ADPq3V5LuZPK/r77KgLLrbP/aTDH2A4wvbpo4643VCzk5Obz88sscP34ckPIg0DiUaEK1LWnkPSzp6en88pe/5MyZM4DoINBoqg5u3brFL37xCy5fvgyIDgKNo8nZTBzQlS4dQxrcLjk5mZ///Odcv34dEB0EImLutwH2Xk6nf7cIxvWr+wWqDmP/5MmTjB49mk6dmvaSTcG/2HUhDaBec19rzc6dOzl37hzjx48nLCzMm8kTvMDltAKyiypY2kAjzWHsJyQkMHHiRDp0kAVYgcjeSxlMH9Sd6Ki6Q/I4jP2UlBQmT55MUJBU54GGo9PWUFzl8vJyXnvtNdLT05k8ebI01AOQw1Zc5TnDe9S7TUlJCfHx8eTl5cmLtNsxCbfT+f3WrXSwV/H1RxcwaUBXXydJcDMHEzMJ69BwfO2cnBzi4+PRWjNmjIRjCkQOJWYxtFcnBvWo3xNIS0tj27ZthIWFMXz4cC+mTvAWhxKzGNm7MwO61/9C3Fu3brFjxw6ioqIYPHiw9xIneIX7JZVcvJffaPjOpKQk3nrrLXr16kX//v29lDrB24gb4GMKy6v49HoOq2Jj6uyUa635+OOPOXnyJNOnT2f16tXSeQ9Qdl1IZ9qgbvTr+nDcM7vdzs6dOzl//jwLFy5k8eLFooMA5JMEE197UT0zNG02G++++y4JCQmsXLmS2bNnezmFgje4nlVMUmYRa+p5wXpVVRVvvPEGKSkprF+/nkmTJnk3gYJXOJSYSb+uEYyIrjtMm7Ox/+STTzJ69Ggvp1DwBoetuModQ+seyC0uLiY+Pp779++zadMmhgwZ4uUUCm2Bq7fSiY+Pp4O9iuWPbmTRFCkPAg2tNQcTspg7vCcRocF1bpOdnV1j7MfFxdGrV9NjMAv+QUlFNadS8ljSwGqutLQ0tm/fTnh4OFu2bKFr167eS6DgFQrLq/jiZl6Dq3hu3rzJjh076Nq1K3FxcXTu3LT39gj+w6fXc9CaBuPtJyUl8fbbbxMTE8MLL7xAeHjj73IT/BMx933MoYQsqmya1fWYOKdPn+bzzz9nxowZYuwHMEkZRSRlFtX7It3jx4/XGPuLFi3ybuIEr3EwIZMpA7vRvVPd8bUPHDhAYmIiq1atYtasWV5OneAt9jhC8oyvO1TbRx99xM2bN9mwYYMY+wFKeZWNz67nsnRMdL31/nvvvUd6ejpPPfWUGPsByp3cUm5kl9QbkkdrzVtvvUV+fj7PPfecGPvtlNs5xfxh23aC7dWsWP+kGPsByvWsYu7kldYbgqOqqort27cDsGXLFjH2A5TPrudQabPXq4OysrIaYz8uLk6M/QDleHIO1XZd7+rOgoKCGmN/8+bNYuwHKEeTs+kSEcLE/l3r/D0rK4u3336bPn36iLHfDpB4Dj5m7+V0ekeFMXlA3W+tnzhxIlprZsyYIcZ+ALPzQipBCtbUY+ZNnz6dTp06MW3aNC+nTPAWGQXlXEkr5C9X1d8pnzNnDjExMWLoBjh7LplVPL3rCcmzcOFCRo4cSWxswy/bFfyXkym5lFXZWNxAiK6lS5cyffp0Ro4c6cWUCd7kcJIJzVSfDpRSrFixApvNJsvt2yl380rZ9OoXdNSD+bsNk1gwScqDQOVgI6HaQkJCWL16Nb169aJnz8ZfrCj4J4eTsugc1oFpg+t+n0ZERASrV69m4MCBYuwHMAcTM+naMYQpA+v2kLp06cLq1asZNWqUhHQOULTWHL+WzbwRPQmu5wXrvXr1YuXKlUyYMEGM/XaAzNz3ISUV1RxJymZVbAxBTg+k1povvviCyspKwsLCmDlzphj7AYzWml0X0pk7vCc9Oz+Io2+32/n888+prq6mY8eOYuwHOAcTM4GHO202m43PP/8cu91OVFSUGPsBzo3sYhIzih4a6KusrOTUqVNorenevbsY+wHOoYQsIkKCmT20dpz1srIyzpw5g9aamJgYMfYDnMNJWQzp2YkhPWt3zIuKijh//jwAAwYMEGO/nXL1Zho/+M1Oiiuq+a+vrRRjP8A5mJDJ2D5R9OlSO3xnVlYWSUlJAIwZM0aM/QBGa83hxGzmj+hJaIfaNs69e/e4efMmABMmTBBjP4Cx2TVHkrJZPCr6IVM3JSWF1NRUAKZMmSLGfgCTlFlEZmEFC0c8vEorKSmJ7OxslFLMmDFDjP12gpj7PuRIUjYV1XZWjXtg4mit2bdvH3v37uXChQs+TJ3gLc7fzedOXmmtF+na7Xb++Mc/sn//fhITE32YOsFbHErIYkD32vG1q6urefvtt9m/f39Ng10IbPZcTAdgtVO9UFlZyRtvvMH+/ftJS0vzVdIEL6G15lCiiascHvIgrrJjqf2+ffvIzc31YQoFb1BWaePkjVwWjardaSsqKiI+Pp69e/dSVFTko9QJvuZKinlZ5qjqG2zdPIlx/br4OkmCB7lfUsnZ2/dZ5jIBJCsrq6Y8qK6u9lHqBG9xNb2QjMLyh1Zz3bt3j9dee419+/Zht9t9lDrBW5y/m09eSeVDoZlSUlJ44403+Pjjj9Fa+yh1grc4mpQNwPyRtQd0r169yttvv82hQ4d8kSzBh4i570P2Xk6nR6dQZgwxy+q01uzdu5cvvviC2bNny0ztdsKuC+mEBgexMta8d8Fh7F+8eJHFixczbtw4H6dQ8DRllTY+vZ7D0tG9a1bpVFdX884775CcnMyaNWsYNmyYj1MpeIPdVkiemC5mhkVlZSU7duzg9u3bPPbYY/Tr18/HKRQ8TXJmMan5ZbU6bQ5jPysri6efflpmZrYDPk/JpaLaXivevsPYLywsZNOmTURGRvowhYKvuJySyvbt2wjGxpoNTzF5SP3hu4TA4EhyFnYNS8c8eHmmw9gPDg7mhRdeoEMHibYb6By2QjM5D/reu3eP7du307FjR5577jmCgsTeCXQOJWYSHKRqvUT1xo0bvPHGG3Tv3p2nnnpKoj60A45dy2ZU78haq7muXr3Ku+++S79+/diwYYPvEif4BCn9fUR5lY3DiVmsiO1NcJCqMfZPnz7N7NmzWb58uRTK7QCbXfPRxTQWjepFl4gQ7HY7H374IRcvXmTJkiUsWLDA10kUvMCJGzlUVNtrQvI4ZuwnJyfzyCOPMH36dB+nUPAGKS4heRzG/p07d3j88ccZP368j1MoeANHiC6HuV9WVsa2bdtqjP0RI0b4MnmClzicZEIzOSaAOIz9oqIinn/+eQYNGuTjFAq+4FJKKq9t326M/cefYt5EKQ/aA58kZNErMozx1gqNzMzMGmM/Li6OHj16NHIEIRA4lJjFhP5diI40E0Du3r3L9u3b6dy5M1u2bCEqKsrHKRS8wcGELKYP7kaXiBDAGPtvvvkmPXr0IC4uTkLxtANKK6s5ffM+C5xm7TuM/f79+/Pcc88RFhbWwBGEQETMfR9x/FoOJZW2mpA8xcXFJCQkMGfOHDH22xGnbuaSVVTBo5NMSJ78/HyuXbvGkiVLmD9/vo9TJ3iLTxKy6BT6wMTJycnh9u3bPPLII7KCpx2x55IVkme8WcWTnp5Oamoqjz/+uKzgaUccTswitm9UzeqNO3fukJubK8Z+O+JBaKYeNaGZUlJSKCoq4rnnnmPgwIE+TqHgC27llPB/dhwiGBuPPP40c8dLedAeqLLZOZaUzZJR0TXvaLt69aoY++2MvJJKzt3Nr7Wa6+LFi3Tu3Jm4uDgx9tsJqfllJGYUsXT0g1U858+fp0ePHmzevJmOHTv6MHWCt/g8JZdKm71m9YbWmi+//FKM/XaOrN/zEXsvpxMV3oFZQ7qjtSYyMpJvfvObdOrUSYz9dsSuC2l0DA1midVQ6969O3/yJ39C586dG9lTCBSMiZPJgpG9CA02460xMTF873vfEx20M3ZfymDqoG7ERBlTd9CgQXz/+98XHbQjHHGV/2TxcLTWKKUYNWoUL730kuigHXEju4R798v41sJhNTqYOHEiw4YNEx20U25mF/Ps/56iwt6bHz23jCnD+zS+kxAQnL6ZR1FFNUvGRNeUB4sWLWL69OlSHrQjjiZnobVZ1efQwerVqykrK5OZ2u2IQ1ZoJufyYMOGDVRWVhIREdHI3kKgcCw5h/CQIKYP7l6jg6eeegqttRj77RiZue8DKqvtHLiayfIxvTmwf2/NS086d+4sxn47orLazp5LGSwf04s9uz7k2LFjANJQb2dcSSsks7CCxSN7sGPHDk6fPg2IDtobN3NKSEgvZNWYnsTHx3Pp0iVAdNDeOHYtG7uGuYMj+d3vfkdycjIgOmhvOOIqz+gXwSuvvMLt27cB0UF75cL1e/zy178horqQHV+fJcZ+O+OThCxCOwQxKsrGyy+/TE5ODkopKQ/aGYcSs+nZOYwutgJ++9vfUlBQQFBQkBj77YxDCZkM7tER2/00Xn31VUpKSggODhZjv51xLDmbWUN7cD0pga1bt1JRUUFoaKgY++0cMffrQCm1SimVpJS6rpT6cR2/K6XUL6zfLyqlpjTn+Cdu5FBUXsWIymTOnj0rL0Bqo3haB8evZVNYVsnIsgSuXLkiOmijeFoHBxOy6KDslCQc5/r16wQHB7sv8YLb8LQO9lxKJwQbtuRj3LlzR3TQBvG0BsCUB306Ks4d3ElmZqbooA3iDR0cTspifK8Q9n3wJnl5efKCxDaIN3QAcOH6Xd58fTthVPKvT0xkTB8JvdGW8LQOtNYcTMxk0YAQ3n7jdcrLy6U8aIN4WgfVNjtHk7JYOiCIHTtep7q6WnTQBvG0Dkorq/nsRi6L+9h5++230VqLDtogntbB3bxSUnJKmBZZzPvvv49SSiYIC4CY+w+hlAoGfgWsBsYCzyqlxrpsthoYYf19A/hNc86x71I6C8LukJmSwLx581iyZIk8kG0Mb+hg1/l7LIu4Rc7dGyxfvpw5c+a4IeWCO/GGDg4lpLE+8jZ3bqWwbt06pkxpUf9f8CBeqRcu3OWxyBSyM9PZuHEjY8e6Hl7wJd7QQLXNzomkVJaHJpGXl8uzzz7LsGHD3JB6wV14QwdF5VVcuZXOtKpLlJaW8sILLzBgwAA3pF5wF97QAcD5a3d48/XtKOysf3ITs2KHtjLlgjvxhg5uZJdQlJfDgNwzhISEsGXLFrp37+6G1Avuwhs6+PJOPhGV9+l89yRRUVHExcURGRnphtQL7sIbOvjsei7R9jzUzRNER0fzwgsvyIz9NoY3dHA0OZshwbnkXf2UgQMHsmnTJkJDQ92QesHfEXP/YWYA17XWKVrrSuBNYL3LNuuBbdrwOdBVKdWkNbLVNjsZV04yLCib+fPni7HfdvGoDkorqilKPEF/clmxYoUY+20Xj+ogPb+U6OwviarK5dFHHxVjv+3iUR3cyChgYN5ZOtkKxdhvu3hUAwCnrmcyV1+lQ1UJzz77LEOHipHXBvG4Do5cvsuyDkl0sFfy/PPP079/f/elXnAXHtfBhRupvLXjNRSa9U9uYubYIe5LveAuPK6D/WeTWBWWRMfwMLZs2UK3bt3cl3rBXXhcB5+cSWB56DW6dukixn7bxfPtg9OXWBJ6g97RvcXYb7t4XAdfnLvIwtCbYuwLDyHm/sP0A+46fb5nfdfcbVBKfUMpdUYpdSY7OxuAi6kFpFR0pu/oKSxevFiM/baLR3Vw6mYet6ujGDl1LrNnz3ZvygV34lEdnEzJI9UWxfSFK5g8ebJ7Uy64E4/q4Mi1XFLtUSxbs54xY8a4N+WCu3CbBqBuHXx+q4AMexSPP/mUGPttF4/r4Iu7xWSrLjwnxn5bxuM6+N+TaWSrrjz2lBj7bRiP6+DUvXKKQnvy4lfE2G/DeL5eSKukLCKar3xlixj7bReP9hW01nyeXkVVZB82bxZjvw3jUR3Y7JrTmXbsXQeIsS88hAT5fpi63Hbdgm3QWr8CvAIwbdo0DTBlYDe2/9lj9I4KF2O/beNRHSweHU3/lx5naC95GVYbx6M6eGxyP8b1e4oR0aKDNo5HdfDivCHMH/ksI3tLh60N4zYNQN06+MHyUaRM6scI0UFbxuM6+IdHx3Fr7lAGS73QlvG4Dn721GQyCsZIO7Ft43EdvLJlFhkFk+jWTV6a2obxuA52fHs+OUUz6dy5Y2vSKXgWj/YVlFJ8+INlFJZXi7HftvGoDoKDFHt/tJryKrsY+8JDiLn/MPcA5+Cm/YG0FmxTL4N6SAPND/C4DsTA8Qs8qgOllBi6/oHoQPB4nRAcpKReaPt4XAcdgoMYLsZ+W8fjOugY2kGM/baPx3UQHhLM4J7Sb2zjeKU8GNhDbJs2jsd1EBkeQmR4SIsTKHgFj+uga0cx9YW6kbA8D3MaGKGUGqKUCgWeAXa6bLMT2Gy96XoWUKC1Tvd2QgWPIjoQQHQgGEQHgmhAANGBYBAdCCA6EAyiAwFEB4JBdCD4DBkCdkFrXa2U+i6wHwgGfq+1vqKU+pb1+8vAHmANcB0oBb7S2HHPnj2bo5S67fRVTyDH3en3Y1zvxyBfJQREBz6kPepANPAwogMB2pAOPKUBEB00AdGBAKIDweB8TwKybQCigyYgOhCgHehAvIMmIToQoA3pwFcoresM9yZ4GKXUGa31NF+no63QXu9He73u+miP96M9XnNjtMd70h6vuTHa4z1pj9fcGO3xnrTHa26M9nhP2uM1N0Z7vCft8Zoboz3ek/Z4zY3RHu9Je7zmxmiP96Q9XnNjyD2RsDyCIAiCIAiCIAiCIAiCIAiC4HeIuS8IgiAIgiAIgiAIgiAIgiAIfoaY+77jFV8noI3RXu9He73u+miP96M9XnNjtMd70h6vuTHa4z1pj9fcGO3xnrTHa26M9nhP2uM1N0Z7vCft8Zoboz3ek/Z4zY3RHu9Je7zmxmiP96Q9XnNjtPt7IjH3BUEQBEEQBEEQBEEQBEEQBMHPkJn7giAIgiAIgiAIgiAIgiAIguBniLkvCIIgCIIgCIIgCIIgCIIgCH6GmPteRim1SimVpJS6rpT6sa/T42uUUr9XSmUppS77Oi3eRHRQG9GB6ABEB6IDg+hAdACiA9GBQXQgOgDRgejA0B51IBp4GNGB6ABEB6IDQ3vUQX2Iue9FlFLBwK+A1cBY4Fml1FjfpsrnbAVW+ToR3kR0UCdbER2IDkQHogPDVkQHogPRgejAsBXRgehAdCA6MGylHelANFAvWxEdiA5EB6IDw1bakQ4aQsx97zIDuK61TtFaVwJvAut9nCaforU+BuT5Oh1eRnTgguhAdACiA9GBQXQgOgDRgejAIDoQHYDoQHRgaIc6EA3UgehAdACiA0QHQLvUQb2Iue9d+gF3nT7fs74T2heiAwFEB4JBdCCA6EAwiA4EEB0IBtGBIBoQQHQgGEQHQoOIue9dVB3faa+nQvA1ogMBRAeCQXQggOhAMIgOBBAdCAbRgSAaEEB0IBhEB0KDiLnvXe4BA5w+9wfSfJQWwXeIDgQQHQgG0YEAogPBIDoQQHQgGEQHgmhAANGBYBAdCA0i5r53OQ2MUEoNUUqFAs8AO32cJsH7iA4EEB0IBtGBAKIDwSA6EEB0IBhEB4JoQADRgWAQHQgNIua+F9FaVwPfBfYDCcDbWusrvk2Vb1FKvQGcBEYppe4ppb7q6zR5GtHBw4gORAcgOkB0AIgOEB0AogNEB4DoANEBIDpAdAC0Px2IBupGdCA6ANEBogOg/emgIZTWEqZJEARBEARBEARBEARBEARBEPwJmbkvCIIgCIIgCIIgCIIgCIIgCH6GmPuCIAiCIAiCIAiCIAiCIAiC4GeIuS8IgiAIgiAIgiAIgiAIgiAIfoaY+4IgCIIgCIIgCIIgCIIgCILgZ4i5LwiCIAiCIAiCIAiCIAiCIAh+hpj7AY5SyqaUOu/0N1gptUgpVaCUOqeUSlBK/YO1rfP3iUqp/+fr9AvuQXQggOhAEA0IBtGBAKIDwSA6EEB0IBhEBwKIDgSD6MC/6ODrBAgep0xrPcn5C6XUYOC41nqtUqoTcF4p9ZH1s+P7COCcUuoDrfVn3k2y4AFEBwKIDgTRgGAQHQggOhAMogMBRAeCQXQggOhAMIgO/AiZud/O0VqXAGeBYS7flwHngX4+SJbgZUQHAogOBNGAYBAdCCA6EAyiAwFEB4JBdCCA6EAwiA7aFmLuBz4RTstoPnD9USnVA5gFXHH5vhswAjjmnWQKHkZ0IIDoQBANCAbRgQCiA8EgOhBAdCAYRAcCiA4Eg+jAj5CwPIHPQ0tpLOYrpc4BduCnWusrSqlF1vcXgVHW9xleS6ngSUQHAogOBNGAYBAdCCA6EAyiAwFEB4JBdCCA6EAwiA78CDH32y/HtdZr6/teKTUS+NSKk3Xey2kTvIfoQADRgSAaEAyiAwFEB4JBdCCA6EAwiA4EEB0IBtFBG0TC8gh1orVOBv4V+Etfp0XwHaIDAUQHgmhAMIgOBBAdCAbRgQCiA8EgOhBAdCAYRAe+Qcx9oSFeBhYopYb4OiGCTxEdCCA6EEQDgkF0IIDoQDCIDgQQHQgG0YEAogPBIDrwMkpr7es0CIIgCIIgCIIgCIIgCIIgCILQDGTmviAIgiAIgiAIgiAIgiAIgiD4GWLuC4IgCIIgCIIgCIIgCIIgCIKfIea+IAiCIAiCIAiCIAiCIAiCIPgZYu4LgiAIgiAIgiAIgiAIgiAIgp8h5r4gCIIgCIIgCIIgCIIgCIIg+Bli7guCIAiCIAiCIAiCIAiCIAiCnyHmviAIgiAIgiAIgiAIgiAIgiD4Gf8fFWzs4+/UvygAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1440x144 with 11 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# #plot roc_curves for all neural network test models\n",
    "# fig, ax = plt.subplots(1, 11, figsize = (20,2))\n",
    "\n",
    "# plot_roc(y_test, y_pred_nn, \"NN Model 3 (i) - Baseline\", ax=ax[0])\n",
    "# plot_roc(y_test, y_pred_nn_t1, \"NN Model 3 (ii)\", ax=ax[1])\n",
    "# plot_roc(y_test, y_pred_nn_t2, \"NN Model 3 (iii)\", ax=ax[2])\n",
    "# plot_roc(y_test, y_pred_nn_t3, \"NN Model 3 (iv)\", ax=ax[3])\n",
    "# plot_roc(y_test, y_pred_nn_t4, \"NN Model 3 (v)\", ax=ax[4])\n",
    "# plot_roc(y_test, y_pred_nn_t5, \"NN Model 3 (vi)\", ax=ax[5])\n",
    "# plot_roc(y_test, y_pred_nn_t6, \"NN Model 3 (vii)\", ax=ax[6])\n",
    "# plot_roc(y_test, y_pred_nn_t7, \"NN Model 3 (viii)\", ax=ax[7])\n",
    "# plot_roc(y_test, y_pred_nn_t8, \"NN Model 3 (ix)\", ax=ax[8])\n",
    "# plot_roc(y_test, y_pred_nn_t9, \"NN Model 3 (x)\", ax=ax[9])\n",
    "# plot_roc(y_test, y_pred_nn_t10, \"NN Model 3 (xi)\", ax=ax[10])\n",
    "\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9aea9a9-f34e-4f94-868d-5911fb32b818",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
